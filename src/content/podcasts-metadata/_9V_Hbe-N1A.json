{
  "schemaVersion": "1.0.0",
  "videoId": "_9V_Hbe-N1A",
  "url": "https://www.youtube.com/watch?v=_9V_Hbe-N1A",
  "metadataCreatedAt": "2026-01-03T03:46:37.985Z",
  "metadataLastSyncedAt": "2026-01-03T07:31:10.313Z",
  "transcriptCreatedAt": "2026-01-03T03:46:37.985Z",
  "title": "Adam Marblestone â€“ AI is missing something fundamental about the brain",
  "description": "Adam Marblestone is CEO of Convergent Research. Heâ€™s had a very interesting past life; Research Scientist at Google Deepmind on their neuroscient team; has worked on brain computer interfaces to quantum computing and nanotech to formal mathematics.\n\nWhere we discuss how the brain learns so much from so little, what the AI field can learn from neuroscience, and the answer to Ilyaâ€™s question: how does the genome encode abstract reward functions? Turns out, theyâ€™re all the same question.\n\nğ„ğğˆğ’ğğƒğ„ ğ‹ğˆğğŠğ’\n* Transcript: https://www.dwarkesh.com/p/adam-marblestone\n* Apple Podcasts: https://podcasts.apple.com/us/podcast/adam-marblestone-ai-is-missing-something-fundamental/id1516093381?i=1000743205259\n* Spotify: https://open.spotify.com/episode/5RD8lxJh0mGSlpEWWExQNG?si=srfZ9QBgRFqvOtJGX8EGqg\n\nğ’ğğğğ’ğğ‘ğ’\n- Gemini 3 Pro recently helped me run an experiment to test multi-agent scaling: basically, if you have a fixed budget of compute, what is the optimal way to split it up across agents? Gemini was my colleague throughout the process â€” honestly, I couldnâ€™t have investigated this question without it. Try Gemini 3 Pro today https://gemini.google.com\n- Labelbox helps you train agents to do economically-valuable, real-world tasks. Labelboxâ€™s network of subject-matter experts ensures you get hyper-realistic RL environments, and their custom tooling lets you generate the highest-quality training data possible from those environments. Learn more at https://labelbox.com/dwarkesh\n\nTo sponsor a future episode, visit https://dwarkesh.com/advertise.\n\nğ…ğ”ğ‘ğ“ğ‡ğ„ğ‘ ğ‘ğ„ğ€ğƒğˆğğ†\nIntro to Brain-Like-AGI Safety - Steven Byrnesâ€™s theory of the learning vs steering subsystem; referenced throughout the episode. https://www.lesswrong.com/s/HzcM2dkCq7fwXBej8\nA Brief History of Intelligence - Great book by Max Bennett on connections between neuroscience and AI. https://www.abriefhistoryofintelligence.com/book\nAdamâ€™s blog. https://longitudinal.blog/\nConvergent Researchâ€™s blog on essential technologies. https://www.essentialtechnology.blog/\nA Tutorial on Energy-Based Learning by Yann LeCun. http://yann.lecun.com/exdb/publis/pdf/lecun-06.pdf\nWhat Does It Mean to Understand a Neural Network? - Kording & Lillicrap. https://arxiv.org/abs/1907.06374\nE11 Bio and their brain connectomics approach. https://www.e11.bio/\nSam Gershman on what dopamine is doing in the brain. https://gershmanlab.com/pubs/GershmanUchida19.pdf\nGwernâ€™s proposal on training models on the brainâ€™s hidden states. https://gwern.net/aunn-brain\nRelevant episodes:\nIlya Sutskever https://youtu.be/aR20FWCCjAs\nRichard Sutton https://youtu.be/21EYKqUsPfg\nAndrej Karpathy https://youtu.be/lXUZvyajciY\n\nğ“ğˆğŒğ„ğ’ğ“ğ€ğŒğğ’\n0:00:00 â€“ The brainâ€™s secret sauce is the reward functions, not the architecture\n0:22:20 â€“ What the genome actually encodes\n0:42:42 â€“ What kind of RL is the brain doing?\n0:50:31 â€“ Is biological hardware a limitation or an advantage?\n1:03:59 â€“ Why we need to map the human brain\n1:23:28 â€“ What value will automating math have?\n1:38:18 â€“ Architecture of the brain",
  "uploadDate": "2025-12-30",
  "duration": 6593,
  "viewCount": 82977,
  "likeCount": 1800,
  "commentCount": 287,
  "channel": "Dwarkesh Patel",
  "channelId": "UCXl4i9dYBrFOabk0xGmbkRA",
  "channelUrl": "https://www.youtube.com/channel/UCXl4i9dYBrFOabk0xGmbkRA",
  "channelFollowerCount": 1150000,
  "thumbnail": "https://i.ytimg.com/vi_webp/_9V_Hbe-N1A/maxresdefault.webp",
  "categories": ["Science & Technology"],
  "tags": [],
  "availability": "public"
}
