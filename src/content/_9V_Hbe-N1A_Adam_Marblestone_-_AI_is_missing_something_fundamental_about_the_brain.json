{
  "createdAt": "2026-01-03T03:46:37.985Z",
  "videoMetadata": {
    "videoId": "_9V_Hbe-N1A",
    "title": "Adam Marblestone – AI is missing something fundamental about the brain",
    "url": "https://www.youtube.com/watch?v=_9V_Hbe-N1A",
    "uploadDate": "2025-12-30"
  },
  "transcript": " The big million dollar question that I have that I've been trying to get the answer to through all these interviews with the researchers, how does the brain do it? Right. Like we're throwing way more data at these LLMs and they still have a small fraction of the total capabilities that a human does. So what's going on? Yeah, I mean, this might be the quadrillion dollar question or something like that. It's it's it's arguably you could make an argument. This is the most important question in science. I don't claim to know the answer. I also don't really think that the answer will necessarily come even from a lot of smart people thinking about it as much as they are. My overall meta-level take is that we have to empower the field of neuroscience to just make neuroscience a more powerful field technologically and otherwise to actually be able to crack a question like this. But maybe the the way that we would think about this now with modern AI, neural nets, deep learning, is that there's sort of these these certain key components of that. There's the architecture. There's maybe hyper parameters of the architecture. How many layers do you have or sort of properties of that architecture? There is the learning algorithm itself. How do you train it? You know, back prop gradient descent. Is it something else? there is how is it initialized okay so if we take the learning part of the system it still may have some initialization of of the weights um and then there are also cost functions there's like what is it being trained to do what's the reward signal what are the loss functions supervision signals my personal hunch within that framework is that the the field has neglected uh the role of this very specific loss functions very specific cost functions And machine learning tends to like mathematically simple loss functions, right? Predict the next token, you know, cross entropy, these simple kind of computer scientists loss functions. I think evolution may have built a lot of complexity into the loss functions. Actually, many different loss functions were different areas turned on at different stages of development. a lot of python code basically uh generating a specific curriculum for what different parts of the brain need to learn because evolution has seen many times what was successful and unsuccessful and evolution could encode the knowledge of the learning curriculum so so in the in the machine learning framework maybe we can come back and we can talk about yeah where do the loss functions of the brain come from can that can loss different loss functions lead to different efficiency of learning you know people say like the cortex has got the universal human learning algorithm the special science that humans have what's up this is a huge question uh and we don't know i've seen models where what the cortex uh you know the cortex has typically this like six layered structure layers in a slightly different sense than layers of a neural net it's like any one location in the cortex has six physical layers of tissue as you go in layers of the sheet and then those areas then connect to each other and that's more like the layers of a network um i've seen versions of that where what you're trying to explain is actually just how does it approximate backprop and what is the cost function for that what is the network being asked you to if you sort of are trying to say it's something like backprop is it doing backprop on next token prediction is it doing backprop on classifying images or what is it doing um and uh no one no one knows um but i think i think one one thought about it one possibility about it is that um it's just this incredibly general prediction engine so so any one area of cortex is just trying to predict any basically can it learn to predict any subset of all the variables it sees from any other subsets so like omnidirectional inference um or omnidirectional prediction um whereas an llm is just you see everything in the context window and then it it computes a very particular conditional probability which is given all the last thousands of things what is the very probabilities for all the all the the next token yeah um but it would be weird for a large language model to say you know um you know the quick brown fox blank blank the lazy dog um and filling in the middle yeah um versus do the next token if it's if it's doing just forward it can learn how to do that stuff in this emergent level of in context learning but natively it's just predicting the next token what if the cortex is just natively made so that it can you know any area of cortex can predict any pattern in any subset of its inputs given any other missing subsets um that is a little bit more like quote-unquote probabilistic ai um i think a lot of things i'm saying by the way are extremely similar to like what jan lecun would say yeah um he's really interested in these energy-based models um and something like that is like the joint distribution of all the variables, what is the likelihood or unlikelihood of just any combination of variables? And if I clamp some of them, I say, well, definitely these variables are in these states, then I can compute with probabilistic sampling, for example, I can compute, okay, conditioned on these being set in this state, what are, and these could be any arbitrary subset of variables in the model can i predict what any other subset is going to do and sample from any other subset given clamping this subset and i could choose a totally different subset and sample from that subset so it's omnidirectional inference and so you know that could be there's some parts of cortex that might be like association areas of cortex that may you know predict vision from audition yeah there might be areas that predict things that the more innate part of the brain is going to do because remember this whole thing is basically riding on top of the sort of a lizard brain and lizard body if you will um and that thing is a thing that's worth predicting too so you're not just predicting do i see this or do i see that but is this muscle about to tense am i about to have a reflex where i laugh you know is my heart rate about to go up um am i about to activate this instinctive behavior based on my higher level understanding of like i can match uh somebody has told me there's a spider on my back to this lizard part that would activate if i was like literally seeing a spider in front of me and you you learn to associate the two so that even just from somebody hearing you say there's a spider on your back yeah let's well let's come back to this and this this is partly having to do with with steve bern's theories which i'm recently obsessed about but yeah but on your podcast with ilia um he said look i'm not aware of any any good theory of how evolution encodes high-level desires or intentions. I think this is very connected to all of these questions about the loss functions and the cost functions that the brain would use. And it's a really profound question, right? Let's say that I am embarrassed for saying the wrong thing on your podcast because I'm imagining that Young Lacuna is listening He says, that's not my theory. You describe energy-based models really badly. That's going to activate in me innate embarrassment and shame, and I'm going to want to go hide and whatever. And that's going to activate these innate reflexes. And that's important because I might otherwise get killed by Yann LeCun's marauding army of other… differentiated research is coming for you, Adam. And so it's important that I have that instinctual response. But of course, evolution has never seen Jan LeCun or known about energy-based models or known what an important scientist or a podcast is. And so somehow the brain has to encode this desire to not piss off really important people in the tribe or something like this in a very robust way without knowing in advance all the things that the learning subsystem, okay, of the brain, the part that is learning, cortex and other parts, the cortex is going to learn this world model. It's going to include things like Jan LeCun and podcasts. And evolution has to make sure that those neurons, whatever the Jan LeCun being upset with me neurons, get properly wired up to the shame response or this part of the reward function um and this is important right because if we're going to be able to seek status in the tribe or learn from knowledgeable people as you said or things like that exchange knowledge and skills with friends but not with enemies i mean we have to learn all this stuff so it has to be able to robustly wire these learned features of the world um learn parts of the world model up to uh these innate reward functions and then actually use that to then learn more right because next time i'm not going to try to piss off young lacuna if he emails me that i got this wrong um and so uh we're going to do further learning based on that so in constructing the reward function it has to use a learned information but how can evolution evolution didn't know about yon lacun so how could how can it how can it do that and so uh the basic idea um that steve burns is proposing is that well part of the cortex or other areas like the amygdala that learn um what they're doing is they're modeling the steering subsystem. The steering subsystem is the part with these more innately programmed responses and the innate programming of these series of reward functions, cost functions, bootstrapping functions that exist. So there are parts of the amygdala, for example, that are able to monitor what those parts do and predict what those parts do. So how do you find the neurons that are important for social status? Well, you have some innate heuristics of social status, for example, or you have some innate heuristics of friendliness that the steering subsystem can use. And the steering subsystem actually has its own sensory system, which is kind of crazy. So we think of vision as being something that the cortex does. But there's also a steering subsystem, subcortical visual system called the superior colliculus with innate ability to detect faces, for example, or threats. So there's a visual system that has innate heuristics and that the steering subsystem has its own responses. So there'll be part of the amygdala or part of the cortex that is learning to predict those responses. And so what are the neurons that matter in the cortex for social status or for friendship? Well, they're the ones that predicts those innate heuristics for friendship, right? So you train a predictor in the cortex and you say, which neurons are part of the predictor uh those are the ones that are now it's now you've actually managed to wire it up yeah this is fascinating um i feel like i still don't understand i understand how the cortex could learn how this primitive part of the brain would respond to um so it can obviously it has these labels on here's literally a picture of a spider and this is bad like be scared of this right and then the cortex learns that this is bad because the innate part tells it that but then it has to generalize to okay the spider's on my back yes and somebody's telling me the spider's on your back that's also bad yes but it never got supervision on that right so how does it well it's because the learning subsystem um is a powerful learning algorithm that does have generalization that is capable of generalization so the steering subsystem these are the innate responses so you're going to have some, let's say, built into your steering subsystem, these lower brain areas, hypothalamus, brainstem, et cetera. And again, they include, they have their own primitive sensory systems. So there may be an innate response. If I see something that's kind of moving fast toward my body that I didn't previously see was there and is kind of small and dark and high contrast, that might be an insect kind of skittering onto my body. um i am going to like flinch right um and so there are these innate responses and so there's going to be some group of neurons let's say in the hypothalamus that is that i am flinching yeah uh or i just flinched right right they're the i just flinched neurons in the hypothalamus um so when you flinch first of all that a negative contribution to the reward function you didn't want that to happen perhaps um but that's only happened that's a reward function then that is it doesn't have any generalization in it so i'm going to avoid that exact situation of the thing skittering toward me um and maybe i'm going to avoid some actions that lead to the thing skittering uh so that's that's something a generalization you can get what steve calls it is downstream of the reward function um so i'm going to avoid the situation where the spider was skittering toward me um but you're also going to do something else so there's going to be like a part of your amygdala say that is saying okay um a few you know a few milliseconds you know hundreds hundreds of milliseconds or seconds earlier um could i have predicted that flinching response it's going to be it's going to be a group of neurons that is essentially a classifier of am i about to flinch um and i'm going to have classifiers for that for every important steering subsystem variable that evolution needs to take care of am i about to flinch am i talking to a friend should i laugh now is the friend high status whatever variables the hypothalamus brainstem contain? Um, am I about to taste salt? Um, so that's going to have, uh, all these variables and for each one is going to have a predictor. It's going to train that predictor. Now the predictor that it trains, that can have some generalization. And the reason it can have some generalizations because it just has a totally different input. So it's input data might be things like the word spider, right? But the word spider can activate in all sorts of situations that lead to the world word spider activating in your world model. So, you know, if you have a complex world model with really complex features, that inherently gives you some generalization It not just the thing skittering toward me It even the word spider or the concept of spider is going to cause that to trigger And this predictor can learn that So whatever spider neurons are in my world model which could even be a book about spiders or somewhere a room where there are spiders or whatever that is The amount of heebie-jeebies that this conversation is eliciting in the audience is like... So now I'm activating your steering subsystem. Your steering subsystem, spider hypothalamus, a subgroup of neurons of skittering insects, are activating based on these very abstract concepts in the conversation. If you keep going, I'm going to put in a trigger warning. That's because you learned this. And the cortex inherently has the ability to generalize because it's just predicting based on these very abstract variables and all these integrated information that it has. whereas the steering system only can use whatever the superior clikless and a few other sensors can spit out so by the way it's remarkable that the person who's made this this connection between different pieces of neuroscience steven burns like former physicist yeah has for the last few years has been trying to synthesize he's an ai safety researcher he's just synthesizing this comes back to the academic incentives right i think that this is it's this is a little bit hard to say what's the exact next experiment how am i going to publish a paper on this how am i going to train my grad student do this very very speculative but there's a lot in the neuroscience literature and steven has been able to pull this together and i think that steve has an answer to elia's question essentially which is which is how does the brain ultimately code for these higher level desires and link them up to the more primitive rewards yeah very naive question but why can't we achieve this omnidirectional inference by just training the model to not just map from a token to next token but remove the masks right in the training so it maps every token to every token or come up with more labels between video and audio and text so that it is forced to map one to each one. I mean, that may be that may be the way. So it's not clear to me. Some people think that there's sort of a different way that it does probabilistic inference or different learning algorithm that isn't backprop. There might be like other ways of learning energy-based models or other things like that that you can imagine, but that's involved in being able to do this and that the brain has that. But I think there's a version of it where what the brain does is like crappy versions of backprop to learn to predict through a few layers. And that, yeah, it's kind of like a multimodal foundation model. Yeah, so maybe the cortex is just kind of like certain kinds of foundation models. LLMs are maybe just predicting the next token, but, you know, vision models maybe are trained in learning to fill in the blanks or reconstruct different pieces or combinations. But I think that it does it in an extremely flexible way. So it's, you know, if you train a model to just fill in this blank at the center, okay, that's great. But what if you didn't train it to fill in this other blank over to the left, then it doesn't know how to do that. It's not part of its like repertoire of predictions that are like amortized into the network. Whereas with a really powerful inference system, you could choose at test time, you know, what is the, you know, the subset of variables it needs to infer and which ones are clamped. Okay, two sub questions. One, it makes you wonder whether the thing that is lacking in artificial neural networks is less about the reward function and more about the encoder or the embedding, which, like, maybe the issue is that you're not representing video and audio and text in the right latent abstraction such that they could intermingle and um conflict maybe this is also related to why llmc bad at drawing connections between different ideas like it's like are the ideas represented at a level of generality at which you could which you could notice well the problem is these questions are all co-mingled so if we don't know if it's doing a back prop like learning and we don't know if it's doing energy-based models and we don't know how these areas are even connected in the first place it's like very hard to like really get to the ground truth of this but yeah it's possible i mean i think that people have done some work my friend joel de pello actually did something some years ago where um i think he put a model i think it was a model of v1 um of sort of specifically how the the early visual cortex represents images and put that as like an input into like a conf net and that like improves something so it could be it could be like differences. The retina is also doing, you know, motion detection and certain things are kind of getting filtered out. So there may be some pre-processing of the sensory data. There may be some clever combinations of which modalities are predicting which or so on that lead to better representation. There may be much more clever things than that. Some people certainly do think that there's inductive biases built in the architecture that will shape the representations, you know, differently or that there are clever things that you can do. So Astera, which is the the same organization that employs Steve Behrens just launched this neuroscience project based on Doris Soh's work. And she has some ideas about how you can build vision systems that basically require less training. They put in, they in build into the assumptions of the design of the architecture that things like objects are bounded by surfaces. And, you know, surfaces have certain types of shapes and relationships of how they occlude each other and stuff like that. So it may be possible to build more assumptions into the network. Evolution may have also put some changes of architecture. It's just I think that also the cost functions and so on may be a key thing that it does. So Andy Jones has this amazing 2021 paper where he uses AlphaZero to show that you can trade off test time compute and training compute. And while that might seem obvious now, this was three years before people were talking about inference scaling. So this got me thinking, is there an experiment you could run today, even if it's a toy experiment, which would help you anticipate the next scaling paradigm? One idea I had was to see if there was anything to multi-agent scaling. Basically, if you have a fixed budget of training compute, are you going to get the smartest agent by dumping all of it into training one single agent, or by sliding that compute up amongst a bunch of models, resulting in a diversity of strategies that get to play off each other? I didn't know how to turn this question into a concrete experiment, though, So I started brainstorming with Gemini 3 Pro in the Gemini app. Gemini helped me think through a bunch of different judgment calls. For example, how do you turn the training loop from self-play to this kind of co-evolutionary league training? How do you initialize and then maintain diversity amongst different AlphaZero agents? How do you even split up the compute between these agents in the first place? I found this clean implementation of AlphaGo Zero, which I then forked and opened up in Antigravity, which is Google's agent first IDE. The code was originally written in 2017, and it was meant to be trained on a single GPU of that time. But I needed to train multiple whole separate populations of AlphaZero agents, so I needed to speed things up. I rented a beefcake of a GPU node, but I needed to refactor the whole implementation to take advantage of all this scale and parallelism. Gemini suggested two different ways to parallelize self-play. One which would involve higher GPU context switching, and the other would involve higher communication overhead. I wasn't sure which one to pick, so I just asked Gemini. And not only did it get both of them working in minutes, but it autonomously created and then ran a benchmark to see which one was best. It would have taken me a week to implement either one of these options. Think about how many judgment calls a software engineer working on an actually complex project has to make. If they have to spend weeks architecting some optimization or feature before they can see whether it will work out, they will just get to test out so many fewer ideas. Anyways, with all this help from Gemini, I actually ran the experiment and got some results. Now, please keep in mind that I'm running this experiment on an anemic budget of compute, and it's very possible I made some mistakes in implementation. But it looks like there can be gains from splitting up a fixed budget of trading compute amongst multiple agents rather than just dumping it all into one. Just to reiterate how surprising this is, the best agent in the population of 16 is getting 1 16th the amount of trading compute as the agent trained on self-play alone. And yet it still outperforms the agent that is hogging all of the compute. The whole process of ViveCoding this experiment with Gemini was really absorbing and fun. It gave me the chance to actually understand how AlphaZero works and to understand the design space around decisions about the hyperparameters and how search is done and how you do this kind of co-evolutionary training rather than getting bogged down in my very novice abilities as an engineer. Go to gemini.google.com to try it out. I want to talk about this idea that you just glanced off of, which was amortized inference. And maybe I should try to explain what I think it means, because I think it's probably wrong, and this will help you correct me. It's been a few years for me, too. Okay. right now the way the models work is you have an input it maps it to an output and this is amortizing a process that the the real process which we think is like what intelligence is which is like you have some prior over how the world could be like what are the causes that make the world the way that it is and then the way when you see some observation you should be like okay here's all the ways the world could be um this cause explains what's happening best now this like doing this calculation over every possible cause is computationally intractable so then you just have to sample like oh here's a potential cause does this explain this observation uh no forget it let's let's keep sampling and then eventually you get the cause the cause then the cause explains the observation and then this becomes your posterior that's actually pretty good i think of sort of yeah so yeah this bayesian inference like in general is like of this very intractable thing right it the algorithms that we have for doing that tend to require taking a lot of samples monte carlo methods taking a lot of samples yeah and taking samples takes time i mean this is like the original like baltimore machines and stuff we're using yeah techniques like this um and still it's used with probabilistic programming other types of methods often and so uh yeah so the bayesian inference problem which is like basically the problem of like perception like given some model of the world and given some data like how should i update my what what are the like the the variables you know missing variables in my in my internal model and i guess the idea is that neural networks are hopefully um obviously there's mechanistically the neural network is not starting with like here is my model of the world and i'm going to try to explain this data but the hope is that instead of starting with um hey does this cause explanation no here did this cause explain this explanation yes what you do is just like observation what's the most what's the cause that we the neural net thinks is the best observation to cause so the feed forward like goes observation to cause observation to cause to then output that yes you don't have to you don't have to evaluate all these energy values or whatever and sample around to make them higher and lower um you just say um approximately that process would result in this being the top one or something like that yeah one way to think about it might be that test time compute inference time compute is actually doing this sampling again because you literally read its shade of thought it's like actually doing this toy example we're talking about where it's like oh can i sell this problem by doing x yeah i need a different approach and this raises the question i mean over time it is the case that the capabilities which were uh which required inference time compute to elicit get distilled into the model so you're amortizing the thing which previously So you needed to do these like rollouts, like Monte Carlo rollouts to to figure out. And so in general, maybe there's this principle of digital minds, which can be copied, have different tradeoffs, which are relevant than biological minds, which cannot. And so in general, it should make sense to amortize more things because you can literally copy the amortization, right? Or copy the things that you have sort of like built in. yeah um and it's maybe this is a tangential question where it might be interesting to speculate about in the future as these things become more intelligent and the way we train them becomes more economically rational what will make sense to amortize into these minds which evolution did not think it was worth amortizing into biological minds they do you have to retrain right i mean first of all i think the probabilistic ai people would be like of course you need test time compute because this inference problem is really hard and the only ways we know how to do it involve lots of test time compute otherwise it's just a crappy approximation that's never gonna like you have to do infinite data or something to like make this so i think that some of the probabilistic people will be like no it's like inherently probabilistic and like amortizing it in this way like just doesn't make sense and so and they might then also point to the brain and say okay well the brain the neurons are kind of stochastic and they're sampling and they're doing doing things and so maybe the brain actually is doing more like the non-amortized inference the real inference um but it's also kind of strange how perception can work in just like milliseconds or whatever it doesn't seem like it uses that much sampling so it's also clearly also doing some kind of um baking things into into like approximate forward passes or something like that to do this and yeah so in the future you know i don't know i mean i think is it already a trend to some degree that things that are people were having to use test time compute for getting like used to train back the the base model right yeah yeah that so now it can do it in one pass right yeah so i mean i think yeah you know maybe evolution did or didn do that uh i think evolution still has to pass everything through the genome right to build the network so and the environment in which humans are living is very dynamic right and so maybe that's if we believe this is true that that there's a learning subsystem per steve burns and a steering subsystem the learning subsystem doesn't have a lot of like pre-initialization or pre-training um it has a certain architecture but then within lifetime it learns um then evolution didn't you know actually like amortize that much into that network right it amortized it instead into a set of innate behaviors in a set of these bootstrapping cost functions or ways of building up very particular reward signals yeah yeah this framework helps explain this um mystery that people have pointed out and i've asked a few guests about which is if you want to analogize evolution to pre-training well how do you explain the fact that so little information is conveyed through the genome so three gigabytes is the size of the total human genome obviously a small fraction of that is actually relevant to coding at the brain yeah um and if previously people made this analogy that actually uh evolution has found the hyper parameters of the model the the numbers which tell you how many layers should there be the architecture basically right like how should things be wired together but if a big part of the story that increases sample efficiency aids learning generally makes systems more performant is the reward function is the loss function yeah and if evolution found those loss functions which aid learning then it actually kind of makes sense how so you can like build an intelligence with so little information because like the reward function are you like right in python right the reward function is like literally a line yeah and so you just like have like a thousand lines like this and that doesn't take up that much space yes and it also gets to do this generalization thing with the thing the thing i was describing where we were talking with about the spider right of where it learns that just the word spider you know triggers the spider you know reflex or whatever um it gets to exploit that too right so it gets to build a reward function that actually has a bunch of generalization in it just by specifying these innate spider stuff and the thought assessors as steve calls them that do the learning um so that's like a potentially a really compact solution to building up these more complex reward functions too that you need. So it doesn't have to anticipate everything about the future of the reward function, just anticipate what variables are relevant, what are heuristics for like finding what those variables are. And then, yeah, so then it has to have like a very compact specification for like the learning algorithm and basic architecture of the learning subsystem. And then it has to specify all this Python code of like all the stuff about the spiders and all the stuff about friends and all the stuff about your mother and all the stuff about mating and social groups and joint eye contact. It has to specify all that stuff. And so is this really true? And so I think that there is some evidence for it. So Fei Chen and Evan McCosco and various other researchers who have been doing these single cell atlases. So one of the things that neuroscience technology or scaling up neuroscience technology, again, this is kind of like my one of my obsessions um has done uh through through um the brain initiative the big you know neuroscience funding programs they've basically gone through different areas especially the mouse brain and map like where are the different cell types um how many different types of cells are there in different areas of cortex are they the same across different areas and then you then you look at these subcortical regions which are more like the like steering subsystem or reward function generating regions how many different types of cells do they have and which neurons types do they have we don't know how they're all connected and exactly what they do or what the circuits are what they mean but you can just like quantify like how many different kinds of cells are there um with sequencing the rna and there are a lot more weird and diverse and bespoke cell types in the steering subsystem basically than there are in the learning subsystem Like the cortical cell types, there's enough to build. It seems like there's enough to build a learning algorithm up there and specify some hyperparameters. And in the in the steering subsystem, there's like a gazillion, you know, thousands of really weird cells, which might be like the one for the spider flinch reflex and the one for I'm about to taste salt. Why would each reward function need a different cell type? Well, so this is where you get innately wired circuits. Right. So in the learning algorithm part in this in the learning learning subsystem. um you set up specify the initial architecture you specify a learning algorithm is all all the all the all the juices is happening through plasticity of the synapses changes of the synapses within that big network but it's kind of like a relatively repeating architecture um how it's initialized it's just like um the amount of python code needed to make you know an eight-layer transformer is not that different from one to make a three-layer transformer right you're just replicating yeah whereas all this python code for the reward function you know if superior click list sees something that's skittering and you know you're feeling goosebumps on your skin or whatever then trigger spider reflex that's just a bunch of like bespoke species specific uh situation specific crap that no the cortex doesn't know about spiders it just knows about layers and right and learning the only way to have this like write this reward function yeah is to have a special cell type yeah yeah well i think so i think you either have to have the special cell types or you have to somehow otherwise get special wiring rules that evolution can say this neuron needs to wire to this neuron without any learning. And the way that that is most likely to happen, I think, is that those cells express like different receptors and proteins that say, OK, when this one comes in contact with this one, let's form a synapse. So it's genetic wiring. Yeah. And those need cell types to do it. Yeah. I'm sure this would make a lot more sense if new 101 neuroscience but like it seems like there's still a lot of complexity or generality rather in the steering system so in the steering system has its own visual uh system that's separate from the visual cortex yeah different features still need to plug into that vision system in the so like the spider thing needs to plug into it and also the um the uh love thing needs to plug into it etc etc yes so it seems complicated like no it's still complicated that's that's all the more reason why a lot of the genomic you know real estate in the genome and in terms of these different cell types and so on would go into wiring up the steering subsystem you can be pre-wiring it can we tell how much of the genome is like clearly working so i guess you could tell how many are relevant to the producing the rna that manifest or the epigenetics that manifest in different cell types in the brain right yeah this is what the cell types helps you get at it i don't think i don't think it's exactly like oh this percent of the genome is doing this but you could say okay in these all these steering substances and sub types you know how many different genes are involved in sort of specifying which is which and how they wire um and how much genomic real estate do those genes take up um versus the ones that specify, you know, visual cortex versus auditory cortex, you kind of just reusing the same genes to do the same thing twice. Whereas the spider reflex hooking up, yes, you're right, they have to build a vision system, they have to build some auditory systems and touch systems and navigation type systems. So, you know, even feeding into the hippocampus and stuff like that, there's head direction cells, even the fly brain, it has innate circuits that, you know, figure out orientation and help it navigate in the world and it uses vision figure as optical flow of how it's flying and you know uh how is it how is its flight related to the wind direction it has all these innate stuff that i think we in the mammal brain we would all put that and lump that into the steering subsystem so there's a lot of work so all the genes basically that go into specifying all the things a fly has to do we're going to have stuff like that too just all in the steering subsystem but do we do we have some estimate of like here's how many nucleotides here are many megabases it takes to i i don't know i mean but but um i mean i think you might be able to talk to biologists about this you know to some degree because you can say well we just have a ton in common i mean we have a lot in common with yeast from a genes perspective yeast is still used as a model yeah for you know some amount of drug development and stuff like that in biology and so so much of the genome is just going towards you have a cell at all it can recycle waste it can get energy it can replicate um and then it then you see what we have in common with a mouse and so we do know at some level that you know the difference is us in a chimpanzee or something and that includes the social instincts and the more advanced you know differences in cortex and so on um it's it's a it's a tiny number of genes that go into these additional amount of making the eight-layer transformer instead of the six-layer transformer or tweaking that reward function this would help explain why the hominid brain exploded inside so fast which is presumably like tell me this is correct but under the story we um social learning or some other thing increased the ability to learn from the environment like increase our sample efficiency right instead of having to go and kill the boar yourself and figure out like how to do that you can just be like uh the elder told me this how you make a spear and then now it increases the incentive to have a bigger cortex which can like learn these things yes and that can be done with a relatively few genes because it's really it's really replicating what the mouse already has is making more of it it's maybe not exactly the same and there may be tweaks but it's like from a perspective you don't have to reinvent right all this stuff right so then um how far back in the history of the evolution of the brain does the cortex go back it is the idea that like the cortex has always figured out this omnidirectional inference thing that's been a solve problem for a long time and then the big unlock with primase is this we got the reward function which increased the returns to having omnidirectional inference or is this good question is the cortex is the omnidirectional inference also something that took a while to unlock i'm not sure that there's agreement about that i think there might be specific questions about language you know are there tweaks to be you know whether that's your auditory and memory some combination auditory memory regions there may also be like um macro wiring right of like you need to wire auditory regions into memory regions or something like that and into some of these social instincts to get i see language for example to happen so there might be but that might be also a small number of gene changes yeah to be able to say oh i just need from my temporal lobe over here going over to the auditory cortex something right and there is some evidence for the you know the brocca's area warnicki's area they're connected with these hippocampus and so on and so prefrontal cortex so there's like some small number of genes maybe for like enabling humans to really properly do language that could be a big one but yeah i mean i think that is it that something changed about the cortex and it became possible to do these things whereas that potential was already there but there wasn't the incentive to expand that capability and then use it wired it to these social instincts and use it more um i mean i would lean somewhat toward the latter i mean i think a mouse i has a lot of similarity in terms of cortex as a human right although there's that uh the cesane hercule hussle work yeah the um the the number of neurons scales better with weight with primate brains than it does with rodent brains right so yeah does that suggest that there actually was some improvement in the scalability of the cortex maybe maybe i'm not i'm not super deep on this there may there may have been yeah changes in architecture changes in the folding changes in neuron properties and stuff that somehow slightly tweak this but they're still a scaling that's right either way right um and so i was not saying there aren't something special about humans in the architecture of the learning subsystem at all um but yeah i mean i think it's pretty widely thought that this is expanded but then the question is okay well how does that how does that fit in also with the steering subsystem changes and the instincts that make use of this and allow you to bootstrap using this effectively um but i mean just to say a few other things i mean so even the fly brain has some amount of, for example, even very far back, I mean, I think you've read this great book, The Brief History of Intelligence, right? I think this is a really good book. Lots of AI researchers think this is a really good book, it seems like. Yeah, you have some amount of learning going back all the way to anything that has a brain, basically. You have something kind of like primitive reinforcement learning, at least, um going back at least to like vertebrates like imagine like a zebrafish it's like a um these kind of these other branches birds maybe kind of reinvented something kind of cortex-like but it doesn't have the six layers but they have something a little bit cortex-like um so that some of those things um after reptiles in some sense birds and mammals both kind of made us up somewhat cortex-like but differently organized thing but even a fly brain has like associative learning senders that actually do things that maybe look a little bit like this like thought assessor concept from from berns where there's like a specific dopamine signal to train specific subgroups of neurons in the fly mushroom body to associate different sensory information with am i going to get food now or am i going to get hurt now yeah tangent I remember reading in one blog post that Baron Millage wrote that the parts of the cortex which are associated with audio and vision, have scaled disproportionately between other primates and humans, whereas the parts associated, say, with odor have not. And I remember him saying something like, this is explained by that kind of data having worse scaling law properties. But I think the and maybe he meant this, but another interpretation of actually what's happening there is that these social reward functions that are built into the steering subsystem needed to make use. More of being able to see your elders and see what the visual cues are and hear what they're saying. yeah in order to make a sense of these cues which guide learning you needed to activate these um yeah activate the vision and audio more than i mean there's all this stuff i feel like it's come up in in your your shows before actually but like even like the design of the human eye where you have like the pupil and the white and everything like we are designed to be able to establish relationships based on joint eye contact and and maybe this came up in the sudden episode i can't remember. But yeah, we have to bootstrap to the point where we can detect eye contact and where we can communicate by language. And that's what the first couple of years of life are trying to do. Okay. I want to ask you about RL. So currently the way these LNs are trained, if they solve the unit test or solve a math problem, that whole trajectory, every token in that trajectory is up-weighted. And what's going on with humans? Are there different types of model based versus model free that are happening in different parts of the brain yeah i mean this is this is another one of these things i mean again all my answers to these questions any specific thing i say is all just kind of like directionally this we can kind of explore around this i find this interesting maybe i feel like the literature points in these directions in some very broad way what i actually want to do is like go and map the entire mouse brain and like figure this out comprehensively and like make neuroscience a ground truth science so i don't know basically um but uh but yeah i mean there so first of all i mean i think with ilia on the podcast i mean he was like it's weird that you don't use value functions right you use like the most dumbest form of rl basically and of course there are these people are incredibly smart and they're optimizing for how to do it on gpus and it's really incredible what they're achieving but like conceptually it's a really dumb form of rl even compared to like what was being done in like 10 years ago right like even uh you know the atari game playing stuff right was using like q learning which is basically like it's a kind of temporal difference learning right and the temporal difference learning basically means you have some kind of a value function of like what action i choose now doesn't just tell me literally what happens immediately after this it tells me like what is the long-run consequence of that for my expected you know total reward or something like that um and so you would have value functions like the fact that we don't have like value functions at all is like in the llms is like it's crazy i mean i think i think because ilia said it i can say it i know you know one one hundredth of what he does about ai but like it's kind of crazy that this is working yeah um but uh yeah i mean in terms of the brain um well so i think there are some parts of the brain that are thought to do something that's very much like model free rl that's or parts of the basal ganglia um sort of striatum and basal ganglia they have like a certain finite like it is thought that they have a certain like finite relatively small action space and the types of actions they could take first of all might be like tell the spinal cord or tell the brainstem and spinal cord to do this motor action yes no or it might be more complicated cognitive type actions like tell the thalamus to allow this part of the cortex to talk to this other part or release the memory that's in the hippocampus and start a new one or something right but there's some finite set of actions that kind of come out of the basal ganglia and that it's just a very simple rl so there are probably parts of other brains in our brain that are just like doing very simple naive type rl algorithms um layer one thing on top of that is that some of the major work in neuroscience like peter diane's work and a bunch bunch of work that is part of why i think deep mind did the temporal difference learning stuff in the first place um is they were very interested in neuroscience um and there's a lot of neuroscience evidence that the dopamine is giving this reward prediction error signal um rather than just reward yes no you know a gazillion time steps in the future it's a prediction error um and that's consistent with like learning these value functions um so there's that and then there's maybe like higher order stuff. So we have these cortex making this world model. Well, one of the things the cortex world model can contain is a model of when you do and don't get rewards, right? Again, it's predicting what the steering subsystem will do. It could be predicting what the basal ganglia will do. And so you have a model in your cortex that has more generalization and more concepts and all this stuff that says, okay, these types of plans, these types of actions will lead in these types of circumstances to reward. So I have a model of my reward. Some people also think that you can go the other way. And so this is part of the inference picture. There's this idea of RL as inference. You could say, well, conditional on my having a high reward, sample a plan that I would have had to get there. That's inference of the plan part from the reward part. I'm clamping the reward as high and inferring the plan sampling from plans that could lead to that. And so if you have this very general cortical thing it can just do if you have this like general very general model based system and the model among other things includes plans and rewards then you just get it for free basically so like in neural network parlance there's a value head associated to the the omnidirectional inference that's happening yes yeah there's or there's a value input um yeah oh okay yeah and it can predict one of one of the one of the almost sensory variables it can predict is is what rewards it's going to get yeah but speaking of this thing about amortizing things um yeah obviously value is like amortized rollouts of looking up reward yeah something like that yeah yeah it's like a statistical average or prediction of it yeah right tangential thought uh you know Joe Henrik and others have this idea that the way human societies have learned to do things is just like, how do you figure out that, you know, this kind of bean, which actually just almost always poisons you, is edible if you do this 10 step incredibly complicated process, any one of which, if you fail at, the bean will be poisonous. how do you figure out how to hunt this seal in this particular way with this like particular weapon at this particular time of the year etc um there's no way but uh just like trying shit over generations and it's actually this is actually very much like model free are all happening at like a civilizational level um no not exactly because evolution is the simplest algorithm in some sense right and if we believe that all this can come from evolution like the outer loop can be like extremely not foresighted and yeah right um that that's interesting just like uh hierarchies of evolution model for you culture uh evolution model for you so what does that tell you maybe the simple algorithms can just get you anything if you do it enough right yeah yeah so but yeah so you you have like maybe this yeah evolution model free basal ganglia model free cortex model based culture uh model free potentially um i mean there's like you pay attention to your elders or whatever so there's maybe this like group selection or whatever of these things is like more model free yeah but now i think culture well it stores some of the model yeah right so let's say you want to train an agent to help you with something like processing loan applications training an agent to do this requires more than just giving the model access to the right tools, things like browsers and PDF readers and risk models. There's this level of tacit knowledge that you can only get by actually working in an industry. For example, certain loan applications will pass every single automated check despite being super risky. Every single individual part of the application might look safe, but experienced underwriters know to compare across documents to find subtle patterns that signal risk. Libelbox has experts like this in whatever domain you're focused on, and they will set up highly realistic training environments that include whatever subtle nuances and watch outs you need to look out for. Beyond just building the environment itself, Labelbox provides all the scaffolding you need to capture training data for your agent. They give you the tools to grade agent performance and capture the video of each session and to reset the entire environment to a clean state between every episode. So whatever domain you're working in, Labelbox can help you train reliable real-world agents. Learn more at labelbox.com slash thwarkash. So stepping back, how is it a disadvantage or an advantage for humans that we get to use biological hardware in comparison to computers as they exist now? So what I mean by this question is like if there's the algorithm, would the algorithm just qualitatively perform much worse or much better if inscribed in the hardware of today? And the reason to think it might like here's what I mean. And like, you know, obviously the brain has had to make a bunch of tradeoffs which are not relevant to competing hardware. It has to be much more energetically efficient. Maybe as a result, it has to run on slower speeds so that there can be a smaller voltage gap. And so the brain runs at 200 hertz and has to like run on 20 watts. On the other hand, you know, with like robotics, we've clearly experienced that fingers are way more nimble than we can make motors so far. as maybe there's something in the brain that is the equivalent of like cognitive uh dexterity which is like maybe due to the fact that we can do unstructured sparsity we can co-locate the memory in the compute yes where does this all that are you like fuck we would be so smarter if we didn't have to deal with these brains or are you like oh i mean i think in the end we will get the best of both worlds right somehow right i think i think an obvious downside of the brain is it cannot be copied yeah you don't have you know external read write access to every neuron in synapse, whereas you do. I can just edit something in the weight matrix, you know, in Python or whatever, you know, and load that up and copy that in principle, right? So the fact that it can't be copied and kind of random accessed is, like, very annoying. But otherwise, maybe these are, it, like, has a lot of advantages. So it also tells you that you want to, like, somehow do the co-design of the algorithm and it maybe even doesn't change it that much from all of what we discussed, but you want to somehow do this co-design. So, yeah, how do you do it with really slow, low voltage switches? That's going to be really important for the energy consumption. The co-locating memory and compute. So, like, I think that probably just like hardware companies will try to co-locate memory and compute. They will try to use lower voltages, allow some stochastic stuff. There are some people that think that this, like, all this probabilistic stuff that we were talking about, oh, oh, it's actually energy-based models and so on. It is doing lots of sampling. it's not just amortizing everything that the neurons are also very natural for that because they're naturally stochastic and so you don't have to do a random number generator and a bunch of python code basically to generate a sample the neuron just generates samples and it can tune what the different probabilities are yeah and so and like learn learn those tunings and so it could be that it's very co-designed with like some kind of inference method or something yeah it'd be hilarious i mean the message of this interview is like you know all these people that folks make fun of on twitter you know yon lakoon and beth jazos and whatever they're like no like well yeah maybe i don't know that is actually that is actually one read of me granted you know i i haven't really worked on ai at all since loms you know took off so i'm just like out of the loop but um i i'm surprised and i i think it's amazing how the scaling is is working and everything but yeah, I think Jan LeCun and Beth Jezos are kind of onto something about the probabilistic models, or at least possibly. And in fact, that's what all the neuroscientists and all the AI people thought until 2021 or something, right? So there's a bunch of cellular stuff happening in the brain that is not just about neuron-to-neuron synaptic connections. How much of that is functionally doing more work than the synapses themselves are doing versus it's just a bunch of kludge that you have to do in order to make the synaptic thing work so the way you need to you know with a digital mind you can nudge the synapse sorry the parameter extremely easily but with a cell to modulate a synapse according to the gradient signal it just takes all of this crazy machinery so like is it actually doing more than it takes extremely little code to do so i don't know but i'm i'm not a believer in the like radical like oh actually memory is not synapses mostly or like learning is mostly genetic changes or something like that i think it would just make a lot of sense i think you put it really well for it to be more like the second thing you said like let's say you want to do weight normalization across all the weights coming out of your neuron right or into your neuron well you probably have to go like",
  "rawResponses": [
    {
      "task": "transcribe",
      "language": "English",
      "duration": 3301.618,
      "text": " The big million dollar question that I have that I've been trying to get the answer to through all these interviews with the researchers, how does the brain do it? Right. Like we're throwing way more data at these LLMs and they still have a small fraction of the total capabilities that a human does. So what's going on? Yeah, I mean, this might be the quadrillion dollar question or something like that. It's it's it's arguably you could make an argument. This is the most important question in science. I don't claim to know the answer. I also don't really think that the answer will necessarily come even from a lot of smart people thinking about it as much as they are. My overall meta-level take is that we have to empower the field of neuroscience to just make neuroscience a more powerful field technologically and otherwise to actually be able to crack a question like this. But maybe the the way that we would think about this now with modern AI, neural nets, deep learning, is that there's sort of these these certain key components of that. There's the architecture. There's maybe hyper parameters of the architecture. How many layers do you have or sort of properties of that architecture? There is the learning algorithm itself. How do you train it? You know, back prop gradient descent. Is it something else? there is how is it initialized okay so if we take the learning part of the system it still may have some initialization of of the weights um and then there are also cost functions there's like what is it being trained to do what's the reward signal what are the loss functions supervision signals my personal hunch within that framework is that the the field has neglected uh the role of this very specific loss functions very specific cost functions And machine learning tends to like mathematically simple loss functions, right? Predict the next token, you know, cross entropy, these simple kind of computer scientists loss functions. I think evolution may have built a lot of complexity into the loss functions. Actually, many different loss functions were different areas turned on at different stages of development. a lot of python code basically uh generating a specific curriculum for what different parts of the brain need to learn because evolution has seen many times what was successful and unsuccessful and evolution could encode the knowledge of the learning curriculum so so in the in the machine learning framework maybe we can come back and we can talk about yeah where do the loss functions of the brain come from can that can loss different loss functions lead to different efficiency of learning you know people say like the cortex has got the universal human learning algorithm the special science that humans have what's up this is a huge question uh and we don't know i've seen models where what the cortex uh you know the cortex has typically this like six layered structure layers in a slightly different sense than layers of a neural net it's like any one location in the cortex has six physical layers of tissue as you go in layers of the sheet and then those areas then connect to each other and that's more like the layers of a network um i've seen versions of that where what you're trying to explain is actually just how does it approximate backprop and what is the cost function for that what is the network being asked you to if you sort of are trying to say it's something like backprop is it doing backprop on next token prediction is it doing backprop on classifying images or what is it doing um and uh no one no one knows um but i think i think one one thought about it one possibility about it is that um it's just this incredibly general prediction engine so so any one area of cortex is just trying to predict any basically can it learn to predict any subset of all the variables it sees from any other subsets so like omnidirectional inference um or omnidirectional prediction um whereas an llm is just you see everything in the context window and then it it computes a very particular conditional probability which is given all the last thousands of things what is the very probabilities for all the all the the next token yeah um but it would be weird for a large language model to say you know um you know the quick brown fox blank blank the lazy dog um and filling in the middle yeah um versus do the next token if it's if it's doing just forward it can learn how to do that stuff in this emergent level of in context learning but natively it's just predicting the next token what if the cortex is just natively made so that it can you know any area of cortex can predict any pattern in any subset of its inputs given any other missing subsets um that is a little bit more like quote-unquote probabilistic ai um i think a lot of things i'm saying by the way are extremely similar to like what jan lecun would say yeah um he's really interested in these energy-based models um and something like that is like the joint distribution of all the variables, what is the likelihood or unlikelihood of just any combination of variables? And if I clamp some of them, I say, well, definitely these variables are in these states, then I can compute with probabilistic sampling, for example, I can compute, okay, conditioned on these being set in this state, what are, and these could be any arbitrary subset of variables in the model can i predict what any other subset is going to do and sample from any other subset given clamping this subset and i could choose a totally different subset and sample from that subset so it's omnidirectional inference and so you know that could be there's some parts of cortex that might be like association areas of cortex that may you know predict vision from audition yeah there might be areas that predict things that the more innate part of the brain is going to do because remember this whole thing is basically riding on top of the sort of a lizard brain and lizard body if you will um and that thing is a thing that's worth predicting too so you're not just predicting do i see this or do i see that but is this muscle about to tense am i about to have a reflex where i laugh you know is my heart rate about to go up um am i about to activate this instinctive behavior based on my higher level understanding of like i can match uh somebody has told me there's a spider on my back to this lizard part that would activate if i was like literally seeing a spider in front of me and you you learn to associate the two so that even just from somebody hearing you say there's a spider on your back yeah let's well let's come back to this and this this is partly having to do with with steve bern's theories which i'm recently obsessed about but yeah but on your podcast with ilia um he said look i'm not aware of any any good theory of how evolution encodes high-level desires or intentions. I think this is very connected to all of these questions about the loss functions and the cost functions that the brain would use. And it's a really profound question, right? Let's say that I am embarrassed for saying the wrong thing on your podcast because I'm imagining that Young Lacuna is listening He says, that's not my theory. You describe energy-based models really badly. That's going to activate in me innate embarrassment and shame, and I'm going to want to go hide and whatever. And that's going to activate these innate reflexes. And that's important because I might otherwise get killed by Yann LeCun's marauding army of other… differentiated research is coming for you, Adam. And so it's important that I have that instinctual response. But of course, evolution has never seen Jan LeCun or known about energy-based models or known what an important scientist or a podcast is. And so somehow the brain has to encode this desire to not piss off really important people in the tribe or something like this in a very robust way without knowing in advance all the things that the learning subsystem, okay, of the brain, the part that is learning, cortex and other parts, the cortex is going to learn this world model. It's going to include things like Jan LeCun and podcasts. And evolution has to make sure that those neurons, whatever the Jan LeCun being upset with me neurons, get properly wired up to the shame response or this part of the reward function um and this is important right because if we're going to be able to seek status in the tribe or learn from knowledgeable people as you said or things like that exchange knowledge and skills with friends but not with enemies i mean we have to learn all this stuff so it has to be able to robustly wire these learned features of the world um learn parts of the world model up to uh these innate reward functions and then actually use that to then learn more right because next time i'm not going to try to piss off young lacuna if he emails me that i got this wrong um and so uh we're going to do further learning based on that so in constructing the reward function it has to use a learned information but how can evolution evolution didn't know about yon lacun so how could how can it how can it do that and so uh the basic idea um that steve burns is proposing is that well part of the cortex or other areas like the amygdala that learn um what they're doing is they're modeling the steering subsystem. The steering subsystem is the part with these more innately programmed responses and the innate programming of these series of reward functions, cost functions, bootstrapping functions that exist. So there are parts of the amygdala, for example, that are able to monitor what those parts do and predict what those parts do. So how do you find the neurons that are important for social status? Well, you have some innate heuristics of social status, for example, or you have some innate heuristics of friendliness that the steering subsystem can use. And the steering subsystem actually has its own sensory system, which is kind of crazy. So we think of vision as being something that the cortex does. But there's also a steering subsystem, subcortical visual system called the superior colliculus with innate ability to detect faces, for example, or threats. So there's a visual system that has innate heuristics and that the steering subsystem has its own responses. So there'll be part of the amygdala or part of the cortex that is learning to predict those responses. And so what are the neurons that matter in the cortex for social status or for friendship? Well, they're the ones that predicts those innate heuristics for friendship, right? So you train a predictor in the cortex and you say, which neurons are part of the predictor uh those are the ones that are now it's now you've actually managed to wire it up yeah this is fascinating um i feel like i still don't understand i understand how the cortex could learn how this primitive part of the brain would respond to um so it can obviously it has these labels on here's literally a picture of a spider and this is bad like be scared of this right and then the cortex learns that this is bad because the innate part tells it that but then it has to generalize to okay the spider's on my back yes and somebody's telling me the spider's on your back that's also bad yes but it never got supervision on that right so how does it well it's because the learning subsystem um is a powerful learning algorithm that does have generalization that is capable of generalization so the steering subsystem these are the innate responses so you're going to have some, let's say, built into your steering subsystem, these lower brain areas, hypothalamus, brainstem, et cetera. And again, they include, they have their own primitive sensory systems. So there may be an innate response. If I see something that's kind of moving fast toward my body that I didn't previously see was there and is kind of small and dark and high contrast, that might be an insect kind of skittering onto my body. um i am going to like flinch right um and so there are these innate responses and so there's going to be some group of neurons let's say in the hypothalamus that is that i am flinching yeah uh or i just flinched right right they're the i just flinched neurons in the hypothalamus um so when you flinch first of all that a negative contribution to the reward function you didn't want that to happen perhaps um but that's only happened that's a reward function then that is it doesn't have any generalization in it so i'm going to avoid that exact situation of the thing skittering toward me um and maybe i'm going to avoid some actions that lead to the thing skittering uh so that's that's something a generalization you can get what steve calls it is downstream of the reward function um so i'm going to avoid the situation where the spider was skittering toward me um but you're also going to do something else so there's going to be like a part of your amygdala say that is saying okay um a few you know a few milliseconds you know hundreds hundreds of milliseconds or seconds earlier um could i have predicted that flinching response it's going to be it's going to be a group of neurons that is essentially a classifier of am i about to flinch um and i'm going to have classifiers for that for every important steering subsystem variable that evolution needs to take care of am i about to flinch am i talking to a friend should i laugh now is the friend high status whatever variables the hypothalamus brainstem contain? Um, am I about to taste salt? Um, so that's going to have, uh, all these variables and for each one is going to have a predictor. It's going to train that predictor. Now the predictor that it trains, that can have some generalization. And the reason it can have some generalizations because it just has a totally different input. So it's input data might be things like the word spider, right? But the word spider can activate in all sorts of situations that lead to the world word spider activating in your world model. So, you know, if you have a complex world model with really complex features, that inherently gives you some generalization It not just the thing skittering toward me It even the word spider or the concept of spider is going to cause that to trigger And this predictor can learn that So whatever spider neurons are in my world model which could even be a book about spiders or somewhere a room where there are spiders or whatever that is The amount of heebie-jeebies that this conversation is eliciting in the audience is like... So now I'm activating your steering subsystem. Your steering subsystem, spider hypothalamus, a subgroup of neurons of skittering insects, are activating based on these very abstract concepts in the conversation. If you keep going, I'm going to put in a trigger warning. That's because you learned this. And the cortex inherently has the ability to generalize because it's just predicting based on these very abstract variables and all these integrated information that it has. whereas the steering system only can use whatever the superior clikless and a few other sensors can spit out so by the way it's remarkable that the person who's made this this connection between different pieces of neuroscience steven burns like former physicist yeah has for the last few years has been trying to synthesize he's an ai safety researcher he's just synthesizing this comes back to the academic incentives right i think that this is it's this is a little bit hard to say what's the exact next experiment how am i going to publish a paper on this how am i going to train my grad student do this very very speculative but there's a lot in the neuroscience literature and steven has been able to pull this together and i think that steve has an answer to elia's question essentially which is which is how does the brain ultimately code for these higher level desires and link them up to the more primitive rewards yeah very naive question but why can't we achieve this omnidirectional inference by just training the model to not just map from a token to next token but remove the masks right in the training so it maps every token to every token or come up with more labels between video and audio and text so that it is forced to map one to each one. I mean, that may be that may be the way. So it's not clear to me. Some people think that there's sort of a different way that it does probabilistic inference or different learning algorithm that isn't backprop. There might be like other ways of learning energy-based models or other things like that that you can imagine, but that's involved in being able to do this and that the brain has that. But I think there's a version of it where what the brain does is like crappy versions of backprop to learn to predict through a few layers. And that, yeah, it's kind of like a multimodal foundation model. Yeah, so maybe the cortex is just kind of like certain kinds of foundation models. LLMs are maybe just predicting the next token, but, you know, vision models maybe are trained in learning to fill in the blanks or reconstruct different pieces or combinations. But I think that it does it in an extremely flexible way. So it's, you know, if you train a model to just fill in this blank at the center, okay, that's great. But what if you didn't train it to fill in this other blank over to the left, then it doesn't know how to do that. It's not part of its like repertoire of predictions that are like amortized into the network. Whereas with a really powerful inference system, you could choose at test time, you know, what is the, you know, the subset of variables it needs to infer and which ones are clamped. Okay, two sub questions. One, it makes you wonder whether the thing that is lacking in artificial neural networks is less about the reward function and more about the encoder or the embedding, which, like, maybe the issue is that you're not representing video and audio and text in the right latent abstraction such that they could intermingle and um conflict maybe this is also related to why llmc bad at drawing connections between different ideas like it's like are the ideas represented at a level of generality at which you could which you could notice well the problem is these questions are all co-mingled so if we don't know if it's doing a back prop like learning and we don't know if it's doing energy-based models and we don't know how these areas are even connected in the first place it's like very hard to like really get to the ground truth of this but yeah it's possible i mean i think that people have done some work my friend joel de pello actually did something some years ago where um i think he put a model i think it was a model of v1 um of sort of specifically how the the early visual cortex represents images and put that as like an input into like a conf net and that like improves something so it could be it could be like differences. The retina is also doing, you know, motion detection and certain things are kind of getting filtered out. So there may be some pre-processing of the sensory data. There may be some clever combinations of which modalities are predicting which or so on that lead to better representation. There may be much more clever things than that. Some people certainly do think that there's inductive biases built in the architecture that will shape the representations, you know, differently or that there are clever things that you can do. So Astera, which is the the same organization that employs Steve Behrens just launched this neuroscience project based on Doris Soh's work. And she has some ideas about how you can build vision systems that basically require less training. They put in, they in build into the assumptions of the design of the architecture that things like objects are bounded by surfaces. And, you know, surfaces have certain types of shapes and relationships of how they occlude each other and stuff like that. So it may be possible to build more assumptions into the network. Evolution may have also put some changes of architecture. It's just I think that also the cost functions and so on may be a key thing that it does. So Andy Jones has this amazing 2021 paper where he uses AlphaZero to show that you can trade off test time compute and training compute. And while that might seem obvious now, this was three years before people were talking about inference scaling. So this got me thinking, is there an experiment you could run today, even if it's a toy experiment, which would help you anticipate the next scaling paradigm? One idea I had was to see if there was anything to multi-agent scaling. Basically, if you have a fixed budget of training compute, are you going to get the smartest agent by dumping all of it into training one single agent, or by sliding that compute up amongst a bunch of models, resulting in a diversity of strategies that get to play off each other? I didn't know how to turn this question into a concrete experiment, though, So I started brainstorming with Gemini 3 Pro in the Gemini app. Gemini helped me think through a bunch of different judgment calls. For example, how do you turn the training loop from self-play to this kind of co-evolutionary league training? How do you initialize and then maintain diversity amongst different AlphaZero agents? How do you even split up the compute between these agents in the first place? I found this clean implementation of AlphaGo Zero, which I then forked and opened up in Antigravity, which is Google's agent first IDE. The code was originally written in 2017, and it was meant to be trained on a single GPU of that time. But I needed to train multiple whole separate populations of AlphaZero agents, so I needed to speed things up. I rented a beefcake of a GPU node, but I needed to refactor the whole implementation to take advantage of all this scale and parallelism. Gemini suggested two different ways to parallelize self-play. One which would involve higher GPU context switching, and the other would involve higher communication overhead. I wasn't sure which one to pick, so I just asked Gemini. And not only did it get both of them working in minutes, but it autonomously created and then ran a benchmark to see which one was best. It would have taken me a week to implement either one of these options. Think about how many judgment calls a software engineer working on an actually complex project has to make. If they have to spend weeks architecting some optimization or feature before they can see whether it will work out, they will just get to test out so many fewer ideas. Anyways, with all this help from Gemini, I actually ran the experiment and got some results. Now, please keep in mind that I'm running this experiment on an anemic budget of compute, and it's very possible I made some mistakes in implementation. But it looks like there can be gains from splitting up a fixed budget of trading compute amongst multiple agents rather than just dumping it all into one. Just to reiterate how surprising this is, the best agent in the population of 16 is getting 1 16th the amount of trading compute as the agent trained on self-play alone. And yet it still outperforms the agent that is hogging all of the compute. The whole process of ViveCoding this experiment with Gemini was really absorbing and fun. It gave me the chance to actually understand how AlphaZero works and to understand the design space around decisions about the hyperparameters and how search is done and how you do this kind of co-evolutionary training rather than getting bogged down in my very novice abilities as an engineer. Go to gemini.google.com to try it out. I want to talk about this idea that you just glanced off of, which was amortized inference. And maybe I should try to explain what I think it means, because I think it's probably wrong, and this will help you correct me. It's been a few years for me, too. Okay. right now the way the models work is you have an input it maps it to an output and this is amortizing a process that the the real process which we think is like what intelligence is which is like you have some prior over how the world could be like what are the causes that make the world the way that it is and then the way when you see some observation you should be like okay here's all the ways the world could be um this cause explains what's happening best now this like doing this calculation over every possible cause is computationally intractable so then you just have to sample like oh here's a potential cause does this explain this observation uh no forget it let's let's keep sampling and then eventually you get the cause the cause then the cause explains the observation and then this becomes your posterior that's actually pretty good i think of sort of yeah so yeah this bayesian inference like in general is like of this very intractable thing right it the algorithms that we have for doing that tend to require taking a lot of samples monte carlo methods taking a lot of samples yeah and taking samples takes time i mean this is like the original like baltimore machines and stuff we're using yeah techniques like this um and still it's used with probabilistic programming other types of methods often and so uh yeah so the bayesian inference problem which is like basically the problem of like perception like given some model of the world and given some data like how should i update my what what are the like the the variables you know missing variables in my in my internal model and i guess the idea is that neural networks are hopefully um obviously there's mechanistically the neural network is not starting with like here is my model of the world and i'm going to try to explain this data but the hope is that instead of starting with um hey does this cause explanation no here did this cause explain this explanation yes what you do is just like observation what's the most what's the cause that we the neural net thinks is the best observation to cause so the feed forward like goes observation to cause observation to cause to then output that yes you don't have to you don't have to evaluate all these energy values or whatever and sample around to make them higher and lower um you just say um approximately that process would result in this being the top one or something like that yeah one way to think about it might be that test time compute inference time compute is actually doing this sampling again because you literally read its shade of thought it's like actually doing this toy example we're talking about where it's like oh can i sell this problem by doing x yeah i need a different approach and this raises the question i mean over time it is the case that the capabilities which were uh which required inference time compute to elicit get distilled into the model so you're amortizing the thing which previously So you needed to do these like rollouts, like Monte Carlo rollouts to to figure out. And so in general, maybe there's this principle of digital minds, which can be copied, have different tradeoffs, which are relevant than biological minds, which cannot. And so in general, it should make sense to amortize more things because you can literally copy the amortization, right? Or copy the things that you have sort of like built in. yeah um and it's maybe this is a tangential question where it might be interesting to speculate about in the future as these things become more intelligent and the way we train them becomes more economically rational what will make sense to amortize into these minds which evolution did not think it was worth amortizing into biological minds they do you have to retrain right i mean first of all i think the probabilistic ai people would be like of course you need test time compute because this inference problem is really hard and the only ways we know how to do it involve lots of test time compute otherwise it's just a crappy approximation that's never gonna like you have to do infinite data or something to like make this so i think that some of the probabilistic people will be like no it's like inherently probabilistic and like amortizing it in this way like just doesn't make sense and so and they might then also point to the brain and say okay well the brain the neurons are kind of stochastic and they're sampling and they're doing doing things and so maybe the brain actually is doing more like the non-amortized inference the real inference um but it's also kind of strange how perception can work in just like milliseconds or whatever it doesn't seem like it uses that much sampling so it's also clearly also doing some kind of um baking things into into like approximate forward passes or something like that to do this and yeah so in the future you know i don't know i mean i think is it already a trend to some degree that things that are people were having to use test time compute for getting like used to train back the the base model right yeah yeah that so now it can do it in one pass right yeah so i mean i think yeah you know maybe evolution did or didn do that uh i think evolution still has to pass everything through the genome right to build the network so and the environment in which humans are living is very dynamic right and so maybe that's if we believe this is true that that there's a learning subsystem per steve burns and a steering subsystem the learning subsystem doesn't have a lot of like pre-initialization or pre-training um it has a certain architecture but then within lifetime it learns um then evolution didn't you know actually like amortize that much into that network right it amortized it instead into a set of innate behaviors in a set of these bootstrapping cost functions or ways of building up very particular reward signals yeah yeah this framework helps explain this um mystery that people have pointed out and i've asked a few guests about which is if you want to analogize evolution to pre-training well how do you explain the fact that so little information is conveyed through the genome so three gigabytes is the size of the total human genome obviously a small fraction of that is actually relevant to coding at the brain yeah um and if previously people made this analogy that actually uh evolution has found the hyper parameters of the model the the numbers which tell you how many layers should there be the architecture basically right like how should things be wired together but if a big part of the story that increases sample efficiency aids learning generally makes systems more performant is the reward function is the loss function yeah and if evolution found those loss functions which aid learning then it actually kind of makes sense how so you can like build an intelligence with so little information because like the reward function are you like right in python right the reward function is like literally a line yeah and so you just like have like a thousand lines like this and that doesn't take up that much space yes and it also gets to do this generalization thing with the thing the thing i was describing where we were talking with about the spider right of where it learns that just the word spider you know triggers the spider you know reflex or whatever um it gets to exploit that too right so it gets to build a reward function that actually has a bunch of generalization in it just by specifying these innate spider stuff and the thought assessors as steve calls them that do the learning um so that's like a potentially a really compact solution to building up these more complex reward functions too that you need. So it doesn't have to anticipate everything about the future of the reward function, just anticipate what variables are relevant, what are heuristics for like finding what those variables are. And then, yeah, so then it has to have like a very compact specification for like the learning algorithm and basic architecture of the learning subsystem. And then it has to specify all this Python code of like all the stuff about the spiders and all the stuff about friends and all the stuff about your mother and all the stuff about mating and social groups and joint eye contact. It has to specify all that stuff. And so is this really true? And so I think that there is some evidence for it. So Fei Chen and Evan McCosco and various other researchers who have been doing these single cell atlases. So one of the things that neuroscience technology or scaling up neuroscience technology, again, this is kind of like my one of my obsessions um has done uh through through um the brain initiative the big you know neuroscience funding programs they've basically gone through different areas especially the mouse brain and map like where are the different cell types um how many different types of cells are there in different areas of cortex are they the same across different areas and then you then you look at these subcortical regions which are more like the like steering subsystem or reward function generating regions how many different types of cells do they have and which neurons types do they have we don't know how they're all connected and exactly what they do or what the circuits are what they mean but you can just like quantify like how many different kinds of cells are there um with sequencing the rna and there are a lot more weird and diverse and bespoke cell types in the steering subsystem basically than there are in the learning subsystem Like the cortical cell types, there's enough to build. It seems like there's enough to build a learning algorithm up there and specify some hyperparameters. And in the in the steering subsystem, there's like a gazillion, you know, thousands of really weird cells, which might be like the one for the spider flinch reflex and the one for I'm about to taste salt. Why would each reward function need a different cell type? Well, so this is where you get innately wired circuits. Right. So in the learning algorithm part in this in the learning learning subsystem. um you set up specify the initial architecture you specify a learning algorithm is all all the all the all the juices is happening through plasticity of the synapses changes of the synapses within that big network but it's kind of like a relatively repeating architecture um how it's initialized it's just like um the amount of python code needed to make you know an eight-layer transformer is not that different from one to make a three-layer transformer right you're just replicating yeah whereas all this python code for the reward function you know if superior click list sees something that's skittering and you know you're feeling goosebumps on your skin or whatever then trigger spider reflex that's just a bunch of like bespoke species specific uh situation specific crap that no the cortex doesn't know about spiders it just knows about layers and right and learning the only way to have this like write this reward function yeah is to have a special cell type yeah yeah well i think so i think you either have to have the special cell types or you have to somehow otherwise get special wiring rules that evolution can say this neuron needs to wire to this neuron without any learning. And the way that that is most likely to happen, I think, is that those cells express like different receptors and proteins that say, OK, when this one comes in contact with this one, let's form a synapse. So it's genetic wiring. Yeah. And those need cell types to do it. Yeah. I'm sure this would make a lot more sense if new 101 neuroscience but like it seems like there's still a lot of complexity or generality rather in the steering system so in the steering system has its own visual uh system that's separate from the visual cortex yeah different features still need to plug into that vision system in the so like the spider thing needs to plug into it and also the um the uh love thing needs to plug into it etc etc yes so it seems complicated like no it's still complicated that's that's all the more reason why a lot of the genomic you know real estate in the genome and in terms of these different cell types and so on would go into wiring up the steering subsystem you can be pre-wiring it can we tell how much of the genome is like clearly working so i guess you could tell how many are relevant to the producing the rna that manifest or the epigenetics that manifest in different cell types in the brain right yeah this is what the cell types helps you get at it i don't think i don't think it's exactly like oh this percent of the genome is doing this but you could say okay in these all these steering substances and sub types you know how many different genes are involved in sort of specifying which is which and how they wire um and how much genomic real estate do those genes take up um versus the ones that specify, you know, visual cortex versus auditory cortex, you kind of just reusing the same genes to do the same thing twice. Whereas the spider reflex hooking up, yes, you're right, they have to build a vision system, they have to build some auditory systems and touch systems and navigation type systems. So, you know, even feeding into the hippocampus and stuff like that, there's head direction cells, even the fly brain, it has innate circuits that, you know, figure out orientation and help it navigate in the world and it uses vision figure as optical flow of how it's flying and you know uh how is it how is its flight related to the wind direction it has all these innate stuff that i think we in the mammal brain we would all put that and lump that into the steering subsystem so there's a lot of work so all the genes basically that go into specifying all the things a fly has to do we're going to have stuff like that too just all in the steering subsystem but do we do we have some estimate of like here's how many nucleotides here are many megabases it takes to i i don't know i mean but but um i mean i think you might be able to talk to biologists about this you know to some degree because you can say well we just have a ton in common i mean we have a lot in common with yeast from a genes perspective yeast is still used as a model yeah for you know some amount of drug development and stuff like that in biology and so so much of the genome is just going towards you have a cell at all it can recycle waste it can get energy it can replicate um and then it then you see what we have in common with a mouse and so we do know at some level that you know the difference is us in a chimpanzee or something and that includes the social instincts and the more advanced you know differences in cortex and so on um it's it's a it's a tiny number of genes that go into these additional amount of making the eight-layer transformer instead of the six-layer transformer or tweaking that reward function this would help explain why the hominid brain exploded inside so fast which is presumably like tell me this is correct but under the story we um social learning or some other thing increased the ability to learn from the environment like increase our sample efficiency right instead of having to go and kill the boar yourself and figure out like how to do that you can just be like uh the elder told me this how you make a spear and then now it increases the incentive to have a bigger cortex which can like learn these things yes and that can be done with a relatively few genes because it's really it's really replicating what the mouse already has is making more of it it's maybe not exactly the same and there may be tweaks but it's like from a perspective you don't have to reinvent right all this stuff right so then um how far back in the history of the evolution of the brain does the cortex go back it is the idea that like the cortex has always figured out this omnidirectional inference thing that's been a solve problem for a long time and then the big unlock with primase is this we got the reward function which increased the returns to having omnidirectional inference or is this good question is the cortex is the omnidirectional inference also something that took a while to unlock i'm not sure that there's agreement about that i think there might be specific questions about language you know are there tweaks to be you know whether that's your auditory and memory some combination auditory memory regions there may also be like um macro wiring right of like you need to wire auditory regions into memory regions or something like that and into some of these social instincts to get i see language for example to happen so there might be but that might be also a small number of gene changes yeah to be able to say oh i just need from my temporal lobe over here going over to the auditory cortex something right and there is some evidence for the you know the brocca's area warnicki's area they're connected with these hippocampus and so on and so prefrontal cortex so there's like some small number of genes maybe for like enabling humans to really properly do language that could be a big one but yeah i mean i think that is it that something changed about the cortex and it became possible to do these things whereas that potential was already there but there wasn't the incentive to expand that capability and then use it wired it to these social instincts and use it more um i mean i would lean somewhat toward the latter i mean i think a mouse i has a lot of similarity in terms of cortex as a human right although there's that uh the cesane hercule hussle work yeah the um the the number of neurons scales better with weight with primate brains than it does with rodent brains right so yeah does that suggest that there actually was some improvement in the scalability of the cortex maybe maybe i'm not i'm not super deep on this there may there may have been yeah changes in architecture changes in the folding changes in neuron properties and stuff that somehow slightly tweak this but they're still a scaling that's right either way right um and so i was not saying there aren't something special about humans in the architecture of the learning subsystem at all um but yeah i mean i think it's pretty widely thought that this is expanded but then the question is okay well how does that how does that fit in also with the steering subsystem changes and the instincts that make use of this and allow you to bootstrap using this effectively um but i mean just to say a few other things i mean so even the fly brain has some amount of, for example, even very far back, I mean, I think you've read this great book, The Brief History of Intelligence, right? I think this is a really good book. Lots of AI researchers think this is a really good book, it seems like. Yeah, you have some amount of learning going back all the way to anything that has a brain, basically. You have something kind of like primitive reinforcement learning, at least, um going back at least to like vertebrates like imagine like a zebrafish it's like a um these kind of these other branches birds maybe kind of reinvented something kind of cortex-like but it doesn't have the six layers but they have something a little bit cortex-like um so that some of those things um after reptiles in some sense birds and mammals both kind of made us up somewhat cortex-like but differently organized thing but even a fly brain has like associative learning senders that actually do things that maybe look a little bit like this like thought assessor concept from from berns where there's like a specific dopamine signal to train specific subgroups of neurons in the fly mushroom body to associate different sensory information with am i going to get food now or am i going to get hurt now yeah tangent I remember reading in one blog post that Baron Millage wrote that the parts of the cortex which are associated with audio and vision, have scaled disproportionately between other primates and humans, whereas the parts associated, say, with odor have not. And I remember him saying something like, this is explained by that kind of data having worse scaling law properties. But I think the and maybe he meant this, but another interpretation of actually what's happening there is that these social reward functions that are built into the steering subsystem needed to make use. More of being able to see your elders and see what the visual cues are and hear what they're saying. yeah in order to make a sense of these cues which guide learning you needed to activate these um yeah activate the vision and audio more than i mean there's all this stuff i feel like it's come up in in your your shows before actually but like even like the design of the human eye where you have like the pupil and the white and everything like we are designed to be able to establish relationships based on joint eye contact and and maybe this came up in the sudden episode i can't remember. But yeah, we have to bootstrap to the point where we can detect eye contact and where we can communicate by language. And that's what the first couple of years of life are trying to do. Okay. I want to ask you about RL. So currently the way these LNs are trained, if they solve the unit test or solve a math problem, that whole trajectory, every token in that trajectory is up-weighted. And what's going on with humans? Are there different types of model based versus model free that are happening in different parts of the brain yeah i mean this is this is another one of these things i mean again all my answers to these questions any specific thing i say is all just kind of like directionally this we can kind of explore around this i find this interesting maybe i feel like the literature points in these directions in some very broad way what i actually want to do is like go and map the entire mouse brain and like figure this out comprehensively and like make neuroscience a ground truth science so i don't know basically um but uh but yeah i mean there so first of all i mean i think with ilia on the podcast i mean he was like it's weird that you don't use value functions right you use like the most dumbest form of rl basically and of course there are these people are incredibly smart and they're optimizing for how to do it on gpus and it's really incredible what they're achieving but like conceptually it's a really dumb form of rl even compared to like what was being done in like 10 years ago right like even uh you know the atari game playing stuff right was using like q learning which is basically like it's a kind of temporal difference learning right and the temporal difference learning basically means you have some kind of a value function of like what action i choose now doesn't just tell me literally what happens immediately after this it tells me like what is the long-run consequence of that for my expected you know total reward or something like that um and so you would have value functions like the fact that we don't have like value functions at all is like in the llms is like it's crazy i mean i think i think because ilia said it i can say it i know you know one one hundredth of what he does about ai but like it's kind of crazy that this is working yeah um but uh yeah i mean in terms of the brain um well so i think there are some parts of the brain that are thought to do something that's very much like model free rl that's or parts of the basal ganglia um sort of striatum and basal ganglia they have like a certain finite like it is thought that they have a certain like finite relatively small action space and the types of actions they could take first of all might be like tell the spinal cord or tell the brainstem and spinal cord to do this motor action yes no or it might be more complicated cognitive type actions like tell the thalamus to allow this part of the cortex to talk to this other part or release the memory that's in the hippocampus and start a new one or something right but there's some finite set of actions that kind of come out of the basal ganglia and that it's just a very simple rl so there are probably parts of other brains in our brain that are just like doing very simple naive type rl algorithms um layer one thing on top of that is that some of the major work in neuroscience like peter diane's work and a bunch bunch of work that is part of why i think deep mind did the temporal difference learning stuff in the first place um is they were very interested in neuroscience um and there's a lot of neuroscience evidence that the dopamine is giving this reward prediction error signal um rather than just reward yes no you know a gazillion time steps in the future it's a prediction error um and that's consistent with like learning these value functions um so there's that and then there's maybe like higher order stuff. So we have these cortex making this world model. Well, one of the things the cortex world model can contain is a model of when you do and don't get rewards, right? Again, it's predicting what the steering subsystem will do. It could be predicting what the basal ganglia will do. And so you have a model in your cortex that has more generalization and more concepts and all this stuff that says, okay, these types of plans, these types of actions will lead in these types of circumstances to reward. So I have a model of my reward. Some people also think that you can go the other way. And so this is part of the inference picture. There's this idea of RL as inference. You could say, well, conditional on my having a high reward, sample a plan that I would have had to get there. That's inference of the plan part from the reward part. I'm clamping the reward as high and inferring the plan sampling from plans that could lead to that. And so if you have this very general cortical thing it can just do if you have this like general very general model based system and the model among other things includes plans and rewards then you just get it for free basically so like in neural network parlance there's a value head associated to the the omnidirectional inference that's happening yes yeah there's or there's a value input um yeah oh okay yeah and it can predict one of one of the one of the almost sensory variables it can predict is is what rewards it's going to get yeah but speaking of this thing about amortizing things um yeah obviously value is like amortized rollouts of looking up reward yeah something like that yeah yeah it's like a statistical average or prediction of it yeah right tangential thought uh you know Joe Henrik and others have this idea that the way human societies have learned to do things is just like, how do you figure out that, you know, this kind of bean, which actually just almost always poisons you, is edible if you do this 10 step incredibly complicated process, any one of which, if you fail at, the bean will be poisonous. how do you figure out how to hunt this seal in this particular way with this like particular weapon at this particular time of the year etc um there's no way but uh just like trying shit over generations and it's actually this is actually very much like model free are all happening at like a civilizational level um no not exactly because evolution is the simplest algorithm in some sense right and if we believe that all this can come from evolution like the outer loop can be like extremely not foresighted and yeah right um that that's interesting just like uh hierarchies of evolution model for you culture uh evolution model for you so what does that tell you maybe the simple algorithms can just get you anything if you do it enough right yeah yeah so but yeah so you you have like maybe this yeah evolution model free basal ganglia model free cortex model based culture uh model free potentially um i mean there's like you pay attention to your elders or whatever so there's maybe this like group selection or whatever of these things is like more model free yeah but now i think culture well it stores some of the model yeah right so let's say you want to train an agent to help you with something like processing loan applications training an agent to do this requires more than just giving the model access to the right tools, things like browsers and PDF readers and risk models. There's this level of tacit knowledge that you can only get by actually working in an industry. For example, certain loan applications will pass every single automated check despite being super risky. Every single individual part of the application might look safe, but experienced underwriters know to compare across documents to find subtle patterns that signal risk. Libelbox has experts like this in whatever domain you're focused on, and they will set up highly realistic training environments that include whatever subtle nuances and watch outs you need to look out for. Beyond just building the environment itself, Labelbox provides all the scaffolding you need to capture training data for your agent. They give you the tools to grade agent performance and capture the video of each session and to reset the entire environment to a clean state between every episode. So whatever domain you're working in, Labelbox can help you train reliable real-world agents. Learn more at labelbox.com slash thwarkash. So stepping back, how is it a disadvantage or an advantage for humans that we get to use biological hardware in comparison to computers as they exist now? So what I mean by this question is like if there's the algorithm, would the algorithm just qualitatively perform much worse or much better if inscribed in the hardware of today? And the reason to think it might like here's what I mean. And like, you know, obviously the brain has had to make a bunch of tradeoffs which are not relevant to competing hardware. It has to be much more energetically efficient. Maybe as a result, it has to run on slower speeds so that there can be a smaller voltage gap. And so the brain runs at 200 hertz and has to like run on 20 watts. On the other hand, you know, with like robotics, we've clearly experienced that fingers are way more nimble than we can make motors so far. as maybe there's something in the brain that is the equivalent of like cognitive uh dexterity which is like maybe due to the fact that we can do unstructured sparsity we can co-locate the memory in the compute yes where does this all that are you like fuck we would be so smarter if we didn't have to deal with these brains or are you like oh i mean i think in the end we will get the best of both worlds right somehow right i think i think an obvious downside of the brain is it cannot be copied yeah you don't have you know external read write access to every neuron in synapse, whereas you do. I can just edit something in the weight matrix, you know, in Python or whatever, you know, and load that up and copy that in principle, right? So the fact that it can't be copied and kind of random accessed is, like, very annoying. But otherwise, maybe these are, it, like, has a lot of advantages. So it also tells you that you want to, like, somehow do the co-design of the algorithm and it maybe even doesn't change it that much from all of what we discussed, but you want to somehow do this co-design. So, yeah, how do you do it with really slow, low voltage switches? That's going to be really important for the energy consumption. The co-locating memory and compute. So, like, I think that probably just like hardware companies will try to co-locate memory and compute. They will try to use lower voltages, allow some stochastic stuff. There are some people that think that this, like, all this probabilistic stuff that we were talking about, oh, oh, it's actually energy-based models and so on. It is doing lots of sampling. it's not just amortizing everything that the neurons are also very natural for that because they're naturally stochastic and so you don't have to do a random number generator and a bunch of python code basically to generate a sample the neuron just generates samples and it can tune what the different probabilities are yeah and so and like learn learn those tunings and so it could be that it's very co-designed with like some kind of inference method or something yeah it'd be hilarious i mean the message of this interview is like you know all these people that folks make fun of on twitter you know yon lakoon and beth jazos and whatever they're like no like well yeah maybe i don't know that is actually that is actually one read of me granted you know i i haven't really worked on ai at all since loms you know took off so i'm just like out of the loop but um i i'm surprised and i i think it's amazing how the scaling is is working and everything but yeah, I think Jan LeCun and Beth Jezos are kind of onto something about the probabilistic models, or at least possibly. And in fact, that's what all the neuroscientists and all the AI people thought until 2021 or something, right? So there's a bunch of cellular stuff happening in the brain that is not just about neuron-to-neuron synaptic connections. How much of that is functionally doing more work than the synapses themselves are doing versus it's just a bunch of kludge that you have to do in order to make the synaptic thing work so the way you need to you know with a digital mind you can nudge the synapse sorry the parameter extremely easily but with a cell to modulate a synapse according to the gradient signal it just takes all of this crazy machinery so like is it actually doing more than it takes extremely little code to do so i don't know but i'm i'm not a believer in the like radical like oh actually memory is not synapses mostly or like learning is mostly genetic changes or something like that i think it would just make a lot of sense i think you put it really well for it to be more like the second thing you said like let's say you want to do weight normalization across all the weights coming out of your neuron right or into your neuron well you probably have to go like",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0,
          "end": 7.18,
          "text": " The big million dollar question that I have that I've been trying to get the answer to through all these interviews with the researchers, how does the brain do it?",
          "tokens": [
            50365,
            440,
            955,
            2459,
            7241,
            1168,
            300,
            286,
            362,
            300,
            286,
            600,
            668,
            1382,
            281,
            483,
            264,
            1867,
            281,
            807,
            439,
            613,
            12318,
            365,
            264,
            10309,
            11,
            577,
            775,
            264,
            3567,
            360,
            309,
            30,
            50724
          ],
          "temperature": 0,
          "avg_logprob": -0.14320336,
          "compression_ratio": 1.7079365,
          "no_speech_prob": 2.0523496e-12
        },
        {
          "id": 1,
          "seek": 0,
          "start": 7.28,
          "end": 13.62,
          "text": " Right. Like we're throwing way more data at these LLMs and they still have a small fraction of the total capabilities that a human does.",
          "tokens": [
            50729,
            1779,
            13,
            1743,
            321,
            434,
            10238,
            636,
            544,
            1412,
            412,
            613,
            441,
            43,
            26386,
            293,
            436,
            920,
            362,
            257,
            1359,
            14135,
            295,
            264,
            3217,
            10862,
            300,
            257,
            1952,
            775,
            13,
            51046
          ],
          "temperature": 0,
          "avg_logprob": -0.14320336,
          "compression_ratio": 1.7079365,
          "no_speech_prob": 2.0523496e-12
        },
        {
          "id": 2,
          "seek": 0,
          "start": 13.74,
          "end": 14.48,
          "text": " So what's going on?",
          "tokens": [
            51052,
            407,
            437,
            311,
            516,
            322,
            30,
            51089
          ],
          "temperature": 0,
          "avg_logprob": -0.14320336,
          "compression_ratio": 1.7079365,
          "no_speech_prob": 2.0523496e-12
        },
        {
          "id": 3,
          "seek": 0,
          "start": 14.94,
          "end": 18.54,
          "text": " Yeah, I mean, this might be the quadrillion dollar question or something like that.",
          "tokens": [
            51112,
            865,
            11,
            286,
            914,
            11,
            341,
            1062,
            312,
            264,
            10787,
            81,
            11836,
            7241,
            1168,
            420,
            746,
            411,
            300,
            13,
            51292
          ],
          "temperature": 0,
          "avg_logprob": -0.14320336,
          "compression_ratio": 1.7079365,
          "no_speech_prob": 2.0523496e-12
        },
        {
          "id": 4,
          "seek": 0,
          "start": 18.54,
          "end": 20.9,
          "text": " It's it's it's arguably you could make an argument.",
          "tokens": [
            51292,
            467,
            311,
            309,
            311,
            309,
            311,
            26771,
            291,
            727,
            652,
            364,
            6770,
            13,
            51410
          ],
          "temperature": 0,
          "avg_logprob": -0.14320336,
          "compression_ratio": 1.7079365,
          "no_speech_prob": 2.0523496e-12
        },
        {
          "id": 5,
          "seek": 0,
          "start": 21.06,
          "end": 23.46,
          "text": " This is the most important question in science.",
          "tokens": [
            51418,
            639,
            307,
            264,
            881,
            1021,
            1168,
            294,
            3497,
            13,
            51538
          ],
          "temperature": 0,
          "avg_logprob": -0.14320336,
          "compression_ratio": 1.7079365,
          "no_speech_prob": 2.0523496e-12
        },
        {
          "id": 6,
          "seek": 0,
          "start": 24.16,
          "end": 27.1,
          "text": " I don't claim to know the answer.",
          "tokens": [
            51573,
            286,
            500,
            380,
            3932,
            281,
            458,
            264,
            1867,
            13,
            51720
          ],
          "temperature": 0,
          "avg_logprob": -0.14320336,
          "compression_ratio": 1.7079365,
          "no_speech_prob": 2.0523496e-12
        },
        {
          "id": 7,
          "seek": 2710,
          "start": 27.1,
          "end": 35.58,
          "text": " I also don't really think that the answer will necessarily come even from a lot of smart people thinking about it as much as they are.",
          "tokens": [
            50365,
            286,
            611,
            500,
            380,
            534,
            519,
            300,
            264,
            1867,
            486,
            4725,
            808,
            754,
            490,
            257,
            688,
            295,
            4069,
            561,
            1953,
            466,
            309,
            382,
            709,
            382,
            436,
            366,
            13,
            50789
          ],
          "temperature": 0,
          "avg_logprob": -0.0759773,
          "compression_ratio": 1.6028037,
          "no_speech_prob": 1.0200075e-12
        },
        {
          "id": 8,
          "seek": 2710,
          "start": 35.76,
          "end": 48.68,
          "text": " My overall meta-level take is that we have to empower the field of neuroscience to just make neuroscience a more powerful field technologically and otherwise to actually be able to crack a question like this.",
          "tokens": [
            50798,
            1222,
            4787,
            19616,
            12,
            12418,
            747,
            307,
            300,
            321,
            362,
            281,
            11071,
            264,
            2519,
            295,
            42762,
            281,
            445,
            652,
            42762,
            257,
            544,
            4005,
            2519,
            1537,
            17157,
            293,
            5911,
            281,
            767,
            312,
            1075,
            281,
            6226,
            257,
            1168,
            411,
            341,
            13,
            51444
          ],
          "temperature": 0,
          "avg_logprob": -0.0759773,
          "compression_ratio": 1.6028037,
          "no_speech_prob": 1.0200075e-12
        },
        {
          "id": 9,
          "seek": 4868,
          "start": 48.68,
          "end": 60.24,
          "text": " But maybe the the way that we would think about this now with modern AI, neural nets, deep learning, is that there's sort of these these certain key components of that.",
          "tokens": [
            50365,
            583,
            1310,
            264,
            264,
            636,
            300,
            321,
            576,
            519,
            466,
            341,
            586,
            365,
            4363,
            7318,
            11,
            18161,
            36170,
            11,
            2452,
            2539,
            11,
            307,
            300,
            456,
            311,
            1333,
            295,
            613,
            613,
            1629,
            2141,
            6677,
            295,
            300,
            13,
            50943
          ],
          "temperature": 0,
          "avg_logprob": -0.14541642,
          "compression_ratio": 1.7630522,
          "no_speech_prob": 8.792243e-13
        },
        {
          "id": 10,
          "seek": 4868,
          "start": 60.32,
          "end": 63.78,
          "text": " There's the architecture. There's maybe hyper parameters of the architecture.",
          "tokens": [
            50947,
            821,
            311,
            264,
            9482,
            13,
            821,
            311,
            1310,
            9848,
            9834,
            295,
            264,
            9482,
            13,
            51120
          ],
          "temperature": 0,
          "avg_logprob": -0.14541642,
          "compression_ratio": 1.7630522,
          "no_speech_prob": 8.792243e-13
        },
        {
          "id": 11,
          "seek": 4868,
          "start": 63.88,
          "end": 66.54,
          "text": " How many layers do you have or sort of properties of that architecture?",
          "tokens": [
            51125,
            1012,
            867,
            7914,
            360,
            291,
            362,
            420,
            1333,
            295,
            7221,
            295,
            300,
            9482,
            30,
            51258
          ],
          "temperature": 0,
          "avg_logprob": -0.14541642,
          "compression_ratio": 1.7630522,
          "no_speech_prob": 8.792243e-13
        },
        {
          "id": 12,
          "seek": 4868,
          "start": 67.58,
          "end": 70.76,
          "text": " There is the learning algorithm itself. How do you train it?",
          "tokens": [
            51310,
            821,
            307,
            264,
            2539,
            9284,
            2564,
            13,
            1012,
            360,
            291,
            3847,
            309,
            30,
            51469
          ],
          "temperature": 0,
          "avg_logprob": -0.14541642,
          "compression_ratio": 1.7630522,
          "no_speech_prob": 8.792243e-13
        },
        {
          "id": 13,
          "seek": 4868,
          "start": 70.84,
          "end": 74.14,
          "text": " You know, back prop gradient descent. Is it something else?",
          "tokens": [
            51473,
            509,
            458,
            11,
            646,
            2365,
            16235,
            23475,
            13,
            1119,
            309,
            746,
            1646,
            30,
            51638
          ],
          "temperature": 0,
          "avg_logprob": -0.14541642,
          "compression_ratio": 1.7630522,
          "no_speech_prob": 8.792243e-13
        },
        {
          "id": 14,
          "seek": 7414,
          "start": 74.14,
          "end": 79.94,
          "text": " there is how is it initialized okay so if we take the learning part of the system it still",
          "tokens": [
            50365,
            456,
            307,
            577,
            307,
            309,
            5883,
            1602,
            1392,
            370,
            498,
            321,
            747,
            264,
            2539,
            644,
            295,
            264,
            1185,
            309,
            920,
            50655
          ],
          "temperature": 0,
          "avg_logprob": -0.078728236,
          "compression_ratio": 1.8987342,
          "no_speech_prob": 1.5133503e-12
        },
        {
          "id": 15,
          "seek": 7414,
          "start": 79.94,
          "end": 86.42,
          "text": " may have some initialization of of the weights um and then there are also cost functions there's",
          "tokens": [
            50655,
            815,
            362,
            512,
            5883,
            2144,
            295,
            295,
            264,
            17443,
            1105,
            293,
            550,
            456,
            366,
            611,
            2063,
            6828,
            456,
            311,
            50979
          ],
          "temperature": 0,
          "avg_logprob": -0.078728236,
          "compression_ratio": 1.8987342,
          "no_speech_prob": 1.5133503e-12
        },
        {
          "id": 16,
          "seek": 7414,
          "start": 86.42,
          "end": 90.28,
          "text": " like what is it being trained to do what's the reward signal what are the loss functions",
          "tokens": [
            50979,
            411,
            437,
            307,
            309,
            885,
            8895,
            281,
            360,
            437,
            311,
            264,
            7782,
            6358,
            437,
            366,
            264,
            4470,
            6828,
            51172
          ],
          "temperature": 0,
          "avg_logprob": -0.078728236,
          "compression_ratio": 1.8987342,
          "no_speech_prob": 1.5133503e-12
        },
        {
          "id": 17,
          "seek": 7414,
          "start": 90.28,
          "end": 97.52,
          "text": " supervision signals my personal hunch within that framework is that the the field has neglected",
          "tokens": [
            51172,
            32675,
            12354,
            452,
            2973,
            47630,
            1951,
            300,
            8388,
            307,
            300,
            264,
            264,
            2519,
            575,
            32701,
            51534
          ],
          "temperature": 0,
          "avg_logprob": -0.078728236,
          "compression_ratio": 1.8987342,
          "no_speech_prob": 1.5133503e-12
        },
        {
          "id": 18,
          "seek": 7414,
          "start": 97.52,
          "end": 102.88,
          "text": " uh the role of this very specific loss functions very specific cost functions",
          "tokens": [
            51534,
            2232,
            264,
            3090,
            295,
            341,
            588,
            2685,
            4470,
            6828,
            588,
            2685,
            2063,
            6828,
            51802
          ],
          "temperature": 0,
          "avg_logprob": -0.078728236,
          "compression_ratio": 1.8987342,
          "no_speech_prob": 1.5133503e-12
        },
        {
          "id": 19,
          "seek": 10288,
          "start": 102.88,
          "end": 109.42,
          "text": " And machine learning tends to like mathematically simple loss functions, right?",
          "tokens": [
            50365,
            400,
            3479,
            2539,
            12258,
            281,
            411,
            44003,
            2199,
            4470,
            6828,
            11,
            558,
            30,
            50692
          ],
          "temperature": 0,
          "avg_logprob": -0.16479097,
          "compression_ratio": 1.712963,
          "no_speech_prob": 1.0042282e-12
        },
        {
          "id": 20,
          "seek": 10288,
          "start": 109.5,
          "end": 117.46,
          "text": " Predict the next token, you know, cross entropy, these simple kind of computer scientists loss functions.",
          "tokens": [
            50696,
            430,
            24945,
            264,
            958,
            14862,
            11,
            291,
            458,
            11,
            3278,
            30867,
            11,
            613,
            2199,
            733,
            295,
            3820,
            7708,
            4470,
            6828,
            13,
            51094
          ],
          "temperature": 0,
          "avg_logprob": -0.16479097,
          "compression_ratio": 1.712963,
          "no_speech_prob": 1.0042282e-12
        },
        {
          "id": 21,
          "seek": 10288,
          "start": 117.46,
          "end": 120.86,
          "text": " I think evolution may have built a lot of complexity into the loss functions.",
          "tokens": [
            51094,
            286,
            519,
            9303,
            815,
            362,
            3094,
            257,
            688,
            295,
            14024,
            666,
            264,
            4470,
            6828,
            13,
            51264
          ],
          "temperature": 0,
          "avg_logprob": -0.16479097,
          "compression_ratio": 1.712963,
          "no_speech_prob": 1.0042282e-12
        },
        {
          "id": 22,
          "seek": 10288,
          "start": 121,
          "end": 125.36,
          "text": " Actually, many different loss functions were different areas turned on at different stages of development.",
          "tokens": [
            51271,
            5135,
            11,
            867,
            819,
            4470,
            6828,
            645,
            819,
            3179,
            3574,
            322,
            412,
            819,
            10232,
            295,
            3250,
            13,
            51489
          ],
          "temperature": 0,
          "avg_logprob": -0.16479097,
          "compression_ratio": 1.712963,
          "no_speech_prob": 1.0042282e-12
        },
        {
          "id": 23,
          "seek": 12536,
          "start": 125.36,
          "end": 132.52,
          "text": " a lot of python code basically uh generating a specific curriculum for what different parts of",
          "tokens": [
            50365,
            257,
            688,
            295,
            38797,
            3089,
            1936,
            2232,
            17746,
            257,
            2685,
            14302,
            337,
            437,
            819,
            3166,
            295,
            50723
          ],
          "temperature": 0,
          "avg_logprob": -0.047590367,
          "compression_ratio": 1.9594594,
          "no_speech_prob": 1.239898e-12
        },
        {
          "id": 24,
          "seek": 12536,
          "start": 132.52,
          "end": 136.6,
          "text": " the brain need to learn because evolution has seen many times what was successful and unsuccessful",
          "tokens": [
            50723,
            264,
            3567,
            643,
            281,
            1466,
            570,
            9303,
            575,
            1612,
            867,
            1413,
            437,
            390,
            4406,
            293,
            46258,
            50927
          ],
          "temperature": 0,
          "avg_logprob": -0.047590367,
          "compression_ratio": 1.9594594,
          "no_speech_prob": 1.239898e-12
        },
        {
          "id": 25,
          "seek": 12536,
          "start": 136.6,
          "end": 141.44,
          "text": " and evolution could encode the knowledge of the learning curriculum so so in the in the machine",
          "tokens": [
            50927,
            293,
            9303,
            727,
            2058,
            1429,
            264,
            3601,
            295,
            264,
            2539,
            14302,
            370,
            370,
            294,
            264,
            294,
            264,
            3479,
            51169
          ],
          "temperature": 0,
          "avg_logprob": -0.047590367,
          "compression_ratio": 1.9594594,
          "no_speech_prob": 1.239898e-12
        },
        {
          "id": 26,
          "seek": 12536,
          "start": 141.44,
          "end": 145.52,
          "text": " learning framework maybe we can come back and we can talk about yeah where do the loss functions of",
          "tokens": [
            51169,
            2539,
            8388,
            1310,
            321,
            393,
            808,
            646,
            293,
            321,
            393,
            751,
            466,
            1338,
            689,
            360,
            264,
            4470,
            6828,
            295,
            51373
          ],
          "temperature": 0,
          "avg_logprob": -0.047590367,
          "compression_ratio": 1.9594594,
          "no_speech_prob": 1.239898e-12
        },
        {
          "id": 27,
          "seek": 12536,
          "start": 145.52,
          "end": 150,
          "text": " the brain come from can that can loss different loss functions lead to different efficiency of",
          "tokens": [
            51373,
            264,
            3567,
            808,
            490,
            393,
            300,
            393,
            4470,
            819,
            4470,
            6828,
            1477,
            281,
            819,
            10493,
            295,
            51597
          ],
          "temperature": 0,
          "avg_logprob": -0.047590367,
          "compression_ratio": 1.9594594,
          "no_speech_prob": 1.239898e-12
        },
        {
          "id": 28,
          "seek": 12536,
          "start": 150,
          "end": 155.06,
          "text": " learning you know people say like the cortex has got the universal human learning algorithm the",
          "tokens": [
            51597,
            2539,
            291,
            458,
            561,
            584,
            411,
            264,
            33312,
            575,
            658,
            264,
            11455,
            1952,
            2539,
            9284,
            264,
            51850
          ],
          "temperature": 0,
          "avg_logprob": -0.047590367,
          "compression_ratio": 1.9594594,
          "no_speech_prob": 1.239898e-12
        },
        {
          "id": 29,
          "seek": 15506,
          "start": 155.06,
          "end": 160.14,
          "text": " special science that humans have what's up this is a huge question uh and we don't know i've seen",
          "tokens": [
            50365,
            2121,
            3497,
            300,
            6255,
            362,
            437,
            311,
            493,
            341,
            307,
            257,
            2603,
            1168,
            2232,
            293,
            321,
            500,
            380,
            458,
            741,
            600,
            1612,
            50619
          ],
          "temperature": 0,
          "avg_logprob": -0.046527393,
          "compression_ratio": 1.8957529,
          "no_speech_prob": 1.5984682e-12
        },
        {
          "id": 30,
          "seek": 15506,
          "start": 160.14,
          "end": 165.4,
          "text": " models where what the cortex uh you know the cortex has typically this like six layered structure",
          "tokens": [
            50619,
            5245,
            689,
            437,
            264,
            33312,
            2232,
            291,
            458,
            264,
            33312,
            575,
            5850,
            341,
            411,
            2309,
            34666,
            3877,
            50882
          ],
          "temperature": 0,
          "avg_logprob": -0.046527393,
          "compression_ratio": 1.8957529,
          "no_speech_prob": 1.5984682e-12
        },
        {
          "id": 31,
          "seek": 15506,
          "start": 165.4,
          "end": 169.88,
          "text": " layers in a slightly different sense than layers of a neural net it's like any one location in the",
          "tokens": [
            50882,
            7914,
            294,
            257,
            4748,
            819,
            2020,
            813,
            7914,
            295,
            257,
            18161,
            2533,
            309,
            311,
            411,
            604,
            472,
            4914,
            294,
            264,
            51106
          ],
          "temperature": 0,
          "avg_logprob": -0.046527393,
          "compression_ratio": 1.8957529,
          "no_speech_prob": 1.5984682e-12
        },
        {
          "id": 32,
          "seek": 15506,
          "start": 169.88,
          "end": 176.1,
          "text": " cortex has six physical layers of tissue as you go in layers of the sheet and then those areas then",
          "tokens": [
            51106,
            33312,
            575,
            2309,
            4001,
            7914,
            295,
            12404,
            382,
            291,
            352,
            294,
            7914,
            295,
            264,
            8193,
            293,
            550,
            729,
            3179,
            550,
            51417
          ],
          "temperature": 0,
          "avg_logprob": -0.046527393,
          "compression_ratio": 1.8957529,
          "no_speech_prob": 1.5984682e-12
        },
        {
          "id": 33,
          "seek": 15506,
          "start": 176.1,
          "end": 181.8,
          "text": " connect to each other and that's more like the layers of a network um i've seen versions of that",
          "tokens": [
            51417,
            1745,
            281,
            1184,
            661,
            293,
            300,
            311,
            544,
            411,
            264,
            7914,
            295,
            257,
            3209,
            1105,
            741,
            600,
            1612,
            9606,
            295,
            300,
            51702
          ],
          "temperature": 0,
          "avg_logprob": -0.046527393,
          "compression_ratio": 1.8957529,
          "no_speech_prob": 1.5984682e-12
        },
        {
          "id": 34,
          "seek": 18180,
          "start": 181.8,
          "end": 188.34,
          "text": " where what you're trying to explain is actually just how does it approximate backprop and what is",
          "tokens": [
            50365,
            689,
            437,
            291,
            434,
            1382,
            281,
            2903,
            307,
            767,
            445,
            577,
            775,
            309,
            30874,
            646,
            79,
            1513,
            293,
            437,
            307,
            50692
          ],
          "temperature": 0,
          "avg_logprob": -0.062372655,
          "compression_ratio": 1.9203187,
          "no_speech_prob": 1.0441063e-12
        },
        {
          "id": 35,
          "seek": 18180,
          "start": 188.34,
          "end": 191.96,
          "text": " the cost function for that what is the network being asked you to if you sort of are trying to",
          "tokens": [
            50692,
            264,
            2063,
            2445,
            337,
            300,
            437,
            307,
            264,
            3209,
            885,
            2351,
            291,
            281,
            498,
            291,
            1333,
            295,
            366,
            1382,
            281,
            50873
          ],
          "temperature": 0,
          "avg_logprob": -0.062372655,
          "compression_ratio": 1.9203187,
          "no_speech_prob": 1.0441063e-12
        },
        {
          "id": 36,
          "seek": 18180,
          "start": 191.96,
          "end": 195.86,
          "text": " say it's something like backprop is it doing backprop on next token prediction is it doing",
          "tokens": [
            50873,
            584,
            309,
            311,
            746,
            411,
            646,
            79,
            1513,
            307,
            309,
            884,
            646,
            79,
            1513,
            322,
            958,
            14862,
            17630,
            307,
            309,
            884,
            51068
          ],
          "temperature": 0,
          "avg_logprob": -0.062372655,
          "compression_ratio": 1.9203187,
          "no_speech_prob": 1.0441063e-12
        },
        {
          "id": 37,
          "seek": 18180,
          "start": 195.86,
          "end": 205.52,
          "text": " backprop on classifying images or what is it doing um and uh no one no one knows um but i think i think",
          "tokens": [
            51068,
            646,
            79,
            1513,
            322,
            1508,
            5489,
            5267,
            420,
            437,
            307,
            309,
            884,
            1105,
            293,
            2232,
            572,
            472,
            572,
            472,
            3255,
            1105,
            457,
            741,
            519,
            741,
            519,
            51551
          ],
          "temperature": 0,
          "avg_logprob": -0.062372655,
          "compression_ratio": 1.9203187,
          "no_speech_prob": 1.0441063e-12
        },
        {
          "id": 38,
          "seek": 18180,
          "start": 205.52,
          "end": 211.32,
          "text": " one one thought about it one possibility about it is that um it's just this incredibly general",
          "tokens": [
            51551,
            472,
            472,
            1194,
            466,
            309,
            472,
            7959,
            466,
            309,
            307,
            300,
            1105,
            309,
            311,
            445,
            341,
            6252,
            2674,
            51841
          ],
          "temperature": 0,
          "avg_logprob": -0.062372655,
          "compression_ratio": 1.9203187,
          "no_speech_prob": 1.0441063e-12
        },
        {
          "id": 39,
          "seek": 21132,
          "start": 211.32,
          "end": 216.64,
          "text": " prediction engine so so any one area of cortex is just trying to predict",
          "tokens": [
            50365,
            17630,
            2848,
            370,
            370,
            604,
            472,
            1859,
            295,
            33312,
            307,
            445,
            1382,
            281,
            6069,
            50631
          ],
          "temperature": 0,
          "avg_logprob": -0.06747895,
          "compression_ratio": 1.8638297,
          "no_speech_prob": 1.3408124e-12
        },
        {
          "id": 40,
          "seek": 21132,
          "start": 216.64,
          "end": 222.82,
          "text": " any basically can it learn to predict any subset of all the variables it sees",
          "tokens": [
            50631,
            604,
            1936,
            393,
            309,
            1466,
            281,
            6069,
            604,
            25993,
            295,
            439,
            264,
            9102,
            309,
            8194,
            50940
          ],
          "temperature": 0,
          "avg_logprob": -0.06747895,
          "compression_ratio": 1.8638297,
          "no_speech_prob": 1.3408124e-12
        },
        {
          "id": 41,
          "seek": 21132,
          "start": 222.82,
          "end": 229.54,
          "text": " from any other subsets so like omnidirectional inference um or omnidirectional prediction",
          "tokens": [
            50940,
            490,
            604,
            661,
            2090,
            1385,
            370,
            411,
            36874,
            327,
            621,
            41048,
            38253,
            1105,
            420,
            36874,
            327,
            621,
            41048,
            17630,
            51276
          ],
          "temperature": 0,
          "avg_logprob": -0.06747895,
          "compression_ratio": 1.8638297,
          "no_speech_prob": 1.3408124e-12
        },
        {
          "id": 42,
          "seek": 21132,
          "start": 229.54,
          "end": 235.24,
          "text": " um whereas an llm is just you see everything in the context window and then it it computes a very",
          "tokens": [
            51276,
            1105,
            9735,
            364,
            4849,
            76,
            307,
            445,
            291,
            536,
            1203,
            294,
            264,
            4319,
            4910,
            293,
            550,
            309,
            309,
            715,
            1819,
            257,
            588,
            51561
          ],
          "temperature": 0,
          "avg_logprob": -0.06747895,
          "compression_ratio": 1.8638297,
          "no_speech_prob": 1.3408124e-12
        },
        {
          "id": 43,
          "seek": 21132,
          "start": 235.24,
          "end": 240.42,
          "text": " particular conditional probability which is given all the last thousands of things what is the very",
          "tokens": [
            51561,
            1729,
            27708,
            8482,
            597,
            307,
            2212,
            439,
            264,
            1036,
            5383,
            295,
            721,
            437,
            307,
            264,
            588,
            51820
          ],
          "temperature": 0,
          "avg_logprob": -0.06747895,
          "compression_ratio": 1.8638297,
          "no_speech_prob": 1.3408124e-12
        },
        {
          "id": 44,
          "seek": 24042,
          "start": 240.42,
          "end": 245.44,
          "text": " probabilities for all the all the the next token yeah um but it would be weird for a large language",
          "tokens": [
            50365,
            33783,
            337,
            439,
            264,
            439,
            264,
            264,
            958,
            14862,
            1338,
            1105,
            457,
            309,
            576,
            312,
            3657,
            337,
            257,
            2416,
            2856,
            50616
          ],
          "temperature": 0,
          "avg_logprob": -0.05997955,
          "compression_ratio": 1.7863636,
          "no_speech_prob": 1.2160608e-12
        },
        {
          "id": 45,
          "seek": 24042,
          "start": 245.44,
          "end": 254.62,
          "text": " model to say you know um you know the quick brown fox blank blank the lazy dog um and filling in the",
          "tokens": [
            50616,
            2316,
            281,
            584,
            291,
            458,
            1105,
            291,
            458,
            264,
            1702,
            6292,
            21026,
            8247,
            8247,
            264,
            14847,
            3000,
            1105,
            293,
            10623,
            294,
            264,
            51075
          ],
          "temperature": 0,
          "avg_logprob": -0.05997955,
          "compression_ratio": 1.7863636,
          "no_speech_prob": 1.2160608e-12
        },
        {
          "id": 46,
          "seek": 24042,
          "start": 254.62,
          "end": 261.68,
          "text": " middle yeah um versus do the next token if it's if it's doing just forward it can learn how to do",
          "tokens": [
            51075,
            2808,
            1338,
            1105,
            5717,
            360,
            264,
            958,
            14862,
            498,
            309,
            311,
            498,
            309,
            311,
            884,
            445,
            2128,
            309,
            393,
            1466,
            577,
            281,
            360,
            51428
          ],
          "temperature": 0,
          "avg_logprob": -0.05997955,
          "compression_ratio": 1.7863636,
          "no_speech_prob": 1.2160608e-12
        },
        {
          "id": 47,
          "seek": 24042,
          "start": 261.68,
          "end": 266.12,
          "text": " that stuff in this emergent level of in context learning but natively it's just predicting the",
          "tokens": [
            51428,
            300,
            1507,
            294,
            341,
            4345,
            6930,
            1496,
            295,
            294,
            4319,
            2539,
            457,
            8470,
            356,
            309,
            311,
            445,
            32884,
            264,
            51650
          ],
          "temperature": 0,
          "avg_logprob": -0.05997955,
          "compression_ratio": 1.7863636,
          "no_speech_prob": 1.2160608e-12
        },
        {
          "id": 48,
          "seek": 26612,
          "start": 266.12,
          "end": 272.26,
          "text": " next token what if the cortex is just natively made so that it can you know any area of cortex",
          "tokens": [
            50365,
            958,
            14862,
            437,
            498,
            264,
            33312,
            307,
            445,
            8470,
            356,
            1027,
            370,
            300,
            309,
            393,
            291,
            458,
            604,
            1859,
            295,
            33312,
            50672
          ],
          "temperature": 0,
          "avg_logprob": -0.073180884,
          "compression_ratio": 1.741573,
          "no_speech_prob": 1.2694497e-12
        },
        {
          "id": 49,
          "seek": 26612,
          "start": 272.26,
          "end": 278.5,
          "text": " can predict any pattern in any subset of its inputs given any other missing subsets um that",
          "tokens": [
            50672,
            393,
            6069,
            604,
            5102,
            294,
            604,
            25993,
            295,
            1080,
            15743,
            2212,
            604,
            661,
            5361,
            2090,
            1385,
            1105,
            300,
            50984
          ],
          "temperature": 0,
          "avg_logprob": -0.073180884,
          "compression_ratio": 1.741573,
          "no_speech_prob": 1.2694497e-12
        },
        {
          "id": 50,
          "seek": 26612,
          "start": 278.5,
          "end": 284.14,
          "text": " is a little bit more like quote-unquote probabilistic ai um i think a lot of things i'm",
          "tokens": [
            50984,
            307,
            257,
            707,
            857,
            544,
            411,
            6513,
            12,
            409,
            25016,
            31959,
            3142,
            9783,
            1105,
            741,
            519,
            257,
            688,
            295,
            721,
            741,
            478,
            51266
          ],
          "temperature": 0,
          "avg_logprob": -0.073180884,
          "compression_ratio": 1.741573,
          "no_speech_prob": 1.2694497e-12
        },
        {
          "id": 51,
          "seek": 26612,
          "start": 284.14,
          "end": 289.12,
          "text": " saying by the way are extremely similar to like what jan lecun would say yeah um he's really",
          "tokens": [
            51266,
            1566,
            538,
            264,
            636,
            366,
            4664,
            2531,
            281,
            411,
            437,
            25442,
            476,
            66,
            409,
            576,
            584,
            1338,
            1105,
            415,
            311,
            534,
            51515
          ],
          "temperature": 0,
          "avg_logprob": -0.073180884,
          "compression_ratio": 1.741573,
          "no_speech_prob": 1.2694497e-12
        },
        {
          "id": 52,
          "seek": 26612,
          "start": 289.12,
          "end": 293.44,
          "text": " interested in these energy-based models um and something like that is like the joint distribution",
          "tokens": [
            51515,
            3102,
            294,
            613,
            2281,
            12,
            6032,
            5245,
            1105,
            293,
            746,
            411,
            300,
            307,
            411,
            264,
            7225,
            7316,
            51731
          ],
          "temperature": 0,
          "avg_logprob": -0.073180884,
          "compression_ratio": 1.741573,
          "no_speech_prob": 1.2694497e-12
        },
        {
          "id": 53,
          "seek": 29344,
          "start": 293.44,
          "end": 300.42,
          "text": " of all the variables, what is the likelihood or unlikelihood of just any combination of variables?",
          "tokens": [
            50365,
            295,
            439,
            264,
            9102,
            11,
            437,
            307,
            264,
            22119,
            420,
            8343,
            21648,
            295,
            445,
            604,
            6562,
            295,
            9102,
            30,
            50714
          ],
          "temperature": 0,
          "avg_logprob": -0.11542009,
          "compression_ratio": 1.787037,
          "no_speech_prob": 9.360449e-13
        },
        {
          "id": 54,
          "seek": 29344,
          "start": 300.88,
          "end": 304.9,
          "text": " And if I clamp some of them, I say, well, definitely these variables are in these states,",
          "tokens": [
            50737,
            400,
            498,
            286,
            17690,
            512,
            295,
            552,
            11,
            286,
            584,
            11,
            731,
            11,
            2138,
            613,
            9102,
            366,
            294,
            613,
            4368,
            11,
            50938
          ],
          "temperature": 0,
          "avg_logprob": -0.11542009,
          "compression_ratio": 1.787037,
          "no_speech_prob": 9.360449e-13
        },
        {
          "id": 55,
          "seek": 29344,
          "start": 305.38,
          "end": 312.36,
          "text": " then I can compute with probabilistic sampling, for example, I can compute, okay, conditioned on",
          "tokens": [
            50962,
            550,
            286,
            393,
            14722,
            365,
            31959,
            3142,
            21179,
            11,
            337,
            1365,
            11,
            286,
            393,
            14722,
            11,
            1392,
            11,
            35833,
            322,
            51311
          ],
          "temperature": 0,
          "avg_logprob": -0.11542009,
          "compression_ratio": 1.787037,
          "no_speech_prob": 9.360449e-13
        },
        {
          "id": 56,
          "seek": 29344,
          "start": 312.36,
          "end": 319.12,
          "text": " these being set in this state, what are, and these could be any arbitrary subset of variables in the",
          "tokens": [
            51311,
            613,
            885,
            992,
            294,
            341,
            1785,
            11,
            437,
            366,
            11,
            293,
            613,
            727,
            312,
            604,
            23211,
            25993,
            295,
            9102,
            294,
            264,
            51649
          ],
          "temperature": 0,
          "avg_logprob": -0.11542009,
          "compression_ratio": 1.787037,
          "no_speech_prob": 9.360449e-13
        },
        {
          "id": 57,
          "seek": 31912,
          "start": 319.12,
          "end": 324.6,
          "text": " model can i predict what any other subset is going to do and sample from any other subset given",
          "tokens": [
            50365,
            2316,
            393,
            741,
            6069,
            437,
            604,
            661,
            25993,
            307,
            516,
            281,
            360,
            293,
            6889,
            490,
            604,
            661,
            25993,
            2212,
            50639
          ],
          "temperature": 0,
          "avg_logprob": -0.060260907,
          "compression_ratio": 2.064982,
          "no_speech_prob": 1.6619304e-12
        },
        {
          "id": 58,
          "seek": 31912,
          "start": 324.6,
          "end": 328.6,
          "text": " clamping this subset and i could choose a totally different subset and sample from that subset",
          "tokens": [
            50639,
            17690,
            278,
            341,
            25993,
            293,
            741,
            727,
            2826,
            257,
            3879,
            819,
            25993,
            293,
            6889,
            490,
            300,
            25993,
            50839
          ],
          "temperature": 0,
          "avg_logprob": -0.060260907,
          "compression_ratio": 2.064982,
          "no_speech_prob": 1.6619304e-12
        },
        {
          "id": 59,
          "seek": 31912,
          "start": 328.6,
          "end": 334.74,
          "text": " so it's omnidirectional inference and so you know that could be there's some parts of cortex that",
          "tokens": [
            50839,
            370,
            309,
            311,
            36874,
            327,
            621,
            41048,
            38253,
            293,
            370,
            291,
            458,
            300,
            727,
            312,
            456,
            311,
            512,
            3166,
            295,
            33312,
            300,
            51146
          ],
          "temperature": 0,
          "avg_logprob": -0.060260907,
          "compression_ratio": 2.064982,
          "no_speech_prob": 1.6619304e-12
        },
        {
          "id": 60,
          "seek": 31912,
          "start": 334.74,
          "end": 339.1,
          "text": " might be like association areas of cortex that may you know predict vision from audition yeah",
          "tokens": [
            51146,
            1062,
            312,
            411,
            14598,
            3179,
            295,
            33312,
            300,
            815,
            291,
            458,
            6069,
            5201,
            490,
            20015,
            1338,
            51364
          ],
          "temperature": 0,
          "avg_logprob": -0.060260907,
          "compression_ratio": 2.064982,
          "no_speech_prob": 1.6619304e-12
        },
        {
          "id": 61,
          "seek": 31912,
          "start": 339.1,
          "end": 344.8,
          "text": " there might be areas that predict things that the more innate part of the brain is going to do",
          "tokens": [
            51364,
            456,
            1062,
            312,
            3179,
            300,
            6069,
            721,
            300,
            264,
            544,
            41766,
            644,
            295,
            264,
            3567,
            307,
            516,
            281,
            360,
            51649
          ],
          "temperature": 0,
          "avg_logprob": -0.060260907,
          "compression_ratio": 2.064982,
          "no_speech_prob": 1.6619304e-12
        },
        {
          "id": 62,
          "seek": 31912,
          "start": 344.8,
          "end": 348.26,
          "text": " because remember this whole thing is basically riding on top of the sort of a lizard brain and",
          "tokens": [
            51649,
            570,
            1604,
            341,
            1379,
            551,
            307,
            1936,
            9546,
            322,
            1192,
            295,
            264,
            1333,
            295,
            257,
            39215,
            3567,
            293,
            51822
          ],
          "temperature": 0,
          "avg_logprob": -0.060260907,
          "compression_ratio": 2.064982,
          "no_speech_prob": 1.6619304e-12
        },
        {
          "id": 63,
          "seek": 34826,
          "start": 348.26,
          "end": 353.32,
          "text": " lizard body if you will um and that thing is a thing that's worth predicting too so you're not",
          "tokens": [
            50365,
            39215,
            1772,
            498,
            291,
            486,
            1105,
            293,
            300,
            551,
            307,
            257,
            551,
            300,
            311,
            3163,
            32884,
            886,
            370,
            291,
            434,
            406,
            50618
          ],
          "temperature": 0,
          "avg_logprob": -0.034256954,
          "compression_ratio": 1.7803738,
          "no_speech_prob": 1.8325762e-12
        },
        {
          "id": 64,
          "seek": 34826,
          "start": 353.32,
          "end": 358.32,
          "text": " just predicting do i see this or do i see that but is this muscle about to tense am i about to",
          "tokens": [
            50618,
            445,
            32884,
            360,
            741,
            536,
            341,
            420,
            360,
            741,
            536,
            300,
            457,
            307,
            341,
            8679,
            466,
            281,
            18760,
            669,
            741,
            466,
            281,
            50868
          ],
          "temperature": 0,
          "avg_logprob": -0.034256954,
          "compression_ratio": 1.7803738,
          "no_speech_prob": 1.8325762e-12
        },
        {
          "id": 65,
          "seek": 34826,
          "start": 358.32,
          "end": 364.52,
          "text": " have a reflex where i laugh you know is my heart rate about to go up um am i about to activate this",
          "tokens": [
            50868,
            362,
            257,
            23802,
            689,
            741,
            5801,
            291,
            458,
            307,
            452,
            1917,
            3314,
            466,
            281,
            352,
            493,
            1105,
            669,
            741,
            466,
            281,
            13615,
            341,
            51178
          ],
          "temperature": 0,
          "avg_logprob": -0.034256954,
          "compression_ratio": 1.7803738,
          "no_speech_prob": 1.8325762e-12
        },
        {
          "id": 66,
          "seek": 34826,
          "start": 364.52,
          "end": 371.66,
          "text": " instinctive behavior based on my higher level understanding of like i can match uh somebody",
          "tokens": [
            51178,
            16556,
            488,
            5223,
            2361,
            322,
            452,
            2946,
            1496,
            3701,
            295,
            411,
            741,
            393,
            2995,
            2232,
            2618,
            51535
          ],
          "temperature": 0,
          "avg_logprob": -0.034256954,
          "compression_ratio": 1.7803738,
          "no_speech_prob": 1.8325762e-12
        },
        {
          "id": 67,
          "seek": 37166,
          "start": 371.66,
          "end": 378.06,
          "text": " has told me there's a spider on my back to this lizard part that would activate if i was like",
          "tokens": [
            50365,
            575,
            1907,
            385,
            456,
            311,
            257,
            17614,
            322,
            452,
            646,
            281,
            341,
            39215,
            644,
            300,
            576,
            13615,
            498,
            741,
            390,
            411,
            50685
          ],
          "temperature": 0,
          "avg_logprob": -0.05381609,
          "compression_ratio": 1.8409091,
          "no_speech_prob": 1.769119e-12
        },
        {
          "id": 68,
          "seek": 37166,
          "start": 378.06,
          "end": 383.48,
          "text": " literally seeing a spider in front of me and you you learn to associate the two so that even just",
          "tokens": [
            50685,
            3736,
            2577,
            257,
            17614,
            294,
            1868,
            295,
            385,
            293,
            291,
            291,
            1466,
            281,
            14644,
            264,
            732,
            370,
            300,
            754,
            445,
            50956
          ],
          "temperature": 0,
          "avg_logprob": -0.05381609,
          "compression_ratio": 1.8409091,
          "no_speech_prob": 1.769119e-12
        },
        {
          "id": 69,
          "seek": 37166,
          "start": 383.48,
          "end": 387.2,
          "text": " from somebody hearing you say there's a spider on your back yeah let's well let's come back to this",
          "tokens": [
            50956,
            490,
            2618,
            4763,
            291,
            584,
            456,
            311,
            257,
            17614,
            322,
            428,
            646,
            1338,
            718,
            311,
            731,
            718,
            311,
            808,
            646,
            281,
            341,
            51142
          ],
          "temperature": 0,
          "avg_logprob": -0.05381609,
          "compression_ratio": 1.8409091,
          "no_speech_prob": 1.769119e-12
        },
        {
          "id": 70,
          "seek": 37166,
          "start": 387.2,
          "end": 391.32,
          "text": " and this this is partly having to do with with steve bern's theories which i'm recently obsessed",
          "tokens": [
            51142,
            293,
            341,
            341,
            307,
            17031,
            1419,
            281,
            360,
            365,
            365,
            2126,
            303,
            272,
            1248,
            311,
            13667,
            597,
            741,
            478,
            3938,
            16923,
            51348
          ],
          "temperature": 0,
          "avg_logprob": -0.05381609,
          "compression_ratio": 1.8409091,
          "no_speech_prob": 1.769119e-12
        },
        {
          "id": 71,
          "seek": 37166,
          "start": 391.32,
          "end": 398.98,
          "text": " about but yeah but on your podcast with ilia um he said look i'm not aware of any any good theory",
          "tokens": [
            51348,
            466,
            457,
            1338,
            457,
            322,
            428,
            7367,
            365,
            1930,
            654,
            1105,
            415,
            848,
            574,
            741,
            478,
            406,
            3650,
            295,
            604,
            604,
            665,
            5261,
            51731
          ],
          "temperature": 0,
          "avg_logprob": -0.05381609,
          "compression_ratio": 1.8409091,
          "no_speech_prob": 1.769119e-12
        },
        {
          "id": 72,
          "seek": 39898,
          "start": 398.98,
          "end": 404.84,
          "text": " of how evolution encodes high-level desires or intentions.",
          "tokens": [
            50365,
            295,
            577,
            9303,
            2058,
            4789,
            1090,
            12,
            12418,
            18005,
            420,
            19354,
            13,
            50658
          ],
          "temperature": 0,
          "avg_logprob": -0.16919683,
          "compression_ratio": 1.5695652,
          "no_speech_prob": 1.0240017e-12
        },
        {
          "id": 73,
          "seek": 39898,
          "start": 405.62,
          "end": 410.76,
          "text": " I think this is very connected to all of these questions",
          "tokens": [
            50697,
            286,
            519,
            341,
            307,
            588,
            4582,
            281,
            439,
            295,
            613,
            1651,
            50954
          ],
          "temperature": 0,
          "avg_logprob": -0.16919683,
          "compression_ratio": 1.5695652,
          "no_speech_prob": 1.0240017e-12
        },
        {
          "id": 74,
          "seek": 39898,
          "start": 410.76,
          "end": 415.48,
          "text": " about the loss functions and the cost functions that the brain would use.",
          "tokens": [
            50954,
            466,
            264,
            4470,
            6828,
            293,
            264,
            2063,
            6828,
            300,
            264,
            3567,
            576,
            764,
            13,
            51190
          ],
          "temperature": 0,
          "avg_logprob": -0.16919683,
          "compression_ratio": 1.5695652,
          "no_speech_prob": 1.0240017e-12
        },
        {
          "id": 75,
          "seek": 39898,
          "start": 415.6,
          "end": 417.28,
          "text": " And it's a really profound question, right?",
          "tokens": [
            51196,
            400,
            309,
            311,
            257,
            534,
            14382,
            1168,
            11,
            558,
            30,
            51280
          ],
          "temperature": 0,
          "avg_logprob": -0.16919683,
          "compression_ratio": 1.5695652,
          "no_speech_prob": 1.0240017e-12
        },
        {
          "id": 76,
          "seek": 39898,
          "start": 417.68,
          "end": 425.32,
          "text": " Let's say that I am embarrassed for saying the wrong thing on your podcast",
          "tokens": [
            51300,
            961,
            311,
            584,
            300,
            286,
            669,
            16843,
            337,
            1566,
            264,
            2085,
            551,
            322,
            428,
            7367,
            51682
          ],
          "temperature": 0,
          "avg_logprob": -0.16919683,
          "compression_ratio": 1.5695652,
          "no_speech_prob": 1.0240017e-12
        },
        {
          "id": 77,
          "seek": 39898,
          "start": 425.32,
          "end": 427.64,
          "text": " because I'm imagining that Young Lacuna is listening",
          "tokens": [
            51682,
            570,
            286,
            478,
            27798,
            300,
            8160,
            40113,
            5051,
            307,
            4764,
            51798
          ],
          "temperature": 0,
          "avg_logprob": -0.16919683,
          "compression_ratio": 1.5695652,
          "no_speech_prob": 1.0240017e-12
        },
        {
          "id": 78,
          "seek": 42764,
          "start": 427.64,
          "end": 447.92,
          "text": " He says, that's not my theory. You describe energy-based models really badly. That's going to activate in me innate embarrassment and shame, and I'm going to want to go hide and whatever. And that's going to activate these innate reflexes. And that's important because I might otherwise get killed by Yann LeCun's marauding army of other…",
          "tokens": [
            50365,
            634,
            1619,
            11,
            300,
            311,
            406,
            452,
            5261,
            13,
            509,
            6786,
            2281,
            12,
            6032,
            5245,
            534,
            13425,
            13,
            663,
            311,
            516,
            281,
            13615,
            294,
            385,
            41766,
            43536,
            293,
            10069,
            11,
            293,
            286,
            478,
            516,
            281,
            528,
            281,
            352,
            6479,
            293,
            2035,
            13,
            400,
            300,
            311,
            516,
            281,
            13615,
            613,
            41766,
            23802,
            279,
            13,
            400,
            300,
            311,
            1021,
            570,
            286,
            1062,
            5911,
            483,
            4652,
            538,
            398,
            969,
            1456,
            34,
            409,
            311,
            1849,
            3751,
            278,
            7267,
            295,
            661,
            1260,
            51379
          ],
          "temperature": 0,
          "avg_logprob": -0.12009868,
          "compression_ratio": 1.5525115,
          "no_speech_prob": 1.9354045e-12
        },
        {
          "id": 79,
          "seek": 44792,
          "start": 447.92,
          "end": 452.02,
          "text": " differentiated research is coming for you, Adam. And so it's important that I have that instinctual",
          "tokens": [
            50365,
            27372,
            770,
            2132,
            307,
            1348,
            337,
            291,
            11,
            7938,
            13,
            400,
            370,
            309,
            311,
            1021,
            300,
            286,
            362,
            300,
            16556,
            901,
            50570
          ],
          "temperature": 0,
          "avg_logprob": -0.10004638,
          "compression_ratio": 1.6097561,
          "no_speech_prob": 1.6046562e-12
        },
        {
          "id": 80,
          "seek": 44792,
          "start": 452.02,
          "end": 456.92,
          "text": " response. But of course, evolution has never seen Jan LeCun or known about energy-based models or",
          "tokens": [
            50570,
            4134,
            13,
            583,
            295,
            1164,
            11,
            9303,
            575,
            1128,
            1612,
            4956,
            1456,
            34,
            409,
            420,
            2570,
            466,
            2281,
            12,
            6032,
            5245,
            420,
            50815
          ],
          "temperature": 0,
          "avg_logprob": -0.10004638,
          "compression_ratio": 1.6097561,
          "no_speech_prob": 1.6046562e-12
        },
        {
          "id": 81,
          "seek": 44792,
          "start": 456.92,
          "end": 465.26,
          "text": " known what an important scientist or a podcast is. And so somehow the brain has to encode this desire",
          "tokens": [
            50815,
            2570,
            437,
            364,
            1021,
            12662,
            420,
            257,
            7367,
            307,
            13,
            400,
            370,
            6063,
            264,
            3567,
            575,
            281,
            2058,
            1429,
            341,
            7516,
            51232
          ],
          "temperature": 0,
          "avg_logprob": -0.10004638,
          "compression_ratio": 1.6097561,
          "no_speech_prob": 1.6046562e-12
        },
        {
          "id": 82,
          "seek": 44792,
          "start": 465.26,
          "end": 473.58,
          "text": " to not piss off really important people in the tribe or something like this in a very robust way",
          "tokens": [
            51232,
            281,
            406,
            15171,
            766,
            534,
            1021,
            561,
            294,
            264,
            17625,
            420,
            746,
            411,
            341,
            294,
            257,
            588,
            13956,
            636,
            51648
          ],
          "temperature": 0,
          "avg_logprob": -0.10004638,
          "compression_ratio": 1.6097561,
          "no_speech_prob": 1.6046562e-12
        },
        {
          "id": 83,
          "seek": 47358,
          "start": 473.58,
          "end": 479.62,
          "text": " without knowing in advance all the things that the learning subsystem, okay, of the brain,",
          "tokens": [
            50365,
            1553,
            5276,
            294,
            7295,
            439,
            264,
            721,
            300,
            264,
            2539,
            2090,
            9321,
            11,
            1392,
            11,
            295,
            264,
            3567,
            11,
            50667
          ],
          "temperature": 0,
          "avg_logprob": -0.12414026,
          "compression_ratio": 1.7104073,
          "no_speech_prob": 8.72463e-13
        },
        {
          "id": 84,
          "seek": 47358,
          "start": 479.7,
          "end": 484.72,
          "text": " the part that is learning, cortex and other parts, the cortex is going to learn this world model.",
          "tokens": [
            50671,
            264,
            644,
            300,
            307,
            2539,
            11,
            33312,
            293,
            661,
            3166,
            11,
            264,
            33312,
            307,
            516,
            281,
            1466,
            341,
            1002,
            2316,
            13,
            50922
          ],
          "temperature": 0,
          "avg_logprob": -0.12414026,
          "compression_ratio": 1.7104073,
          "no_speech_prob": 8.72463e-13
        },
        {
          "id": 85,
          "seek": 47358,
          "start": 485.32,
          "end": 491.98,
          "text": " It's going to include things like Jan LeCun and podcasts. And evolution has to make sure that",
          "tokens": [
            50952,
            467,
            311,
            516,
            281,
            4090,
            721,
            411,
            4956,
            1456,
            34,
            409,
            293,
            24045,
            13,
            400,
            9303,
            575,
            281,
            652,
            988,
            300,
            51285
          ],
          "temperature": 0,
          "avg_logprob": -0.12414026,
          "compression_ratio": 1.7104073,
          "no_speech_prob": 8.72463e-13
        },
        {
          "id": 86,
          "seek": 47358,
          "start": 491.98,
          "end": 497.58,
          "text": " those neurons, whatever the Jan LeCun being upset with me neurons, get properly wired up to the",
          "tokens": [
            51285,
            729,
            22027,
            11,
            2035,
            264,
            4956,
            1456,
            34,
            409,
            885,
            8340,
            365,
            385,
            22027,
            11,
            483,
            6108,
            27415,
            493,
            281,
            264,
            51565
          ],
          "temperature": 0,
          "avg_logprob": -0.12414026,
          "compression_ratio": 1.7104073,
          "no_speech_prob": 8.72463e-13
        },
        {
          "id": 87,
          "seek": 49758,
          "start": 497.58,
          "end": 503.84,
          "text": " shame response or this part of the reward function um and this is important right because",
          "tokens": [
            50365,
            10069,
            4134,
            420,
            341,
            644,
            295,
            264,
            7782,
            2445,
            1105,
            293,
            341,
            307,
            1021,
            558,
            570,
            50678
          ],
          "temperature": 0,
          "avg_logprob": -0.041757178,
          "compression_ratio": 1.9136213,
          "no_speech_prob": 1.735061e-12
        },
        {
          "id": 88,
          "seek": 49758,
          "start": 503.84,
          "end": 507.38,
          "text": " if we're going to be able to seek status in the tribe or learn from knowledgeable people as you",
          "tokens": [
            50678,
            498,
            321,
            434,
            516,
            281,
            312,
            1075,
            281,
            8075,
            6558,
            294,
            264,
            17625,
            420,
            1466,
            490,
            33800,
            561,
            382,
            291,
            50855
          ],
          "temperature": 0,
          "avg_logprob": -0.041757178,
          "compression_ratio": 1.9136213,
          "no_speech_prob": 1.735061e-12
        },
        {
          "id": 89,
          "seek": 49758,
          "start": 507.38,
          "end": 511.68,
          "text": " said or things like that exchange knowledge and skills with friends but not with enemies i mean",
          "tokens": [
            50855,
            848,
            420,
            721,
            411,
            300,
            7742,
            3601,
            293,
            3942,
            365,
            1855,
            457,
            406,
            365,
            7805,
            741,
            914,
            51070
          ],
          "temperature": 0,
          "avg_logprob": -0.041757178,
          "compression_ratio": 1.9136213,
          "no_speech_prob": 1.735061e-12
        },
        {
          "id": 90,
          "seek": 49758,
          "start": 511.68,
          "end": 515.62,
          "text": " we have to learn all this stuff so it has to be able to robustly wire these learned features of",
          "tokens": [
            51070,
            321,
            362,
            281,
            1466,
            439,
            341,
            1507,
            370,
            309,
            575,
            281,
            312,
            1075,
            281,
            13956,
            356,
            6234,
            613,
            3264,
            4122,
            295,
            51267
          ],
          "temperature": 0,
          "avg_logprob": -0.041757178,
          "compression_ratio": 1.9136213,
          "no_speech_prob": 1.735061e-12
        },
        {
          "id": 91,
          "seek": 49758,
          "start": 515.62,
          "end": 522.58,
          "text": " the world um learn parts of the world model up to uh these innate reward functions and then actually",
          "tokens": [
            51267,
            264,
            1002,
            1105,
            1466,
            3166,
            295,
            264,
            1002,
            2316,
            493,
            281,
            2232,
            613,
            41766,
            7782,
            6828,
            293,
            550,
            767,
            51615
          ],
          "temperature": 0,
          "avg_logprob": -0.041757178,
          "compression_ratio": 1.9136213,
          "no_speech_prob": 1.735061e-12
        },
        {
          "id": 92,
          "seek": 49758,
          "start": 522.58,
          "end": 526.4,
          "text": " use that to then learn more right because next time i'm not going to try to piss off young lacuna",
          "tokens": [
            51615,
            764,
            300,
            281,
            550,
            1466,
            544,
            558,
            570,
            958,
            565,
            741,
            478,
            406,
            516,
            281,
            853,
            281,
            15171,
            766,
            2037,
            28027,
            5051,
            51806
          ],
          "temperature": 0,
          "avg_logprob": -0.041757178,
          "compression_ratio": 1.9136213,
          "no_speech_prob": 1.735061e-12
        },
        {
          "id": 93,
          "seek": 52640,
          "start": 526.4,
          "end": 533.6,
          "text": " if he emails me that i got this wrong um and so uh we're going to do further learning based on that",
          "tokens": [
            50365,
            498,
            415,
            12524,
            385,
            300,
            741,
            658,
            341,
            2085,
            1105,
            293,
            370,
            2232,
            321,
            434,
            516,
            281,
            360,
            3052,
            2539,
            2361,
            322,
            300,
            50725
          ],
          "temperature": 0,
          "avg_logprob": -0.095653065,
          "compression_ratio": 1.8577236,
          "no_speech_prob": 1.3147139e-12
        },
        {
          "id": 94,
          "seek": 52640,
          "start": 533.6,
          "end": 538.52,
          "text": " so in constructing the reward function it has to use a learned information but how can evolution",
          "tokens": [
            50725,
            370,
            294,
            39969,
            264,
            7782,
            2445,
            309,
            575,
            281,
            764,
            257,
            3264,
            1589,
            457,
            577,
            393,
            9303,
            50971
          ],
          "temperature": 0,
          "avg_logprob": -0.095653065,
          "compression_ratio": 1.8577236,
          "no_speech_prob": 1.3147139e-12
        },
        {
          "id": 95,
          "seek": 52640,
          "start": 538.52,
          "end": 543.32,
          "text": " evolution didn't know about yon lacun so how could how can it how can it do that and so",
          "tokens": [
            50971,
            9303,
            994,
            380,
            458,
            466,
            288,
            266,
            28027,
            409,
            370,
            577,
            727,
            577,
            393,
            309,
            577,
            393,
            309,
            360,
            300,
            293,
            370,
            51211
          ],
          "temperature": 0,
          "avg_logprob": -0.095653065,
          "compression_ratio": 1.8577236,
          "no_speech_prob": 1.3147139e-12
        },
        {
          "id": 96,
          "seek": 52640,
          "start": 543.32,
          "end": 549.6,
          "text": " uh the basic idea um that steve burns is proposing is that well part of the cortex",
          "tokens": [
            51211,
            2232,
            264,
            3875,
            1558,
            1105,
            300,
            2126,
            303,
            22684,
            307,
            29939,
            307,
            300,
            731,
            644,
            295,
            264,
            33312,
            51525
          ],
          "temperature": 0,
          "avg_logprob": -0.095653065,
          "compression_ratio": 1.8577236,
          "no_speech_prob": 1.3147139e-12
        },
        {
          "id": 97,
          "seek": 52640,
          "start": 549.6,
          "end": 555.14,
          "text": " or other areas like the amygdala that learn um what they're doing is they're modeling the",
          "tokens": [
            51525,
            420,
            661,
            3179,
            411,
            264,
            669,
            18103,
            67,
            5159,
            300,
            1466,
            1105,
            437,
            436,
            434,
            884,
            307,
            436,
            434,
            15983,
            264,
            51802
          ],
          "temperature": 0,
          "avg_logprob": -0.095653065,
          "compression_ratio": 1.8577236,
          "no_speech_prob": 1.3147139e-12
        },
        {
          "id": 98,
          "seek": 55514,
          "start": 555.14,
          "end": 558.7,
          "text": " steering subsystem. The steering subsystem is the part with these more innately programmed",
          "tokens": [
            50365,
            14823,
            2090,
            9321,
            13,
            440,
            14823,
            2090,
            9321,
            307,
            264,
            644,
            365,
            613,
            544,
            7714,
            1592,
            31092,
            50543
          ],
          "temperature": 0,
          "avg_logprob": -0.055431563,
          "compression_ratio": 1.902439,
          "no_speech_prob": 1.0240034e-12
        },
        {
          "id": 99,
          "seek": 55514,
          "start": 558.7,
          "end": 562.64,
          "text": " responses and the innate programming of these series of reward functions, cost functions,",
          "tokens": [
            50543,
            13019,
            293,
            264,
            41766,
            9410,
            295,
            613,
            2638,
            295,
            7782,
            6828,
            11,
            2063,
            6828,
            11,
            50740
          ],
          "temperature": 0,
          "avg_logprob": -0.055431563,
          "compression_ratio": 1.902439,
          "no_speech_prob": 1.0240034e-12
        },
        {
          "id": 100,
          "seek": 55514,
          "start": 562.78,
          "end": 567.94,
          "text": " bootstrapping functions that exist. So there are parts of the amygdala, for example, that are able",
          "tokens": [
            50747,
            11450,
            19639,
            3759,
            6828,
            300,
            2514,
            13,
            407,
            456,
            366,
            3166,
            295,
            264,
            669,
            18103,
            67,
            5159,
            11,
            337,
            1365,
            11,
            300,
            366,
            1075,
            51005
          ],
          "temperature": 0,
          "avg_logprob": -0.055431563,
          "compression_ratio": 1.902439,
          "no_speech_prob": 1.0240034e-12
        },
        {
          "id": 101,
          "seek": 55514,
          "start": 567.94,
          "end": 573.38,
          "text": " to monitor what those parts do and predict what those parts do. So how do you find the neurons",
          "tokens": [
            51005,
            281,
            6002,
            437,
            729,
            3166,
            360,
            293,
            6069,
            437,
            729,
            3166,
            360,
            13,
            407,
            577,
            360,
            291,
            915,
            264,
            22027,
            51277
          ],
          "temperature": 0,
          "avg_logprob": -0.055431563,
          "compression_ratio": 1.902439,
          "no_speech_prob": 1.0240034e-12
        },
        {
          "id": 102,
          "seek": 55514,
          "start": 573.38,
          "end": 578.96,
          "text": " that are important for social status? Well, you have some innate heuristics of social status,",
          "tokens": [
            51277,
            300,
            366,
            1021,
            337,
            2093,
            6558,
            30,
            1042,
            11,
            291,
            362,
            512,
            41766,
            415,
            374,
            6006,
            295,
            2093,
            6558,
            11,
            51556
          ],
          "temperature": 0,
          "avg_logprob": -0.055431563,
          "compression_ratio": 1.902439,
          "no_speech_prob": 1.0240034e-12
        },
        {
          "id": 103,
          "seek": 57896,
          "start": 578.96,
          "end": 586.78,
          "text": " for example, or you have some innate heuristics of friendliness that the steering subsystem can",
          "tokens": [
            50365,
            337,
            1365,
            11,
            420,
            291,
            362,
            512,
            41766,
            415,
            374,
            6006,
            295,
            1277,
            32268,
            300,
            264,
            14823,
            2090,
            9321,
            393,
            50756
          ],
          "temperature": 0,
          "avg_logprob": -0.05265316,
          "compression_ratio": 1.7066667,
          "no_speech_prob": 1.1290399e-12
        },
        {
          "id": 104,
          "seek": 57896,
          "start": 586.78,
          "end": 591.26,
          "text": " use. And the steering subsystem actually has its own sensory system, which is kind of crazy. So",
          "tokens": [
            50756,
            764,
            13,
            400,
            264,
            14823,
            2090,
            9321,
            767,
            575,
            1080,
            1065,
            27233,
            1185,
            11,
            597,
            307,
            733,
            295,
            3219,
            13,
            407,
            50980
          ],
          "temperature": 0,
          "avg_logprob": -0.05265316,
          "compression_ratio": 1.7066667,
          "no_speech_prob": 1.1290399e-12
        },
        {
          "id": 105,
          "seek": 57896,
          "start": 591.26,
          "end": 596.78,
          "text": " we think of vision as being something that the cortex does. But there's also a steering subsystem,",
          "tokens": [
            50980,
            321,
            519,
            295,
            5201,
            382,
            885,
            746,
            300,
            264,
            33312,
            775,
            13,
            583,
            456,
            311,
            611,
            257,
            14823,
            2090,
            9321,
            11,
            51256
          ],
          "temperature": 0,
          "avg_logprob": -0.05265316,
          "compression_ratio": 1.7066667,
          "no_speech_prob": 1.1290399e-12
        },
        {
          "id": 106,
          "seek": 57896,
          "start": 596.9,
          "end": 603.2,
          "text": " subcortical visual system called the superior colliculus with innate ability to detect faces,",
          "tokens": [
            51262,
            1422,
            66,
            477,
            804,
            5056,
            1185,
            1219,
            264,
            13028,
            1263,
            299,
            26107,
            365,
            41766,
            3485,
            281,
            5531,
            8475,
            11,
            51577
          ],
          "temperature": 0,
          "avg_logprob": -0.05265316,
          "compression_ratio": 1.7066667,
          "no_speech_prob": 1.1290399e-12
        },
        {
          "id": 107,
          "seek": 60320,
          "start": 603.2,
          "end": 611.1,
          "text": " for example, or threats. So there's a visual system that has innate heuristics and that the",
          "tokens": [
            50365,
            337,
            1365,
            11,
            420,
            14909,
            13,
            407,
            456,
            311,
            257,
            5056,
            1185,
            300,
            575,
            41766,
            415,
            374,
            6006,
            293,
            300,
            264,
            50760
          ],
          "temperature": 0,
          "avg_logprob": -0.065566376,
          "compression_ratio": 1.931174,
          "no_speech_prob": 1.1290771e-12
        },
        {
          "id": 108,
          "seek": 60320,
          "start": 611.1,
          "end": 614.74,
          "text": " steering subsystem has its own responses. So there'll be part of the amygdala or part of the",
          "tokens": [
            50760,
            14823,
            2090,
            9321,
            575,
            1080,
            1065,
            13019,
            13,
            407,
            456,
            603,
            312,
            644,
            295,
            264,
            669,
            18103,
            67,
            5159,
            420,
            644,
            295,
            264,
            50942
          ],
          "temperature": 0,
          "avg_logprob": -0.065566376,
          "compression_ratio": 1.931174,
          "no_speech_prob": 1.1290771e-12
        },
        {
          "id": 109,
          "seek": 60320,
          "start": 614.74,
          "end": 619.26,
          "text": " cortex that is learning to predict those responses. And so what are the neurons that matter in the",
          "tokens": [
            50942,
            33312,
            300,
            307,
            2539,
            281,
            6069,
            729,
            13019,
            13,
            400,
            370,
            437,
            366,
            264,
            22027,
            300,
            1871,
            294,
            264,
            51168
          ],
          "temperature": 0,
          "avg_logprob": -0.065566376,
          "compression_ratio": 1.931174,
          "no_speech_prob": 1.1290771e-12
        },
        {
          "id": 110,
          "seek": 60320,
          "start": 619.26,
          "end": 624.94,
          "text": " cortex for social status or for friendship? Well, they're the ones that predicts those innate",
          "tokens": [
            51168,
            33312,
            337,
            2093,
            6558,
            420,
            337,
            13216,
            30,
            1042,
            11,
            436,
            434,
            264,
            2306,
            300,
            6069,
            82,
            729,
            41766,
            51452
          ],
          "temperature": 0,
          "avg_logprob": -0.065566376,
          "compression_ratio": 1.931174,
          "no_speech_prob": 1.1290771e-12
        },
        {
          "id": 111,
          "seek": 60320,
          "start": 624.94,
          "end": 629.44,
          "text": " heuristics for friendship, right? So you train a predictor in the cortex and you say, which neurons",
          "tokens": [
            51452,
            415,
            374,
            6006,
            337,
            13216,
            11,
            558,
            30,
            407,
            291,
            3847,
            257,
            6069,
            284,
            294,
            264,
            33312,
            293,
            291,
            584,
            11,
            597,
            22027,
            51677
          ],
          "temperature": 0,
          "avg_logprob": -0.065566376,
          "compression_ratio": 1.931174,
          "no_speech_prob": 1.1290771e-12
        },
        {
          "id": 112,
          "seek": 62944,
          "start": 629.44,
          "end": 635.06,
          "text": " are part of the predictor uh those are the ones that are now it's now you've actually managed to",
          "tokens": [
            50365,
            366,
            644,
            295,
            264,
            6069,
            284,
            2232,
            729,
            366,
            264,
            2306,
            300,
            366,
            586,
            309,
            311,
            586,
            291,
            600,
            767,
            6453,
            281,
            50646
          ],
          "temperature": 0,
          "avg_logprob": -0.023213487,
          "compression_ratio": 1.7030568,
          "no_speech_prob": 1.2018629e-12
        },
        {
          "id": 113,
          "seek": 62944,
          "start": 635.06,
          "end": 640.86,
          "text": " wire it up yeah this is fascinating um i feel like i still don't understand i understand how",
          "tokens": [
            50646,
            6234,
            309,
            493,
            1338,
            341,
            307,
            10343,
            1105,
            741,
            841,
            411,
            741,
            920,
            500,
            380,
            1223,
            741,
            1223,
            577,
            50936
          ],
          "temperature": 0,
          "avg_logprob": -0.023213487,
          "compression_ratio": 1.7030568,
          "no_speech_prob": 1.2018629e-12
        },
        {
          "id": 114,
          "seek": 62944,
          "start": 640.86,
          "end": 649.96,
          "text": " the cortex could learn how this primitive part of the brain would respond to um so it can obviously",
          "tokens": [
            50936,
            264,
            33312,
            727,
            1466,
            577,
            341,
            28540,
            644,
            295,
            264,
            3567,
            576,
            4196,
            281,
            1105,
            370,
            309,
            393,
            2745,
            51391
          ],
          "temperature": 0,
          "avg_logprob": -0.023213487,
          "compression_ratio": 1.7030568,
          "no_speech_prob": 1.2018629e-12
        },
        {
          "id": 115,
          "seek": 62944,
          "start": 649.96,
          "end": 656.32,
          "text": " it has these labels on here's literally a picture of a spider and this is bad like be scared of this",
          "tokens": [
            51391,
            309,
            575,
            613,
            16949,
            322,
            510,
            311,
            3736,
            257,
            3036,
            295,
            257,
            17614,
            293,
            341,
            307,
            1578,
            411,
            312,
            5338,
            295,
            341,
            51709
          ],
          "temperature": 0,
          "avg_logprob": -0.023213487,
          "compression_ratio": 1.7030568,
          "no_speech_prob": 1.2018629e-12
        },
        {
          "id": 116,
          "seek": 65632,
          "start": 656.32,
          "end": 661.3,
          "text": " right and then the cortex learns that this is bad because the innate part tells it that but then",
          "tokens": [
            50365,
            558,
            293,
            550,
            264,
            33312,
            27152,
            300,
            341,
            307,
            1578,
            570,
            264,
            41766,
            644,
            5112,
            309,
            300,
            457,
            550,
            50614
          ],
          "temperature": 0,
          "avg_logprob": -0.06675836,
          "compression_ratio": 1.9407115,
          "no_speech_prob": 1.7080063e-12
        },
        {
          "id": 117,
          "seek": 65632,
          "start": 661.3,
          "end": 666.18,
          "text": " it has to generalize to okay the spider's on my back yes and somebody's telling me the spider's",
          "tokens": [
            50614,
            309,
            575,
            281,
            2674,
            1125,
            281,
            1392,
            264,
            17614,
            311,
            322,
            452,
            646,
            2086,
            293,
            2618,
            311,
            3585,
            385,
            264,
            17614,
            311,
            50858
          ],
          "temperature": 0,
          "avg_logprob": -0.06675836,
          "compression_ratio": 1.9407115,
          "no_speech_prob": 1.7080063e-12
        },
        {
          "id": 118,
          "seek": 65632,
          "start": 666.18,
          "end": 671.44,
          "text": " on your back that's also bad yes but it never got supervision on that right so how does it well it's",
          "tokens": [
            50858,
            322,
            428,
            646,
            300,
            311,
            611,
            1578,
            2086,
            457,
            309,
            1128,
            658,
            32675,
            322,
            300,
            558,
            370,
            577,
            775,
            309,
            731,
            309,
            311,
            51121
          ],
          "temperature": 0,
          "avg_logprob": -0.06675836,
          "compression_ratio": 1.9407115,
          "no_speech_prob": 1.7080063e-12
        },
        {
          "id": 119,
          "seek": 65632,
          "start": 671.44,
          "end": 677.88,
          "text": " because the learning subsystem um is a powerful learning algorithm that does have generalization",
          "tokens": [
            51121,
            570,
            264,
            2539,
            2090,
            9321,
            1105,
            307,
            257,
            4005,
            2539,
            9284,
            300,
            775,
            362,
            2674,
            2144,
            51443
          ],
          "temperature": 0,
          "avg_logprob": -0.06675836,
          "compression_ratio": 1.9407115,
          "no_speech_prob": 1.7080063e-12
        },
        {
          "id": 120,
          "seek": 65632,
          "start": 677.88,
          "end": 683.32,
          "text": " that is capable of generalization so the steering subsystem these are the innate responses so you're",
          "tokens": [
            51443,
            300,
            307,
            8189,
            295,
            2674,
            2144,
            370,
            264,
            14823,
            2090,
            9321,
            613,
            366,
            264,
            41766,
            13019,
            370,
            291,
            434,
            51715
          ],
          "temperature": 0,
          "avg_logprob": -0.06675836,
          "compression_ratio": 1.9407115,
          "no_speech_prob": 1.7080063e-12
        },
        {
          "id": 121,
          "seek": 68332,
          "start": 683.32,
          "end": 688.8,
          "text": " going to have some, let's say, built into your steering subsystem, these lower brain areas,",
          "tokens": [
            50365,
            516,
            281,
            362,
            512,
            11,
            718,
            311,
            584,
            11,
            3094,
            666,
            428,
            14823,
            2090,
            9321,
            11,
            613,
            3126,
            3567,
            3179,
            11,
            50639
          ],
          "temperature": 0,
          "avg_logprob": -0.072981656,
          "compression_ratio": 1.7027028,
          "no_speech_prob": 8.5551005e-13
        },
        {
          "id": 122,
          "seek": 68332,
          "start": 688.9,
          "end": 693.56,
          "text": " hypothalamus, brainstem, et cetera. And again, they include, they have their own primitive",
          "tokens": [
            50644,
            24371,
            23819,
            301,
            11,
            3567,
            1099,
            11,
            1030,
            11458,
            13,
            400,
            797,
            11,
            436,
            4090,
            11,
            436,
            362,
            641,
            1065,
            28540,
            50877
          ],
          "temperature": 0,
          "avg_logprob": -0.072981656,
          "compression_ratio": 1.7027028,
          "no_speech_prob": 8.5551005e-13
        },
        {
          "id": 123,
          "seek": 68332,
          "start": 693.56,
          "end": 700.6,
          "text": " sensory systems. So there may be an innate response. If I see something that's kind of",
          "tokens": [
            50877,
            27233,
            3652,
            13,
            407,
            456,
            815,
            312,
            364,
            41766,
            4134,
            13,
            759,
            286,
            536,
            746,
            300,
            311,
            733,
            295,
            51229
          ],
          "temperature": 0,
          "avg_logprob": -0.072981656,
          "compression_ratio": 1.7027028,
          "no_speech_prob": 8.5551005e-13
        },
        {
          "id": 124,
          "seek": 68332,
          "start": 700.6,
          "end": 704.64,
          "text": " moving fast toward my body that I didn't previously see was there and is kind of small",
          "tokens": [
            51229,
            2684,
            2370,
            7361,
            452,
            1772,
            300,
            286,
            994,
            380,
            8046,
            536,
            390,
            456,
            293,
            307,
            733,
            295,
            1359,
            51431
          ],
          "temperature": 0,
          "avg_logprob": -0.072981656,
          "compression_ratio": 1.7027028,
          "no_speech_prob": 8.5551005e-13
        },
        {
          "id": 125,
          "seek": 68332,
          "start": 704.64,
          "end": 708.52,
          "text": " and dark and high contrast, that might be an insect kind of skittering onto my body.",
          "tokens": [
            51431,
            293,
            2877,
            293,
            1090,
            8712,
            11,
            300,
            1062,
            312,
            364,
            13261,
            733,
            295,
            1110,
            3904,
            278,
            3911,
            452,
            1772,
            13,
            51625
          ],
          "temperature": 0,
          "avg_logprob": -0.072981656,
          "compression_ratio": 1.7027028,
          "no_speech_prob": 8.5551005e-13
        },
        {
          "id": 126,
          "seek": 70852,
          "start": 708.52,
          "end": 714.84,
          "text": " um i am going to like flinch right um and so there are these innate responses and so there's",
          "tokens": [
            50365,
            1105,
            741,
            669,
            516,
            281,
            411,
            932,
            12415,
            558,
            1105,
            293,
            370,
            456,
            366,
            613,
            41766,
            13019,
            293,
            370,
            456,
            311,
            50681
          ],
          "temperature": 0,
          "avg_logprob": -0.056792486,
          "compression_ratio": 2.0036101,
          "no_speech_prob": 1.832581e-12
        },
        {
          "id": 127,
          "seek": 70852,
          "start": 714.84,
          "end": 719.74,
          "text": " going to be some group of neurons let's say in the hypothalamus that is that i am flinching yeah",
          "tokens": [
            50681,
            516,
            281,
            312,
            512,
            1594,
            295,
            22027,
            718,
            311,
            584,
            294,
            264,
            24371,
            23819,
            301,
            300,
            307,
            300,
            741,
            669,
            932,
            12415,
            278,
            1338,
            50926
          ],
          "temperature": 0,
          "avg_logprob": -0.056792486,
          "compression_ratio": 2.0036101,
          "no_speech_prob": 1.832581e-12
        },
        {
          "id": 128,
          "seek": 70852,
          "start": 719.74,
          "end": 724.3,
          "text": " uh or i just flinched right right they're the i just flinched neurons in the hypothalamus",
          "tokens": [
            50926,
            2232,
            420,
            741,
            445,
            932,
            12415,
            292,
            558,
            558,
            436,
            434,
            264,
            741,
            445,
            932,
            12415,
            292,
            22027,
            294,
            264,
            24371,
            23819,
            301,
            51154
          ],
          "temperature": 0,
          "avg_logprob": -0.056792486,
          "compression_ratio": 2.0036101,
          "no_speech_prob": 1.832581e-12
        },
        {
          "id": 129,
          "seek": 70852,
          "start": 724.3,
          "end": 728.94,
          "text": " um so when you flinch first of all that a negative contribution to the reward function",
          "tokens": [
            51154,
            1105,
            370,
            562,
            291,
            932,
            12415,
            700,
            295,
            439,
            300,
            257,
            3671,
            13150,
            281,
            264,
            7782,
            2445,
            51386
          ],
          "temperature": 0,
          "avg_logprob": -0.056792486,
          "compression_ratio": 2.0036101,
          "no_speech_prob": 1.832581e-12
        },
        {
          "id": 130,
          "seek": 70852,
          "start": 728.94,
          "end": 734.34,
          "text": " you didn't want that to happen perhaps um but that's only happened that's a reward function",
          "tokens": [
            51386,
            291,
            994,
            380,
            528,
            300,
            281,
            1051,
            4317,
            1105,
            457,
            300,
            311,
            787,
            2011,
            300,
            311,
            257,
            7782,
            2445,
            51656
          ],
          "temperature": 0,
          "avg_logprob": -0.056792486,
          "compression_ratio": 2.0036101,
          "no_speech_prob": 1.832581e-12
        },
        {
          "id": 131,
          "seek": 70852,
          "start": 734.34,
          "end": 738.02,
          "text": " then that is it doesn't have any generalization in it so i'm going to avoid that exact situation",
          "tokens": [
            51656,
            550,
            300,
            307,
            309,
            1177,
            380,
            362,
            604,
            2674,
            2144,
            294,
            309,
            370,
            741,
            478,
            516,
            281,
            5042,
            300,
            1900,
            2590,
            51840
          ],
          "temperature": 0,
          "avg_logprob": -0.056792486,
          "compression_ratio": 2.0036101,
          "no_speech_prob": 1.832581e-12
        },
        {
          "id": 132,
          "seek": 73802,
          "start": 738.02,
          "end": 742.76,
          "text": " of the thing skittering toward me um and maybe i'm going to avoid some actions that lead to the",
          "tokens": [
            50365,
            295,
            264,
            551,
            1110,
            3904,
            278,
            7361,
            385,
            1105,
            293,
            1310,
            741,
            478,
            516,
            281,
            5042,
            512,
            5909,
            300,
            1477,
            281,
            264,
            50602
          ],
          "temperature": 0,
          "avg_logprob": -0.025309065,
          "compression_ratio": 1.9918033,
          "no_speech_prob": 1.4725862e-12
        },
        {
          "id": 133,
          "seek": 73802,
          "start": 742.76,
          "end": 747.54,
          "text": " thing skittering uh so that's that's something a generalization you can get what steve calls it is",
          "tokens": [
            50602,
            551,
            1110,
            3904,
            278,
            2232,
            370,
            300,
            311,
            300,
            311,
            746,
            257,
            2674,
            2144,
            291,
            393,
            483,
            437,
            2126,
            303,
            5498,
            309,
            307,
            50841
          ],
          "temperature": 0,
          "avg_logprob": -0.025309065,
          "compression_ratio": 1.9918033,
          "no_speech_prob": 1.4725862e-12
        },
        {
          "id": 134,
          "seek": 73802,
          "start": 747.54,
          "end": 752.26,
          "text": " downstream of the reward function um so i'm going to avoid the situation where the spider was",
          "tokens": [
            50841,
            30621,
            295,
            264,
            7782,
            2445,
            1105,
            370,
            741,
            478,
            516,
            281,
            5042,
            264,
            2590,
            689,
            264,
            17614,
            390,
            51077
          ],
          "temperature": 0,
          "avg_logprob": -0.025309065,
          "compression_ratio": 1.9918033,
          "no_speech_prob": 1.4725862e-12
        },
        {
          "id": 135,
          "seek": 73802,
          "start": 752.26,
          "end": 756.02,
          "text": " skittering toward me um but you're also going to do something else so there's going to be like a",
          "tokens": [
            51077,
            1110,
            3904,
            278,
            7361,
            385,
            1105,
            457,
            291,
            434,
            611,
            516,
            281,
            360,
            746,
            1646,
            370,
            456,
            311,
            516,
            281,
            312,
            411,
            257,
            51265
          ],
          "temperature": 0,
          "avg_logprob": -0.025309065,
          "compression_ratio": 1.9918033,
          "no_speech_prob": 1.4725862e-12
        },
        {
          "id": 136,
          "seek": 73802,
          "start": 756.02,
          "end": 764.16,
          "text": " part of your amygdala say that is saying okay um a few you know a few milliseconds you know hundreds",
          "tokens": [
            51265,
            644,
            295,
            428,
            669,
            18103,
            67,
            5159,
            584,
            300,
            307,
            1566,
            1392,
            1105,
            257,
            1326,
            291,
            458,
            257,
            1326,
            34184,
            291,
            458,
            6779,
            51672
          ],
          "temperature": 0,
          "avg_logprob": -0.025309065,
          "compression_ratio": 1.9918033,
          "no_speech_prob": 1.4725862e-12
        },
        {
          "id": 137,
          "seek": 76416,
          "start": 764.16,
          "end": 770.98,
          "text": " hundreds of milliseconds or seconds earlier um could i have predicted that flinching response",
          "tokens": [
            50365,
            6779,
            295,
            34184,
            420,
            3949,
            3071,
            1105,
            727,
            741,
            362,
            19147,
            300,
            932,
            12415,
            278,
            4134,
            50706
          ],
          "temperature": 0,
          "avg_logprob": -0.041954864,
          "compression_ratio": 1.9208333,
          "no_speech_prob": 1.064793e-12
        },
        {
          "id": 138,
          "seek": 76416,
          "start": 770.98,
          "end": 774.2,
          "text": " it's going to be it's going to be a group of neurons that is essentially a classifier of am",
          "tokens": [
            50706,
            309,
            311,
            516,
            281,
            312,
            309,
            311,
            516,
            281,
            312,
            257,
            1594,
            295,
            22027,
            300,
            307,
            4476,
            257,
            1508,
            9902,
            295,
            669,
            50867
          ],
          "temperature": 0,
          "avg_logprob": -0.041954864,
          "compression_ratio": 1.9208333,
          "no_speech_prob": 1.064793e-12
        },
        {
          "id": 139,
          "seek": 76416,
          "start": 774.2,
          "end": 778.52,
          "text": " i about to flinch um and i'm going to have classifiers for that for every important steering",
          "tokens": [
            50867,
            741,
            466,
            281,
            932,
            12415,
            1105,
            293,
            741,
            478,
            516,
            281,
            362,
            1508,
            23463,
            337,
            300,
            337,
            633,
            1021,
            14823,
            51083
          ],
          "temperature": 0,
          "avg_logprob": -0.041954864,
          "compression_ratio": 1.9208333,
          "no_speech_prob": 1.064793e-12
        },
        {
          "id": 140,
          "seek": 76416,
          "start": 778.52,
          "end": 782.88,
          "text": " subsystem variable that evolution needs to take care of am i about to flinch am i talking to a",
          "tokens": [
            51083,
            2090,
            9321,
            7006,
            300,
            9303,
            2203,
            281,
            747,
            1127,
            295,
            669,
            741,
            466,
            281,
            932,
            12415,
            669,
            741,
            1417,
            281,
            257,
            51301
          ],
          "temperature": 0,
          "avg_logprob": -0.041954864,
          "compression_ratio": 1.9208333,
          "no_speech_prob": 1.064793e-12
        },
        {
          "id": 141,
          "seek": 76416,
          "start": 782.88,
          "end": 787.46,
          "text": " friend should i laugh now is the friend high status whatever variables the hypothalamus",
          "tokens": [
            51301,
            1277,
            820,
            741,
            5801,
            586,
            307,
            264,
            1277,
            1090,
            6558,
            2035,
            9102,
            264,
            24371,
            23819,
            301,
            51530
          ],
          "temperature": 0,
          "avg_logprob": -0.041954864,
          "compression_ratio": 1.9208333,
          "no_speech_prob": 1.064793e-12
        },
        {
          "id": 142,
          "seek": 78746,
          "start": 787.46,
          "end": 794.26,
          "text": " brainstem contain? Um, am I about to taste salt? Um, so that's going to have, uh, all these variables",
          "tokens": [
            50365,
            3567,
            1099,
            5304,
            30,
            3301,
            11,
            669,
            286,
            466,
            281,
            3939,
            5139,
            30,
            3301,
            11,
            370,
            300,
            311,
            516,
            281,
            362,
            11,
            2232,
            11,
            439,
            613,
            9102,
            50705
          ],
          "temperature": 0,
          "avg_logprob": -0.053652275,
          "compression_ratio": 1.8333334,
          "no_speech_prob": 1.2348736e-12
        },
        {
          "id": 143,
          "seek": 78746,
          "start": 794.26,
          "end": 798.18,
          "text": " and for each one is going to have a predictor. It's going to train that predictor. Now the predictor",
          "tokens": [
            50705,
            293,
            337,
            1184,
            472,
            307,
            516,
            281,
            362,
            257,
            6069,
            284,
            13,
            467,
            311,
            516,
            281,
            3847,
            300,
            6069,
            284,
            13,
            823,
            264,
            6069,
            284,
            50901
          ],
          "temperature": 0,
          "avg_logprob": -0.053652275,
          "compression_ratio": 1.8333334,
          "no_speech_prob": 1.2348736e-12
        },
        {
          "id": 144,
          "seek": 78746,
          "start": 798.18,
          "end": 802.14,
          "text": " that it trains, that can have some generalization. And the reason it can have some generalizations",
          "tokens": [
            50901,
            300,
            309,
            16329,
            11,
            300,
            393,
            362,
            512,
            2674,
            2144,
            13,
            400,
            264,
            1778,
            309,
            393,
            362,
            512,
            2674,
            14455,
            51099
          ],
          "temperature": 0,
          "avg_logprob": -0.053652275,
          "compression_ratio": 1.8333334,
          "no_speech_prob": 1.2348736e-12
        },
        {
          "id": 145,
          "seek": 78746,
          "start": 802.14,
          "end": 806.82,
          "text": " because it just has a totally different input. So it's input data might be things like the word",
          "tokens": [
            51099,
            570,
            309,
            445,
            575,
            257,
            3879,
            819,
            4846,
            13,
            407,
            309,
            311,
            4846,
            1412,
            1062,
            312,
            721,
            411,
            264,
            1349,
            51333
          ],
          "temperature": 0,
          "avg_logprob": -0.053652275,
          "compression_ratio": 1.8333334,
          "no_speech_prob": 1.2348736e-12
        },
        {
          "id": 146,
          "seek": 78746,
          "start": 806.82,
          "end": 811.72,
          "text": " spider, right? But the word spider can activate in all sorts of situations that lead to the world",
          "tokens": [
            51333,
            17614,
            11,
            558,
            30,
            583,
            264,
            1349,
            17614,
            393,
            13615,
            294,
            439,
            7527,
            295,
            6851,
            300,
            1477,
            281,
            264,
            1002,
            51578
          ],
          "temperature": 0,
          "avg_logprob": -0.053652275,
          "compression_ratio": 1.8333334,
          "no_speech_prob": 1.2348736e-12
        },
        {
          "id": 147,
          "seek": 81172,
          "start": 811.72,
          "end": 814.3,
          "text": " word spider activating in your world model.",
          "tokens": [
            50365,
            1349,
            17614,
            42481,
            294,
            428,
            1002,
            2316,
            13,
            50494
          ],
          "temperature": 0,
          "avg_logprob": -0.18697113,
          "compression_ratio": 1.6550218,
          "no_speech_prob": 1.3144822e-12
        },
        {
          "id": 148,
          "seek": 81172,
          "start": 815.64,
          "end": 819.06,
          "text": " So, you know, if you have a complex world model with really complex features,",
          "tokens": [
            50561,
            407,
            11,
            291,
            458,
            11,
            498,
            291,
            362,
            257,
            3997,
            1002,
            2316,
            365,
            534,
            3997,
            4122,
            11,
            50732
          ],
          "temperature": 0,
          "avg_logprob": -0.18697113,
          "compression_ratio": 1.6550218,
          "no_speech_prob": 1.3144822e-12
        },
        {
          "id": 149,
          "seek": 820,
          "start": 819.16,
          "end": 837.646,
          "text": " that inherently gives you some generalization It not just the thing skittering toward me It even the word spider or the concept of spider is going to cause that to trigger And this predictor can learn that So whatever spider neurons are in my world model which could even be a book about spiders or somewhere a room where there are spiders or whatever that is",
          "tokens": [
            50737,
            300,
            27993,
            2709,
            291,
            512,
            2674,
            2144,
            13,
            50817,
            50824,
            467,
            311,
            406,
            445,
            264,
            551,
            1110,
            3904,
            278,
            7361,
            385,
            13,
            50902,
            50917,
            467,
            311,
            754,
            264,
            1349,
            17614,
            420,
            264,
            3410,
            295,
            17614,
            307,
            516,
            281,
            3082,
            300,
            281,
            7875,
            13,
            400,
            341,
            6069,
            284,
            393,
            1466,
            300,
            13,
            407,
            2035,
            17614,
            22027,
            366,
            294,
            452,
            1002,
            2316,
            11,
            597,
            727,
            754,
            312,
            257,
            1446,
            466,
            32171,
            420,
            4079,
            11,
            257,
            1808,
            689,
            456,
            366,
            32171,
            420,
            2035,
            300,
            307,
            13,
            51226
          ],
          "temperature": 0,
          "avg_logprob": -0.08914397,
          "compression_ratio": 1.6313131,
          "no_speech_prob": 2.343914e-12
        },
        {
          "id": 150,
          "seek": 2542,
          "start": 837.646,
          "end": 842.866,
          "text": " The amount of heebie-jeebies that this conversation is eliciting in the audience is like...",
          "tokens": [
            50365,
            440,
            2372,
            295,
            415,
            68,
            7392,
            12,
            73,
            1653,
            23177,
            300,
            341,
            3761,
            307,
            806,
            299,
            1748,
            294,
            264,
            4034,
            307,
            411,
            485,
            50626
          ],
          "temperature": 0,
          "avg_logprob": -0.19160311,
          "compression_ratio": 1.8205128,
          "no_speech_prob": 4.129253e-12
        },
        {
          "id": 151,
          "seek": 2542,
          "start": 842.866,
          "end": 844.866,
          "text": " So now I'm activating your steering subsystem.",
          "tokens": [
            50626,
            407,
            586,
            286,
            478,
            42481,
            428,
            14823,
            2090,
            9321,
            13,
            50726
          ],
          "temperature": 0,
          "avg_logprob": -0.19160311,
          "compression_ratio": 1.8205128,
          "no_speech_prob": 4.129253e-12
        },
        {
          "id": 152,
          "seek": 2542,
          "start": 845.38605,
          "end": 850.866,
          "text": " Your steering subsystem, spider hypothalamus, a subgroup of neurons of skittering insects,",
          "tokens": [
            50752,
            2260,
            14823,
            2090,
            9321,
            11,
            17614,
            24371,
            23819,
            301,
            11,
            257,
            1422,
            17377,
            295,
            22027,
            295,
            1110,
            3904,
            278,
            20201,
            11,
            51026
          ],
          "temperature": 0,
          "avg_logprob": -0.19160311,
          "compression_ratio": 1.8205128,
          "no_speech_prob": 4.129253e-12
        },
        {
          "id": 153,
          "seek": 2542,
          "start": 851.26605,
          "end": 853.76605,
          "text": " are activating based on these very abstract concepts in the conversation.",
          "tokens": [
            51046,
            366,
            42481,
            2361,
            322,
            613,
            588,
            12649,
            10392,
            294,
            264,
            3761,
            13,
            51171
          ],
          "temperature": 0,
          "avg_logprob": -0.19160311,
          "compression_ratio": 1.8205128,
          "no_speech_prob": 4.129253e-12
        },
        {
          "id": 154,
          "seek": 2542,
          "start": 853.76605,
          "end": 855.32605,
          "text": " If you keep going, I'm going to put in a trigger warning.",
          "tokens": [
            51171,
            759,
            291,
            1066,
            516,
            11,
            286,
            478,
            516,
            281,
            829,
            294,
            257,
            7875,
            9164,
            13,
            51249
          ],
          "temperature": 0,
          "avg_logprob": -0.19160311,
          "compression_ratio": 1.8205128,
          "no_speech_prob": 4.129253e-12
        },
        {
          "id": 155,
          "seek": 2542,
          "start": 856.226,
          "end": 858.20605,
          "text": " That's because you learned this.",
          "tokens": [
            51294,
            663,
            311,
            570,
            291,
            3264,
            341,
            13,
            51393
          ],
          "temperature": 0,
          "avg_logprob": -0.19160311,
          "compression_ratio": 1.8205128,
          "no_speech_prob": 4.129253e-12
        },
        {
          "id": 156,
          "seek": 2542,
          "start": 858.38605,
          "end": 861.486,
          "text": " And the cortex inherently has the ability to generalize",
          "tokens": [
            51402,
            400,
            264,
            33312,
            27993,
            575,
            264,
            3485,
            281,
            2674,
            1125,
            51557
          ],
          "temperature": 0,
          "avg_logprob": -0.19160311,
          "compression_ratio": 1.8205128,
          "no_speech_prob": 4.129253e-12
        },
        {
          "id": 157,
          "seek": 2542,
          "start": 861.486,
          "end": 863.926,
          "text": " because it's just predicting based on these very abstract variables",
          "tokens": [
            51557,
            570,
            309,
            311,
            445,
            32884,
            2361,
            322,
            613,
            588,
            12649,
            9102,
            51679
          ],
          "temperature": 0,
          "avg_logprob": -0.19160311,
          "compression_ratio": 1.8205128,
          "no_speech_prob": 4.129253e-12
        },
        {
          "id": 158,
          "seek": 2542,
          "start": 863.926,
          "end": 866.50604,
          "text": " and all these integrated information that it has.",
          "tokens": [
            51679,
            293,
            439,
            613,
            10919,
            1589,
            300,
            309,
            575,
            13,
            51808
          ],
          "temperature": 0,
          "avg_logprob": -0.19160311,
          "compression_ratio": 1.8205128,
          "no_speech_prob": 4.129253e-12
        },
        {
          "id": 159,
          "seek": 5428,
          "start": 866.50604,
          "end": 871.366,
          "text": " whereas the steering system only can use whatever the superior clikless and a few other sensors can",
          "tokens": [
            50365,
            9735,
            264,
            14823,
            1185,
            787,
            393,
            764,
            2035,
            264,
            13028,
            596,
            1035,
            1832,
            293,
            257,
            1326,
            661,
            14840,
            393,
            50608
          ],
          "temperature": 0,
          "avg_logprob": -0.11013456,
          "compression_ratio": 1.8273972,
          "no_speech_prob": 1.9278678e-12
        },
        {
          "id": 160,
          "seek": 5428,
          "start": 871.366,
          "end": 875.666,
          "text": " spit out so by the way it's remarkable that the person who's made this this connection between",
          "tokens": [
            50608,
            22127,
            484,
            370,
            538,
            264,
            636,
            309,
            311,
            12802,
            300,
            264,
            954,
            567,
            311,
            1027,
            341,
            341,
            4984,
            1296,
            50823
          ],
          "temperature": 0,
          "avg_logprob": -0.11013456,
          "compression_ratio": 1.8273972,
          "no_speech_prob": 1.9278678e-12
        },
        {
          "id": 161,
          "seek": 5428,
          "start": 875.666,
          "end": 879.666,
          "text": " different pieces of neuroscience steven burns like former physicist yeah has for the last few",
          "tokens": [
            50823,
            819,
            3755,
            295,
            42762,
            2126,
            553,
            22684,
            411,
            5819,
            42466,
            1338,
            575,
            337,
            264,
            1036,
            1326,
            51023
          ],
          "temperature": 0,
          "avg_logprob": -0.11013456,
          "compression_ratio": 1.8273972,
          "no_speech_prob": 1.9278678e-12
        },
        {
          "id": 162,
          "seek": 5428,
          "start": 879.666,
          "end": 882.88605,
          "text": " years has been trying to synthesize he's an ai safety researcher he's just synthesizing this",
          "tokens": [
            51023,
            924,
            575,
            668,
            1382,
            281,
            26617,
            1125,
            415,
            311,
            364,
            9783,
            4514,
            21751,
            415,
            311,
            445,
            26617,
            3319,
            341,
            51184
          ],
          "temperature": 0,
          "avg_logprob": -0.11013456,
          "compression_ratio": 1.8273972,
          "no_speech_prob": 1.9278678e-12
        },
        {
          "id": 163,
          "seek": 5428,
          "start": 882.88605,
          "end": 886.666,
          "text": " comes back to the academic incentives right i think that this is it's this is a little bit hard",
          "tokens": [
            51184,
            1487,
            646,
            281,
            264,
            7778,
            23374,
            558,
            741,
            519,
            300,
            341,
            307,
            309,
            311,
            341,
            307,
            257,
            707,
            857,
            1152,
            51373
          ],
          "temperature": 0,
          "avg_logprob": -0.11013456,
          "compression_ratio": 1.8273972,
          "no_speech_prob": 1.9278678e-12
        },
        {
          "id": 164,
          "seek": 5428,
          "start": 886.666,
          "end": 890.486,
          "text": " to say what's the exact next experiment how am i going to publish a paper on this how am i going",
          "tokens": [
            51373,
            281,
            584,
            437,
            311,
            264,
            1900,
            958,
            5120,
            577,
            669,
            741,
            516,
            281,
            11374,
            257,
            3035,
            322,
            341,
            577,
            669,
            741,
            516,
            51564
          ],
          "temperature": 0,
          "avg_logprob": -0.11013456,
          "compression_ratio": 1.8273972,
          "no_speech_prob": 1.9278678e-12
        },
        {
          "id": 165,
          "seek": 5428,
          "start": 890.486,
          "end": 894.12604,
          "text": " to train my grad student do this very very speculative but there's a lot in the neuroscience",
          "tokens": [
            51564,
            281,
            3847,
            452,
            2771,
            3107,
            360,
            341,
            588,
            588,
            49415,
            457,
            456,
            311,
            257,
            688,
            294,
            264,
            42762,
            51746
          ],
          "temperature": 0,
          "avg_logprob": -0.11013456,
          "compression_ratio": 1.8273972,
          "no_speech_prob": 1.9278678e-12
        },
        {
          "id": 166,
          "seek": 8190,
          "start": 894.12604,
          "end": 897.486,
          "text": " literature and steven has been able to pull this together and i think that steve has an answer to",
          "tokens": [
            50365,
            10394,
            293,
            2126,
            553,
            575,
            668,
            1075,
            281,
            2235,
            341,
            1214,
            293,
            741,
            519,
            300,
            2126,
            303,
            575,
            364,
            1867,
            281,
            50533
          ],
          "temperature": 0,
          "avg_logprob": -0.07959228,
          "compression_ratio": 1.7606177,
          "no_speech_prob": 3.504386e-12
        },
        {
          "id": 167,
          "seek": 8190,
          "start": 897.486,
          "end": 902.08606,
          "text": " elia's question essentially which is which is how does the brain ultimately code for these higher",
          "tokens": [
            50533,
            806,
            654,
            311,
            1168,
            4476,
            597,
            307,
            597,
            307,
            577,
            775,
            264,
            3567,
            6284,
            3089,
            337,
            613,
            2946,
            50763
          ],
          "temperature": 0,
          "avg_logprob": -0.07959228,
          "compression_ratio": 1.7606177,
          "no_speech_prob": 3.504386e-12
        },
        {
          "id": 168,
          "seek": 8190,
          "start": 902.08606,
          "end": 906.466,
          "text": " level desires and link them up to the more primitive rewards yeah very naive question",
          "tokens": [
            50763,
            1496,
            18005,
            293,
            2113,
            552,
            493,
            281,
            264,
            544,
            28540,
            17203,
            1338,
            588,
            29052,
            1168,
            50982
          ],
          "temperature": 0,
          "avg_logprob": -0.07959228,
          "compression_ratio": 1.7606177,
          "no_speech_prob": 3.504386e-12
        },
        {
          "id": 169,
          "seek": 8190,
          "start": 906.466,
          "end": 913.88605,
          "text": " but why can't we achieve this omnidirectional inference by just training the model to",
          "tokens": [
            50982,
            457,
            983,
            393,
            380,
            321,
            4584,
            341,
            36874,
            327,
            621,
            41048,
            38253,
            538,
            445,
            3097,
            264,
            2316,
            281,
            51353
          ],
          "temperature": 0,
          "avg_logprob": -0.07959228,
          "compression_ratio": 1.7606177,
          "no_speech_prob": 3.504386e-12
        },
        {
          "id": 170,
          "seek": 8190,
          "start": 913.88605,
          "end": 920.026,
          "text": " not just map from a token to next token but remove the masks right in the training so it",
          "tokens": [
            51353,
            406,
            445,
            4471,
            490,
            257,
            14862,
            281,
            958,
            14862,
            457,
            4159,
            264,
            11830,
            558,
            294,
            264,
            3097,
            370,
            309,
            51660
          ],
          "temperature": 0,
          "avg_logprob": -0.07959228,
          "compression_ratio": 1.7606177,
          "no_speech_prob": 3.504386e-12
        },
        {
          "id": 171,
          "seek": 10780,
          "start": 920.026,
          "end": 927.38605,
          "text": " maps every token to every token or come up with more labels between video and audio and text so",
          "tokens": [
            50365,
            11317,
            633,
            14862,
            281,
            633,
            14862,
            420,
            808,
            493,
            365,
            544,
            16949,
            1296,
            960,
            293,
            6278,
            293,
            2487,
            370,
            50733
          ],
          "temperature": 0,
          "avg_logprob": -0.08849215,
          "compression_ratio": 1.6844444,
          "no_speech_prob": 1.5921721e-12
        },
        {
          "id": 172,
          "seek": 10780,
          "start": 927.38605,
          "end": 933.286,
          "text": " that it is forced to map one to each one. I mean, that may be that may be the way. So it's not",
          "tokens": [
            50733,
            300,
            309,
            307,
            7579,
            281,
            4471,
            472,
            281,
            1184,
            472,
            13,
            286,
            914,
            11,
            300,
            815,
            312,
            300,
            815,
            312,
            264,
            636,
            13,
            407,
            309,
            311,
            406,
            51028
          ],
          "temperature": 0,
          "avg_logprob": -0.08849215,
          "compression_ratio": 1.6844444,
          "no_speech_prob": 1.5921721e-12
        },
        {
          "id": 173,
          "seek": 10780,
          "start": 933.286,
          "end": 940.62604,
          "text": " clear to me. Some people think that there's sort of a different way that it does probabilistic",
          "tokens": [
            51028,
            1850,
            281,
            385,
            13,
            2188,
            561,
            519,
            300,
            456,
            311,
            1333,
            295,
            257,
            819,
            636,
            300,
            309,
            775,
            31959,
            3142,
            51395
          ],
          "temperature": 0,
          "avg_logprob": -0.08849215,
          "compression_ratio": 1.6844444,
          "no_speech_prob": 1.5921721e-12
        },
        {
          "id": 174,
          "seek": 10780,
          "start": 940.62604,
          "end": 945.286,
          "text": " inference or different learning algorithm that isn't backprop. There might be like other ways",
          "tokens": [
            51395,
            38253,
            420,
            819,
            2539,
            9284,
            300,
            1943,
            380,
            646,
            79,
            1513,
            13,
            821,
            1062,
            312,
            411,
            661,
            2098,
            51628
          ],
          "temperature": 0,
          "avg_logprob": -0.08849215,
          "compression_ratio": 1.6844444,
          "no_speech_prob": 1.5921721e-12
        },
        {
          "id": 175,
          "seek": 13306,
          "start": 945.286,
          "end": 950.38605,
          "text": " of learning energy-based models or other things like that that you can imagine, but that's involved",
          "tokens": [
            50365,
            295,
            2539,
            2281,
            12,
            6032,
            5245,
            420,
            661,
            721,
            411,
            300,
            300,
            291,
            393,
            3811,
            11,
            457,
            300,
            311,
            3288,
            50620
          ],
          "temperature": 0,
          "avg_logprob": -0.092797026,
          "compression_ratio": 1.7619047,
          "no_speech_prob": 2.2275853e-12
        },
        {
          "id": 176,
          "seek": 13306,
          "start": 950.38605,
          "end": 953.766,
          "text": " in being able to do this and that the brain has that. But I think there's a version of it where",
          "tokens": [
            50620,
            294,
            885,
            1075,
            281,
            360,
            341,
            293,
            300,
            264,
            3567,
            575,
            300,
            13,
            583,
            286,
            519,
            456,
            311,
            257,
            3037,
            295,
            309,
            689,
            50789
          ],
          "temperature": 0,
          "avg_logprob": -0.092797026,
          "compression_ratio": 1.7619047,
          "no_speech_prob": 2.2275853e-12
        },
        {
          "id": 177,
          "seek": 13306,
          "start": 953.766,
          "end": 960.266,
          "text": " what the brain does is like crappy versions of backprop to learn to predict through a few layers.",
          "tokens": [
            50789,
            437,
            264,
            3567,
            775,
            307,
            411,
            36531,
            9606,
            295,
            646,
            79,
            1513,
            281,
            1466,
            281,
            6069,
            807,
            257,
            1326,
            7914,
            13,
            51114
          ],
          "temperature": 0,
          "avg_logprob": -0.092797026,
          "compression_ratio": 1.7619047,
          "no_speech_prob": 2.2275853e-12
        },
        {
          "id": 178,
          "seek": 13306,
          "start": 961.08606,
          "end": 965.306,
          "text": " And that, yeah, it's kind of like a multimodal foundation model. Yeah, so maybe the cortex is",
          "tokens": [
            51155,
            400,
            300,
            11,
            1338,
            11,
            309,
            311,
            733,
            295,
            411,
            257,
            32972,
            378,
            304,
            7030,
            2316,
            13,
            865,
            11,
            370,
            1310,
            264,
            33312,
            307,
            51366
          ],
          "temperature": 0,
          "avg_logprob": -0.092797026,
          "compression_ratio": 1.7619047,
          "no_speech_prob": 2.2275853e-12
        },
        {
          "id": 179,
          "seek": 13306,
          "start": 965.306,
          "end": 970.94604,
          "text": " just kind of like certain kinds of foundation models. LLMs are maybe just predicting the next",
          "tokens": [
            51366,
            445,
            733,
            295,
            411,
            1629,
            3685,
            295,
            7030,
            5245,
            13,
            441,
            43,
            26386,
            366,
            1310,
            445,
            32884,
            264,
            958,
            51648
          ],
          "temperature": 0,
          "avg_logprob": -0.092797026,
          "compression_ratio": 1.7619047,
          "no_speech_prob": 2.2275853e-12
        },
        {
          "id": 180,
          "seek": 15872,
          "start": 970.94604,
          "end": 975.06604,
          "text": " token, but, you know, vision models maybe are trained in learning to fill in the blanks or",
          "tokens": [
            50365,
            14862,
            11,
            457,
            11,
            291,
            458,
            11,
            5201,
            5245,
            1310,
            366,
            8895,
            294,
            2539,
            281,
            2836,
            294,
            264,
            8247,
            82,
            420,
            50571
          ],
          "temperature": 0,
          "avg_logprob": -0.08164483,
          "compression_ratio": 1.74613,
          "no_speech_prob": 1.846496e-12
        },
        {
          "id": 181,
          "seek": 15872,
          "start": 975.06604,
          "end": 980.226,
          "text": " reconstruct different pieces or combinations. But I think that it does it in an extremely flexible",
          "tokens": [
            50571,
            31499,
            819,
            3755,
            420,
            21267,
            13,
            583,
            286,
            519,
            300,
            309,
            775,
            309,
            294,
            364,
            4664,
            11358,
            50829
          ],
          "temperature": 0,
          "avg_logprob": -0.08164483,
          "compression_ratio": 1.74613,
          "no_speech_prob": 1.846496e-12
        },
        {
          "id": 182,
          "seek": 15872,
          "start": 980.226,
          "end": 984.866,
          "text": " way. So it's, you know, if you train a model to just fill in this blank at the center, okay,",
          "tokens": [
            50829,
            636,
            13,
            407,
            309,
            311,
            11,
            291,
            458,
            11,
            498,
            291,
            3847,
            257,
            2316,
            281,
            445,
            2836,
            294,
            341,
            8247,
            412,
            264,
            3056,
            11,
            1392,
            11,
            51061
          ],
          "temperature": 0,
          "avg_logprob": -0.08164483,
          "compression_ratio": 1.74613,
          "no_speech_prob": 1.846496e-12
        },
        {
          "id": 183,
          "seek": 15872,
          "start": 984.88605,
          "end": 988.20605,
          "text": " that's great. But what if you didn't train it to fill in this other blank over to the left,",
          "tokens": [
            51062,
            300,
            311,
            869,
            13,
            583,
            437,
            498,
            291,
            994,
            380,
            3847,
            309,
            281,
            2836,
            294,
            341,
            661,
            8247,
            670,
            281,
            264,
            1411,
            11,
            51228
          ],
          "temperature": 0,
          "avg_logprob": -0.08164483,
          "compression_ratio": 1.74613,
          "no_speech_prob": 1.846496e-12
        },
        {
          "id": 184,
          "seek": 15872,
          "start": 988.786,
          "end": 993.62604,
          "text": " then it doesn't know how to do that. It's not part of its like repertoire of predictions that",
          "tokens": [
            51257,
            550,
            309,
            1177,
            380,
            458,
            577,
            281,
            360,
            300,
            13,
            467,
            311,
            406,
            644,
            295,
            1080,
            411,
            49604,
            295,
            21264,
            300,
            51499
          ],
          "temperature": 0,
          "avg_logprob": -0.08164483,
          "compression_ratio": 1.74613,
          "no_speech_prob": 1.846496e-12
        },
        {
          "id": 185,
          "seek": 15872,
          "start": 993.62604,
          "end": 998.166,
          "text": " are like amortized into the network. Whereas with a really powerful inference system, you could",
          "tokens": [
            51499,
            366,
            411,
            669,
            477,
            1602,
            666,
            264,
            3209,
            13,
            13813,
            365,
            257,
            534,
            4005,
            38253,
            1185,
            11,
            291,
            727,
            51726
          ],
          "temperature": 0,
          "avg_logprob": -0.08164483,
          "compression_ratio": 1.74613,
          "no_speech_prob": 1.846496e-12
        },
        {
          "id": 186,
          "seek": 18594,
          "start": 998.166,
          "end": 1004.766,
          "text": " choose at test time, you know, what is the, you know, the subset of variables it needs to infer",
          "tokens": [
            50365,
            2826,
            412,
            1500,
            565,
            11,
            291,
            458,
            11,
            437,
            307,
            264,
            11,
            291,
            458,
            11,
            264,
            25993,
            295,
            9102,
            309,
            2203,
            281,
            13596,
            50695
          ],
          "temperature": 0,
          "avg_logprob": -0.13178626,
          "compression_ratio": 1.6681416,
          "no_speech_prob": 1.259531e-12
        },
        {
          "id": 187,
          "seek": 18594,
          "start": 1004.766,
          "end": 1010.846,
          "text": " and which ones are clamped. Okay, two sub questions. One, it makes you wonder whether",
          "tokens": [
            50695,
            293,
            597,
            2306,
            366,
            17690,
            292,
            13,
            1033,
            11,
            732,
            1422,
            1651,
            13,
            1485,
            11,
            309,
            1669,
            291,
            2441,
            1968,
            50999
          ],
          "temperature": 0,
          "avg_logprob": -0.13178626,
          "compression_ratio": 1.6681416,
          "no_speech_prob": 1.259531e-12
        },
        {
          "id": 188,
          "seek": 18594,
          "start": 1010.846,
          "end": 1015.06604,
          "text": " the thing that is lacking in artificial neural networks is less about the reward function and",
          "tokens": [
            50999,
            264,
            551,
            300,
            307,
            20889,
            294,
            11677,
            18161,
            9590,
            307,
            1570,
            466,
            264,
            7782,
            2445,
            293,
            51210
          ],
          "temperature": 0,
          "avg_logprob": -0.13178626,
          "compression_ratio": 1.6681416,
          "no_speech_prob": 1.259531e-12
        },
        {
          "id": 189,
          "seek": 18594,
          "start": 1015.06604,
          "end": 1025.206,
          "text": " more about the encoder or the embedding, which, like, maybe the issue is that you're not representing",
          "tokens": [
            51210,
            544,
            466,
            264,
            2058,
            19866,
            420,
            264,
            12240,
            3584,
            11,
            597,
            11,
            411,
            11,
            1310,
            264,
            2734,
            307,
            300,
            291,
            434,
            406,
            13460,
            51717
          ],
          "temperature": 0,
          "avg_logprob": -0.13178626,
          "compression_ratio": 1.6681416,
          "no_speech_prob": 1.259531e-12
        },
        {
          "id": 190,
          "seek": 21298,
          "start": 1025.206,
          "end": 1033.626,
          "text": " video and audio and text in the right latent abstraction such that they could intermingle",
          "tokens": [
            50365,
            960,
            293,
            6278,
            293,
            2487,
            294,
            264,
            558,
            48994,
            37765,
            1270,
            300,
            436,
            727,
            728,
            2810,
            306,
            50786
          ],
          "temperature": 0,
          "avg_logprob": -0.06972802,
          "compression_ratio": 1.9059234,
          "no_speech_prob": 1.3833229e-12
        },
        {
          "id": 191,
          "seek": 21298,
          "start": 1033.626,
          "end": 1039.886,
          "text": " and um conflict maybe this is also related to why llmc bad at drawing connections between",
          "tokens": [
            50786,
            293,
            1105,
            6596,
            1310,
            341,
            307,
            611,
            4077,
            281,
            983,
            4849,
            76,
            66,
            1578,
            412,
            6316,
            9271,
            1296,
            51099
          ],
          "temperature": 0,
          "avg_logprob": -0.06972802,
          "compression_ratio": 1.9059234,
          "no_speech_prob": 1.3833229e-12
        },
        {
          "id": 192,
          "seek": 21298,
          "start": 1039.886,
          "end": 1043.446,
          "text": " different ideas like it's like are the ideas represented at a level of generality",
          "tokens": [
            51099,
            819,
            3487,
            411,
            309,
            311,
            411,
            366,
            264,
            3487,
            10379,
            412,
            257,
            1496,
            295,
            1337,
            1860,
            51277
          ],
          "temperature": 0,
          "avg_logprob": -0.06972802,
          "compression_ratio": 1.9059234,
          "no_speech_prob": 1.3833229e-12
        },
        {
          "id": 193,
          "seek": 21298,
          "start": 1043.446,
          "end": 1047.9861,
          "text": " at which you could which you could notice well the problem is these questions are all co-mingled",
          "tokens": [
            51277,
            412,
            597,
            291,
            727,
            597,
            291,
            727,
            3449,
            731,
            264,
            1154,
            307,
            613,
            1651,
            366,
            439,
            598,
            12,
            2810,
            1493,
            51504
          ],
          "temperature": 0,
          "avg_logprob": -0.06972802,
          "compression_ratio": 1.9059234,
          "no_speech_prob": 1.3833229e-12
        },
        {
          "id": 194,
          "seek": 21298,
          "start": 1047.9861,
          "end": 1050.926,
          "text": " so if we don't know if it's doing a back prop like learning and we don't know if it's doing",
          "tokens": [
            51504,
            370,
            498,
            321,
            500,
            380,
            458,
            498,
            309,
            311,
            884,
            257,
            646,
            2365,
            411,
            2539,
            293,
            321,
            500,
            380,
            458,
            498,
            309,
            311,
            884,
            51651
          ],
          "temperature": 0,
          "avg_logprob": -0.06972802,
          "compression_ratio": 1.9059234,
          "no_speech_prob": 1.3833229e-12
        },
        {
          "id": 195,
          "seek": 21298,
          "start": 1050.926,
          "end": 1054.906,
          "text": " energy-based models and we don't know how these areas are even connected in the first place it's",
          "tokens": [
            51651,
            2281,
            12,
            6032,
            5245,
            293,
            321,
            500,
            380,
            458,
            577,
            613,
            3179,
            366,
            754,
            4582,
            294,
            264,
            700,
            1081,
            309,
            311,
            51850
          ],
          "temperature": 0,
          "avg_logprob": -0.06972802,
          "compression_ratio": 1.9059234,
          "no_speech_prob": 1.3833229e-12
        },
        {
          "id": 196,
          "seek": 24268,
          "start": 1054.906,
          "end": 1059.126,
          "text": " like very hard to like really get to the ground truth of this but yeah it's possible i mean",
          "tokens": [
            50365,
            411,
            588,
            1152,
            281,
            411,
            534,
            483,
            281,
            264,
            2727,
            3494,
            295,
            341,
            457,
            1338,
            309,
            311,
            1944,
            741,
            914,
            50576
          ],
          "temperature": 0,
          "avg_logprob": -0.06253602,
          "compression_ratio": 1.7951807,
          "no_speech_prob": 1.5674949e-12
        },
        {
          "id": 197,
          "seek": 24268,
          "start": 1059.126,
          "end": 1063.146,
          "text": " i think that people have done some work my friend joel de pello actually did something",
          "tokens": [
            50576,
            741,
            519,
            300,
            561,
            362,
            1096,
            512,
            589,
            452,
            1277,
            1488,
            338,
            368,
            520,
            1913,
            767,
            630,
            746,
            50777
          ],
          "temperature": 0,
          "avg_logprob": -0.06253602,
          "compression_ratio": 1.7951807,
          "no_speech_prob": 1.5674949e-12
        },
        {
          "id": 198,
          "seek": 24268,
          "start": 1063.146,
          "end": 1073.006,
          "text": " some years ago where um i think he put a model i think it was a model of v1 um of sort of",
          "tokens": [
            50777,
            512,
            924,
            2057,
            689,
            1105,
            741,
            519,
            415,
            829,
            257,
            2316,
            741,
            519,
            309,
            390,
            257,
            2316,
            295,
            371,
            16,
            1105,
            295,
            1333,
            295,
            51270
          ],
          "temperature": 0,
          "avg_logprob": -0.06253602,
          "compression_ratio": 1.7951807,
          "no_speech_prob": 1.5674949e-12
        },
        {
          "id": 199,
          "seek": 24268,
          "start": 1073.006,
          "end": 1078.266,
          "text": " specifically how the the early visual cortex represents images and put that as like an input",
          "tokens": [
            51270,
            4682,
            577,
            264,
            264,
            2440,
            5056,
            33312,
            8855,
            5267,
            293,
            829,
            300,
            382,
            411,
            364,
            4846,
            51533
          ],
          "temperature": 0,
          "avg_logprob": -0.06253602,
          "compression_ratio": 1.7951807,
          "no_speech_prob": 1.5674949e-12
        },
        {
          "id": 200,
          "seek": 24268,
          "start": 1078.266,
          "end": 1081.686,
          "text": " into like a conf net and that like improves something so it could be it could be like",
          "tokens": [
            51533,
            666,
            411,
            257,
            1497,
            2533,
            293,
            300,
            411,
            24771,
            746,
            370,
            309,
            727,
            312,
            309,
            727,
            312,
            411,
            51704
          ],
          "temperature": 0,
          "avg_logprob": -0.06253602,
          "compression_ratio": 1.7951807,
          "no_speech_prob": 1.5674949e-12
        },
        {
          "id": 201,
          "seek": 26946,
          "start": 1081.686,
          "end": 1086.4661,
          "text": " differences. The retina is also doing, you know, motion detection and certain things are kind of",
          "tokens": [
            50365,
            7300,
            13,
            440,
            1533,
            1426,
            307,
            611,
            884,
            11,
            291,
            458,
            11,
            5394,
            17784,
            293,
            1629,
            721,
            366,
            733,
            295,
            50604
          ],
          "temperature": 0,
          "avg_logprob": -0.078638434,
          "compression_ratio": 1.9186441,
          "no_speech_prob": 1.3148279e-12
        },
        {
          "id": 202,
          "seek": 26946,
          "start": 1086.4661,
          "end": 1091.286,
          "text": " getting filtered out. So there may be some pre-processing of the sensory data. There may be",
          "tokens": [
            50604,
            1242,
            37111,
            484,
            13,
            407,
            456,
            815,
            312,
            512,
            659,
            12,
            41075,
            278,
            295,
            264,
            27233,
            1412,
            13,
            821,
            815,
            312,
            50845
          ],
          "temperature": 0,
          "avg_logprob": -0.078638434,
          "compression_ratio": 1.9186441,
          "no_speech_prob": 1.3148279e-12
        },
        {
          "id": 203,
          "seek": 26946,
          "start": 1091.286,
          "end": 1097.7261,
          "text": " some clever combinations of which modalities are predicting which or so on that lead to better",
          "tokens": [
            50845,
            512,
            13494,
            21267,
            295,
            597,
            1072,
            16110,
            366,
            32884,
            597,
            420,
            370,
            322,
            300,
            1477,
            281,
            1101,
            51167
          ],
          "temperature": 0,
          "avg_logprob": -0.078638434,
          "compression_ratio": 1.9186441,
          "no_speech_prob": 1.3148279e-12
        },
        {
          "id": 204,
          "seek": 26946,
          "start": 1097.7261,
          "end": 1100.826,
          "text": " representation. There may be much more clever things than that. Some people certainly do think",
          "tokens": [
            51167,
            10290,
            13,
            821,
            815,
            312,
            709,
            544,
            13494,
            721,
            813,
            300,
            13,
            2188,
            561,
            3297,
            360,
            519,
            51322
          ],
          "temperature": 0,
          "avg_logprob": -0.078638434,
          "compression_ratio": 1.9186441,
          "no_speech_prob": 1.3148279e-12
        },
        {
          "id": 205,
          "seek": 26946,
          "start": 1100.826,
          "end": 1105.666,
          "text": " that there's inductive biases built in the architecture that will shape the representations,",
          "tokens": [
            51322,
            300,
            456,
            311,
            31612,
            488,
            32152,
            3094,
            294,
            264,
            9482,
            300,
            486,
            3909,
            264,
            33358,
            11,
            51564
          ],
          "temperature": 0,
          "avg_logprob": -0.078638434,
          "compression_ratio": 1.9186441,
          "no_speech_prob": 1.3148279e-12
        },
        {
          "id": 206,
          "seek": 26946,
          "start": 1106.106,
          "end": 1111.006,
          "text": " you know, differently or that there are clever things that you can do. So Astera, which is the",
          "tokens": [
            51586,
            291,
            458,
            11,
            7614,
            420,
            300,
            456,
            366,
            13494,
            721,
            300,
            291,
            393,
            360,
            13,
            407,
            12884,
            1663,
            11,
            597,
            307,
            264,
            51831
          ],
          "temperature": 0,
          "avg_logprob": -0.078638434,
          "compression_ratio": 1.9186441,
          "no_speech_prob": 1.3148279e-12
        },
        {
          "id": 207,
          "seek": 29878,
          "start": 1111.006,
          "end": 1116.9861,
          "text": " the same organization that employs Steve Behrens just launched this neuroscience project based on Doris Soh's work.",
          "tokens": [
            50365,
            264,
            912,
            4475,
            300,
            846,
            49522,
            7466,
            13068,
            1095,
            82,
            445,
            8730,
            341,
            42762,
            1716,
            2361,
            322,
            13643,
            271,
            407,
            71,
            311,
            589,
            13,
            50664
          ],
          "temperature": 0,
          "avg_logprob": -0.13175501,
          "compression_ratio": 1.6206896,
          "no_speech_prob": 1.2843738e-12
        },
        {
          "id": 208,
          "seek": 29878,
          "start": 1116.9861,
          "end": 1124.286,
          "text": " And she has some ideas about how you can build vision systems that basically require less training.",
          "tokens": [
            50664,
            400,
            750,
            575,
            512,
            3487,
            466,
            577,
            291,
            393,
            1322,
            5201,
            3652,
            300,
            1936,
            3651,
            1570,
            3097,
            13,
            51029
          ],
          "temperature": 0,
          "avg_logprob": -0.13175501,
          "compression_ratio": 1.6206896,
          "no_speech_prob": 1.2843738e-12
        },
        {
          "id": 209,
          "seek": 29878,
          "start": 1124.446,
          "end": 1134.2461,
          "text": " They put in, they in build into the assumptions of the design of the architecture that things like objects are bounded by surfaces.",
          "tokens": [
            51037,
            814,
            829,
            294,
            11,
            436,
            294,
            1322,
            666,
            264,
            17695,
            295,
            264,
            1715,
            295,
            264,
            9482,
            300,
            721,
            411,
            6565,
            366,
            37498,
            538,
            16130,
            13,
            51527
          ],
          "temperature": 0,
          "avg_logprob": -0.13175501,
          "compression_ratio": 1.6206896,
          "no_speech_prob": 1.2843738e-12
        },
        {
          "id": 210,
          "seek": 29878,
          "start": 1134.586,
          "end": 1139.7261,
          "text": " And, you know, surfaces have certain types of shapes and relationships of how they occlude each other and stuff like that.",
          "tokens": [
            51544,
            400,
            11,
            291,
            458,
            11,
            16130,
            362,
            1629,
            3467,
            295,
            10854,
            293,
            6159,
            295,
            577,
            436,
            2678,
            32334,
            1184,
            661,
            293,
            1507,
            411,
            300,
            13,
            51801
          ],
          "temperature": 0,
          "avg_logprob": -0.13175501,
          "compression_ratio": 1.6206896,
          "no_speech_prob": 1.2843738e-12
        },
        {
          "id": 211,
          "seek": 32750,
          "start": 1139.7261,
          "end": 1142.806,
          "text": " So it may be possible to build more assumptions into the network.",
          "tokens": [
            50365,
            407,
            309,
            815,
            312,
            1944,
            281,
            1322,
            544,
            17695,
            666,
            264,
            3209,
            13,
            50519
          ],
          "temperature": 0,
          "avg_logprob": -0.09830847,
          "compression_ratio": 1.5986159,
          "no_speech_prob": 1.1114367e-12
        },
        {
          "id": 212,
          "seek": 32750,
          "start": 1143.4661,
          "end": 1146.026,
          "text": " Evolution may have also put some changes of architecture.",
          "tokens": [
            50552,
            40800,
            815,
            362,
            611,
            829,
            512,
            2962,
            295,
            9482,
            13,
            50680
          ],
          "temperature": 0,
          "avg_logprob": -0.09830847,
          "compression_ratio": 1.5986159,
          "no_speech_prob": 1.1114367e-12
        },
        {
          "id": 213,
          "seek": 32750,
          "start": 1148.146,
          "end": 1153.666,
          "text": " It's just I think that also the cost functions and so on may be a key thing that it does.",
          "tokens": [
            50786,
            467,
            311,
            445,
            286,
            519,
            300,
            611,
            264,
            2063,
            6828,
            293,
            370,
            322,
            815,
            312,
            257,
            2141,
            551,
            300,
            309,
            775,
            13,
            51062
          ],
          "temperature": 0,
          "avg_logprob": -0.09830847,
          "compression_ratio": 1.5986159,
          "no_speech_prob": 1.1114367e-12
        },
        {
          "id": 214,
          "seek": 32750,
          "start": 1154.386,
          "end": 1161.286,
          "text": " So Andy Jones has this amazing 2021 paper where he uses AlphaZero to show that you can trade off test time compute and training compute.",
          "tokens": [
            51098,
            407,
            13285,
            10512,
            575,
            341,
            2243,
            7201,
            3035,
            689,
            415,
            4960,
            20588,
            57,
            2032,
            281,
            855,
            300,
            291,
            393,
            4923,
            766,
            1500,
            565,
            14722,
            293,
            3097,
            14722,
            13,
            51443
          ],
          "temperature": 0,
          "avg_logprob": -0.09830847,
          "compression_ratio": 1.5986159,
          "no_speech_prob": 1.1114367e-12
        },
        {
          "id": 215,
          "seek": 32750,
          "start": 1161.806,
          "end": 1166.206,
          "text": " And while that might seem obvious now, this was three years before people were talking about inference scaling.",
          "tokens": [
            51469,
            400,
            1339,
            300,
            1062,
            1643,
            6322,
            586,
            11,
            341,
            390,
            1045,
            924,
            949,
            561,
            645,
            1417,
            466,
            38253,
            21589,
            13,
            51689
          ],
          "temperature": 0,
          "avg_logprob": -0.09830847,
          "compression_ratio": 1.5986159,
          "no_speech_prob": 1.1114367e-12
        },
        {
          "id": 216,
          "seek": 35398,
          "start": 1166.206,
          "end": 1170.806,
          "text": " So this got me thinking, is there an experiment you could run today, even if it's a toy experiment,",
          "tokens": [
            50365,
            407,
            341,
            658,
            385,
            1953,
            11,
            307,
            456,
            364,
            5120,
            291,
            727,
            1190,
            965,
            11,
            754,
            498,
            309,
            311,
            257,
            12058,
            5120,
            11,
            50595
          ],
          "temperature": 0,
          "avg_logprob": -0.113680325,
          "compression_ratio": 1.7366863,
          "no_speech_prob": 2.1592045e-12
        },
        {
          "id": 217,
          "seek": 35398,
          "start": 1171.106,
          "end": 1173.786,
          "text": " which would help you anticipate the next scaling paradigm?",
          "tokens": [
            50610,
            597,
            576,
            854,
            291,
            21685,
            264,
            958,
            21589,
            24709,
            30,
            50744
          ],
          "temperature": 0,
          "avg_logprob": -0.113680325,
          "compression_ratio": 1.7366863,
          "no_speech_prob": 2.1592045e-12
        },
        {
          "id": 218,
          "seek": 35398,
          "start": 1174.086,
          "end": 1176.766,
          "text": " One idea I had was to see if there was anything to multi-agent scaling.",
          "tokens": [
            50759,
            1485,
            1558,
            286,
            632,
            390,
            281,
            536,
            498,
            456,
            390,
            1340,
            281,
            4825,
            12,
            559,
            317,
            21589,
            13,
            50893
          ],
          "temperature": 0,
          "avg_logprob": -0.113680325,
          "compression_ratio": 1.7366863,
          "no_speech_prob": 2.1592045e-12
        },
        {
          "id": 219,
          "seek": 35398,
          "start": 1177.186,
          "end": 1179.166,
          "text": " Basically, if you have a fixed budget of training compute,",
          "tokens": [
            50914,
            8537,
            11,
            498,
            291,
            362,
            257,
            6806,
            4706,
            295,
            3097,
            14722,
            11,
            51013
          ],
          "temperature": 0,
          "avg_logprob": -0.113680325,
          "compression_ratio": 1.7366863,
          "no_speech_prob": 2.1592045e-12
        },
        {
          "id": 220,
          "seek": 35398,
          "start": 1179.526,
          "end": 1184.326,
          "text": " are you going to get the smartest agent by dumping all of it into training one single agent,",
          "tokens": [
            51031,
            366,
            291,
            516,
            281,
            483,
            264,
            41491,
            9461,
            538,
            42224,
            439,
            295,
            309,
            666,
            3097,
            472,
            2167,
            9461,
            11,
            51271
          ],
          "temperature": 0,
          "avg_logprob": -0.113680325,
          "compression_ratio": 1.7366863,
          "no_speech_prob": 2.1592045e-12
        },
        {
          "id": 221,
          "seek": 35398,
          "start": 1184.546,
          "end": 1186.906,
          "text": " or by sliding that compute up amongst a bunch of models,",
          "tokens": [
            51282,
            420,
            538,
            21169,
            300,
            14722,
            493,
            12918,
            257,
            3840,
            295,
            5245,
            11,
            51400
          ],
          "temperature": 0,
          "avg_logprob": -0.113680325,
          "compression_ratio": 1.7366863,
          "no_speech_prob": 2.1592045e-12
        },
        {
          "id": 222,
          "seek": 35398,
          "start": 1187.266,
          "end": 1190.186,
          "text": " resulting in a diversity of strategies that get to play off each other?",
          "tokens": [
            51418,
            16505,
            294,
            257,
            8811,
            295,
            9029,
            300,
            483,
            281,
            862,
            766,
            1184,
            661,
            30,
            51564
          ],
          "temperature": 0,
          "avg_logprob": -0.113680325,
          "compression_ratio": 1.7366863,
          "no_speech_prob": 2.1592045e-12
        },
        {
          "id": 223,
          "seek": 35398,
          "start": 1190.326,
          "end": 1192.826,
          "text": " I didn't know how to turn this question into a concrete experiment, though,",
          "tokens": [
            51571,
            286,
            994,
            380,
            458,
            577,
            281,
            1261,
            341,
            1168,
            666,
            257,
            9859,
            5120,
            11,
            1673,
            11,
            51696
          ],
          "temperature": 0,
          "avg_logprob": -0.113680325,
          "compression_ratio": 1.7366863,
          "no_speech_prob": 2.1592045e-12
        },
        {
          "id": 224,
          "seek": 38060,
          "start": 1192.826,
          "end": 1196.306,
          "text": " So I started brainstorming with Gemini 3 Pro in the Gemini app.",
          "tokens": [
            50365,
            407,
            286,
            1409,
            35245,
            278,
            365,
            22894,
            3812,
            805,
            1705,
            294,
            264,
            22894,
            3812,
            724,
            13,
            50539
          ],
          "temperature": 0,
          "avg_logprob": -0.2037933,
          "compression_ratio": 1.6625767,
          "no_speech_prob": 1.9054855e-12
        },
        {
          "id": 225,
          "seek": 38060,
          "start": 1196.706,
          "end": 1199.506,
          "text": " Gemini helped me think through a bunch of different judgment calls.",
          "tokens": [
            50559,
            22894,
            3812,
            4254,
            385,
            519,
            807,
            257,
            3840,
            295,
            819,
            12216,
            5498,
            13,
            50699
          ],
          "temperature": 0,
          "avg_logprob": -0.2037933,
          "compression_ratio": 1.6625767,
          "no_speech_prob": 1.9054855e-12
        },
        {
          "id": 226,
          "seek": 38060,
          "start": 1199.7261,
          "end": 1203.506,
          "text": " For example, how do you turn the training loop from self-play to this kind of",
          "tokens": [
            50710,
            1171,
            1365,
            11,
            577,
            360,
            291,
            1261,
            264,
            3097,
            6367,
            490,
            2698,
            12,
            2858,
            281,
            341,
            733,
            295,
            50899
          ],
          "temperature": 0,
          "avg_logprob": -0.2037933,
          "compression_ratio": 1.6625767,
          "no_speech_prob": 1.9054855e-12
        },
        {
          "id": 227,
          "seek": 38060,
          "start": 1203.666,
          "end": 1205.146,
          "text": " co-evolutionary league training?",
          "tokens": [
            50907,
            598,
            12,
            13379,
            3386,
            822,
            14957,
            3097,
            30,
            50981
          ],
          "temperature": 0,
          "avg_logprob": -0.2037933,
          "compression_ratio": 1.6625767,
          "no_speech_prob": 1.9054855e-12
        },
        {
          "id": 228,
          "seek": 38060,
          "start": 1205.4661,
          "end": 1210.3461,
          "text": " How do you initialize and then maintain diversity amongst different AlphaZero agents?",
          "tokens": [
            50997,
            1012,
            360,
            291,
            5883,
            1125,
            293,
            550,
            6909,
            8811,
            12918,
            819,
            20588,
            57,
            2032,
            12554,
            30,
            51241
          ],
          "temperature": 0,
          "avg_logprob": -0.2037933,
          "compression_ratio": 1.6625767,
          "no_speech_prob": 1.9054855e-12
        },
        {
          "id": 229,
          "seek": 38060,
          "start": 1210.386,
          "end": 1213.186,
          "text": " How do you even split up the compute between these agents in the first place?",
          "tokens": [
            51243,
            1012,
            360,
            291,
            754,
            7472,
            493,
            264,
            14722,
            1296,
            613,
            12554,
            294,
            264,
            700,
            1081,
            30,
            51383
          ],
          "temperature": 0,
          "avg_logprob": -0.2037933,
          "compression_ratio": 1.6625767,
          "no_speech_prob": 1.9054855e-12
        },
        {
          "id": 230,
          "seek": 38060,
          "start": 1213.3461,
          "end": 1218.186,
          "text": " I found this clean implementation of AlphaGo Zero, which I then forked and opened up in",
          "tokens": [
            51391,
            286,
            1352,
            341,
            2541,
            11420,
            295,
            20588,
            12104,
            17182,
            11,
            597,
            286,
            550,
            17716,
            292,
            293,
            5625,
            493,
            294,
            51633
          ],
          "temperature": 0,
          "avg_logprob": -0.2037933,
          "compression_ratio": 1.6625767,
          "no_speech_prob": 1.9054855e-12
        },
        {
          "id": 231,
          "seek": 38060,
          "start": 1218.186,
          "end": 1221.3461,
          "text": " Antigravity, which is Google's agent first IDE.",
          "tokens": [
            51633,
            5130,
            328,
            13404,
            507,
            11,
            597,
            307,
            3329,
            311,
            9461,
            700,
            40930,
            13,
            51791
          ],
          "temperature": 0,
          "avg_logprob": -0.2037933,
          "compression_ratio": 1.6625767,
          "no_speech_prob": 1.9054855e-12
        },
        {
          "id": 232,
          "seek": 40912,
          "start": 1221.3461,
          "end": 1227.886,
          "text": " The code was originally written in 2017, and it was meant to be trained on a single GPU of that time.",
          "tokens": [
            50365,
            440,
            3089,
            390,
            7993,
            3720,
            294,
            6591,
            11,
            293,
            309,
            390,
            4140,
            281,
            312,
            8895,
            322,
            257,
            2167,
            18407,
            295,
            300,
            565,
            13,
            50692
          ],
          "temperature": 0,
          "avg_logprob": -0.111680396,
          "compression_ratio": 1.6773163,
          "no_speech_prob": 5.215628e-12
        },
        {
          "id": 233,
          "seek": 40912,
          "start": 1228.126,
          "end": 1234.026,
          "text": " But I needed to train multiple whole separate populations of AlphaZero agents, so I needed to speed things up.",
          "tokens": [
            50704,
            583,
            286,
            2978,
            281,
            3847,
            3866,
            1379,
            4994,
            12822,
            295,
            20588,
            57,
            2032,
            12554,
            11,
            370,
            286,
            2978,
            281,
            3073,
            721,
            493,
            13,
            50999
          ],
          "temperature": 0,
          "avg_logprob": -0.111680396,
          "compression_ratio": 1.6773163,
          "no_speech_prob": 5.215628e-12
        },
        {
          "id": 234,
          "seek": 40912,
          "start": 1234.3461,
          "end": 1241.426,
          "text": " I rented a beefcake of a GPU node, but I needed to refactor the whole implementation to take advantage of all this scale and parallelism.",
          "tokens": [
            51015,
            286,
            32381,
            257,
            9256,
            13994,
            295,
            257,
            18407,
            9984,
            11,
            457,
            286,
            2978,
            281,
            1895,
            15104,
            264,
            1379,
            11420,
            281,
            747,
            5002,
            295,
            439,
            341,
            4373,
            293,
            8952,
            1434,
            13,
            51369
          ],
          "temperature": 0,
          "avg_logprob": -0.111680396,
          "compression_ratio": 1.6773163,
          "no_speech_prob": 5.215628e-12
        },
        {
          "id": 235,
          "seek": 40912,
          "start": 1241.826,
          "end": 1244.046,
          "text": " Gemini suggested two different ways to parallelize self-play.",
          "tokens": [
            51389,
            22894,
            3812,
            10945,
            732,
            819,
            2098,
            281,
            8952,
            1125,
            2698,
            12,
            2858,
            13,
            51500
          ],
          "temperature": 0,
          "avg_logprob": -0.111680396,
          "compression_ratio": 1.6773163,
          "no_speech_prob": 5.215628e-12
        },
        {
          "id": 236,
          "seek": 40912,
          "start": 1244.406,
          "end": 1249.8461,
          "text": " One which would involve higher GPU context switching, and the other would involve higher communication overhead.",
          "tokens": [
            51518,
            1485,
            597,
            576,
            9494,
            2946,
            18407,
            4319,
            16493,
            11,
            293,
            264,
            661,
            576,
            9494,
            2946,
            6101,
            19922,
            13,
            51790
          ],
          "temperature": 0,
          "avg_logprob": -0.111680396,
          "compression_ratio": 1.6773163,
          "no_speech_prob": 5.215628e-12
        },
        {
          "id": 237,
          "seek": 43762,
          "start": 1249.8461,
          "end": 1253.606,
          "text": " I wasn't sure which one to pick, so I just asked Gemini.",
          "tokens": [
            50365,
            286,
            2067,
            380,
            988,
            597,
            472,
            281,
            1888,
            11,
            370,
            286,
            445,
            2351,
            22894,
            3812,
            13,
            50553
          ],
          "temperature": 0,
          "avg_logprob": -0.14071944,
          "compression_ratio": 1.6749226,
          "no_speech_prob": 2.2538091e-12
        },
        {
          "id": 238,
          "seek": 43762,
          "start": 1253.606,
          "end": 1257.586,
          "text": " And not only did it get both of them working in minutes, but it autonomously created and",
          "tokens": [
            50553,
            400,
            406,
            787,
            630,
            309,
            483,
            1293,
            295,
            552,
            1364,
            294,
            2077,
            11,
            457,
            309,
            18203,
            5098,
            2942,
            293,
            50752
          ],
          "temperature": 0,
          "avg_logprob": -0.14071944,
          "compression_ratio": 1.6749226,
          "no_speech_prob": 2.2538091e-12
        },
        {
          "id": 239,
          "seek": 43762,
          "start": 1257.586,
          "end": 1260.566,
          "text": " then ran a benchmark to see which one was best.",
          "tokens": [
            50752,
            550,
            5872,
            257,
            18927,
            281,
            536,
            597,
            472,
            390,
            1151,
            13,
            50901
          ],
          "temperature": 0,
          "avg_logprob": -0.14071944,
          "compression_ratio": 1.6749226,
          "no_speech_prob": 2.2538091e-12
        },
        {
          "id": 240,
          "seek": 43762,
          "start": 1260.566,
          "end": 1263.786,
          "text": " It would have taken me a week to implement either one of these options.",
          "tokens": [
            50901,
            467,
            576,
            362,
            2726,
            385,
            257,
            1243,
            281,
            4445,
            2139,
            472,
            295,
            613,
            3956,
            13,
            51062
          ],
          "temperature": 0,
          "avg_logprob": -0.14071944,
          "compression_ratio": 1.6749226,
          "no_speech_prob": 2.2538091e-12
        },
        {
          "id": 241,
          "seek": 43762,
          "start": 1263.786,
          "end": 1267.826,
          "text": " Think about how many judgment calls a software engineer working on an actually complex project",
          "tokens": [
            51062,
            6557,
            466,
            577,
            867,
            12216,
            5498,
            257,
            4722,
            11403,
            1364,
            322,
            364,
            767,
            3997,
            1716,
            51264
          ],
          "temperature": 0,
          "avg_logprob": -0.14071944,
          "compression_ratio": 1.6749226,
          "no_speech_prob": 2.2538091e-12
        },
        {
          "id": 242,
          "seek": 43762,
          "start": 1267.826,
          "end": 1268.826,
          "text": " has to make.",
          "tokens": [
            51264,
            575,
            281,
            652,
            13,
            51314
          ],
          "temperature": 0,
          "avg_logprob": -0.14071944,
          "compression_ratio": 1.6749226,
          "no_speech_prob": 2.2538091e-12
        },
        {
          "id": 243,
          "seek": 43762,
          "start": 1268.826,
          "end": 1272.646,
          "text": " If they have to spend weeks architecting some optimization or feature before they can see",
          "tokens": [
            51314,
            759,
            436,
            362,
            281,
            3496,
            3259,
            6331,
            278,
            512,
            19618,
            420,
            4111,
            949,
            436,
            393,
            536,
            51505
          ],
          "temperature": 0,
          "avg_logprob": -0.14071944,
          "compression_ratio": 1.6749226,
          "no_speech_prob": 2.2538091e-12
        },
        {
          "id": 244,
          "seek": 43762,
          "start": 1272.646,
          "end": 1276.7261,
          "text": " whether it will work out, they will just get to test out so many fewer ideas.",
          "tokens": [
            51505,
            1968,
            309,
            486,
            589,
            484,
            11,
            436,
            486,
            445,
            483,
            281,
            1500,
            484,
            370,
            867,
            13366,
            3487,
            13,
            51709
          ],
          "temperature": 0,
          "avg_logprob": -0.14071944,
          "compression_ratio": 1.6749226,
          "no_speech_prob": 2.2538091e-12
        },
        {
          "id": 245,
          "seek": 46450,
          "start": 1276.7261,
          "end": 1280.086,
          "text": " Anyways, with all this help from Gemini, I actually ran the experiment and got some results.",
          "tokens": [
            50365,
            15585,
            11,
            365,
            439,
            341,
            854,
            490,
            22894,
            3812,
            11,
            286,
            767,
            5872,
            264,
            5120,
            293,
            658,
            512,
            3542,
            13,
            50533
          ],
          "temperature": 0,
          "avg_logprob": -0.13034417,
          "compression_ratio": 1.6847134,
          "no_speech_prob": 2.17612e-12
        },
        {
          "id": 246,
          "seek": 46450,
          "start": 1280.4861,
          "end": 1284.326,
          "text": " Now, please keep in mind that I'm running this experiment on an anemic budget of compute,",
          "tokens": [
            50553,
            823,
            11,
            1767,
            1066,
            294,
            1575,
            300,
            286,
            478,
            2614,
            341,
            5120,
            322,
            364,
            364,
            3438,
            4706,
            295,
            14722,
            11,
            50745
          ],
          "temperature": 0,
          "avg_logprob": -0.13034417,
          "compression_ratio": 1.6847134,
          "no_speech_prob": 2.17612e-12
        },
        {
          "id": 247,
          "seek": 46450,
          "start": 1284.586,
          "end": 1286.826,
          "text": " and it's very possible I made some mistakes in implementation.",
          "tokens": [
            50758,
            293,
            309,
            311,
            588,
            1944,
            286,
            1027,
            512,
            8038,
            294,
            11420,
            13,
            50870
          ],
          "temperature": 0,
          "avg_logprob": -0.13034417,
          "compression_ratio": 1.6847134,
          "no_speech_prob": 2.17612e-12
        },
        {
          "id": 248,
          "seek": 46450,
          "start": 1287.586,
          "end": 1293.406,
          "text": " But it looks like there can be gains from splitting up a fixed budget of trading compute",
          "tokens": [
            50908,
            583,
            309,
            1542,
            411,
            456,
            393,
            312,
            16823,
            490,
            30348,
            493,
            257,
            6806,
            4706,
            295,
            9529,
            14722,
            51199
          ],
          "temperature": 0,
          "avg_logprob": -0.13034417,
          "compression_ratio": 1.6847134,
          "no_speech_prob": 2.17612e-12
        },
        {
          "id": 249,
          "seek": 46450,
          "start": 1293.406,
          "end": 1297.166,
          "text": " amongst multiple agents rather than just dumping it all into one.",
          "tokens": [
            51199,
            12918,
            3866,
            12554,
            2831,
            813,
            445,
            42224,
            309,
            439,
            666,
            472,
            13,
            51387
          ],
          "temperature": 0,
          "avg_logprob": -0.13034417,
          "compression_ratio": 1.6847134,
          "no_speech_prob": 2.17612e-12
        },
        {
          "id": 250,
          "seek": 46450,
          "start": 1297.4861,
          "end": 1299.266,
          "text": " Just to reiterate how surprising this is,",
          "tokens": [
            51403,
            1449,
            281,
            33528,
            577,
            8830,
            341,
            307,
            11,
            51492
          ],
          "temperature": 0,
          "avg_logprob": -0.13034417,
          "compression_ratio": 1.6847134,
          "no_speech_prob": 2.17612e-12
        },
        {
          "id": 251,
          "seek": 46450,
          "start": 1299.266,
          "end": 1305.006,
          "text": " the best agent in the population of 16 is getting 1 16th the amount of trading compute",
          "tokens": [
            51492,
            264,
            1151,
            9461,
            294,
            264,
            4415,
            295,
            3165,
            307,
            1242,
            502,
            3165,
            392,
            264,
            2372,
            295,
            9529,
            14722,
            51779
          ],
          "temperature": 0,
          "avg_logprob": -0.13034417,
          "compression_ratio": 1.6847134,
          "no_speech_prob": 2.17612e-12
        },
        {
          "id": 252,
          "seek": 49278,
          "start": 1305.006,
          "end": 1307.786,
          "text": " as the agent trained on self-play alone.",
          "tokens": [
            50365,
            382,
            264,
            9461,
            8895,
            322,
            2698,
            12,
            2858,
            3312,
            13,
            50504
          ],
          "temperature": 0,
          "avg_logprob": -0.13529664,
          "compression_ratio": 1.624521,
          "no_speech_prob": 1.9966847e-12
        },
        {
          "id": 253,
          "seek": 49278,
          "start": 1308.326,
          "end": 1312.426,
          "text": " And yet it still outperforms the agent that is hogging all of the compute.",
          "tokens": [
            50531,
            400,
            1939,
            309,
            920,
            484,
            26765,
            82,
            264,
            9461,
            300,
            307,
            24855,
            3249,
            439,
            295,
            264,
            14722,
            13,
            50736
          ],
          "temperature": 0,
          "avg_logprob": -0.13529664,
          "compression_ratio": 1.624521,
          "no_speech_prob": 1.9966847e-12
        },
        {
          "id": 254,
          "seek": 49278,
          "start": 1312.626,
          "end": 1315.8461,
          "text": " The whole process of ViveCoding this experiment with Gemini",
          "tokens": [
            50746,
            440,
            1379,
            1399,
            295,
            44288,
            34,
            8616,
            341,
            5120,
            365,
            22894,
            3812,
            50907
          ],
          "temperature": 0,
          "avg_logprob": -0.13529664,
          "compression_ratio": 1.624521,
          "no_speech_prob": 1.9966847e-12
        },
        {
          "id": 255,
          "seek": 49278,
          "start": 1315.8461,
          "end": 1317.926,
          "text": " was really absorbing and fun.",
          "tokens": [
            50907,
            390,
            534,
            38720,
            293,
            1019,
            13,
            51011
          ],
          "temperature": 0,
          "avg_logprob": -0.13529664,
          "compression_ratio": 1.624521,
          "no_speech_prob": 1.9966847e-12
        },
        {
          "id": 256,
          "seek": 49278,
          "start": 1318.306,
          "end": 1321.286,
          "text": " It gave me the chance to actually understand how AlphaZero works",
          "tokens": [
            51030,
            467,
            2729,
            385,
            264,
            2931,
            281,
            767,
            1223,
            577,
            20588,
            57,
            2032,
            1985,
            51179
          ],
          "temperature": 0,
          "avg_logprob": -0.13529664,
          "compression_ratio": 1.624521,
          "no_speech_prob": 1.9966847e-12
        },
        {
          "id": 257,
          "seek": 49278,
          "start": 1321.286,
          "end": 1326.766,
          "text": " and to understand the design space around decisions about the hyperparameters",
          "tokens": [
            51179,
            293,
            281,
            1223,
            264,
            1715,
            1901,
            926,
            5327,
            466,
            264,
            9848,
            2181,
            335,
            6202,
            51453
          ],
          "temperature": 0,
          "avg_logprob": -0.13529664,
          "compression_ratio": 1.624521,
          "no_speech_prob": 1.9966847e-12
        },
        {
          "id": 258,
          "seek": 49278,
          "start": 1326.766,
          "end": 1330.906,
          "text": " and how search is done and how you do this kind of co-evolutionary training",
          "tokens": [
            51453,
            293,
            577,
            3164,
            307,
            1096,
            293,
            577,
            291,
            360,
            341,
            733,
            295,
            598,
            12,
            13379,
            3386,
            822,
            3097,
            51660
          ],
          "temperature": 0,
          "avg_logprob": -0.13529664,
          "compression_ratio": 1.624521,
          "no_speech_prob": 1.9966847e-12
        },
        {
          "id": 259,
          "seek": 51868,
          "start": 1330.906,
          "end": 1335.2461,
          "text": " rather than getting bogged down in my very novice abilities as an engineer.",
          "tokens": [
            50365,
            2831,
            813,
            1242,
            26132,
            3004,
            760,
            294,
            452,
            588,
            23883,
            573,
            11582,
            382,
            364,
            11403,
            13,
            50582
          ],
          "temperature": 0,
          "avg_logprob": -0.21827003,
          "compression_ratio": 1.516129,
          "no_speech_prob": 8.2928987e-13
        },
        {
          "id": 260,
          "seek": 51868,
          "start": 1335.606,
          "end": 1339.2261,
          "text": " Go to gemini.google.com to try it out.",
          "tokens": [
            50600,
            1037,
            281,
            7173,
            3812,
            13,
            1571,
            3127,
            13,
            1112,
            281,
            853,
            309,
            484,
            13,
            50781
          ],
          "temperature": 0,
          "avg_logprob": -0.21827003,
          "compression_ratio": 1.516129,
          "no_speech_prob": 8.2928987e-13
        },
        {
          "id": 261,
          "seek": 51868,
          "start": 1339.9861,
          "end": 1343.4661,
          "text": " I want to talk about this idea that you just glanced off of,",
          "tokens": [
            50819,
            286,
            528,
            281,
            751,
            466,
            341,
            1558,
            300,
            291,
            445,
            1563,
            4864,
            766,
            295,
            11,
            50993
          ],
          "temperature": 0,
          "avg_logprob": -0.21827003,
          "compression_ratio": 1.516129,
          "no_speech_prob": 8.2928987e-13
        },
        {
          "id": 262,
          "seek": 51868,
          "start": 1343.526,
          "end": 1345.046,
          "text": " which was amortized inference.",
          "tokens": [
            50996,
            597,
            390,
            669,
            477,
            1602,
            38253,
            13,
            51072
          ],
          "temperature": 0,
          "avg_logprob": -0.21827003,
          "compression_ratio": 1.516129,
          "no_speech_prob": 8.2928987e-13
        },
        {
          "id": 263,
          "seek": 51868,
          "start": 1347.4661,
          "end": 1352.886,
          "text": " And maybe I should try to explain what I think it means,",
          "tokens": [
            51193,
            400,
            1310,
            286,
            820,
            853,
            281,
            2903,
            437,
            286,
            519,
            309,
            1355,
            11,
            51464
          ],
          "temperature": 0,
          "avg_logprob": -0.21827003,
          "compression_ratio": 1.516129,
          "no_speech_prob": 8.2928987e-13
        },
        {
          "id": 264,
          "seek": 51868,
          "start": 1352.9661,
          "end": 1355.926,
          "text": " because I think it's probably wrong, and this will help you correct me.",
          "tokens": [
            51468,
            570,
            286,
            519,
            309,
            311,
            1391,
            2085,
            11,
            293,
            341,
            486,
            854,
            291,
            3006,
            385,
            13,
            51616
          ],
          "temperature": 0,
          "avg_logprob": -0.21827003,
          "compression_ratio": 1.516129,
          "no_speech_prob": 8.2928987e-13
        },
        {
          "id": 265,
          "seek": 51868,
          "start": 1355.926,
          "end": 1357.0061,
          "text": " It's been a few years for me, too.",
          "tokens": [
            51616,
            467,
            311,
            668,
            257,
            1326,
            924,
            337,
            385,
            11,
            886,
            13,
            51670
          ],
          "temperature": 0,
          "avg_logprob": -0.21827003,
          "compression_ratio": 1.516129,
          "no_speech_prob": 8.2928987e-13
        },
        {
          "id": 266,
          "seek": 51868,
          "start": 1357.206,
          "end": 1357.386,
          "text": " Okay.",
          "tokens": [
            51680,
            1033,
            13,
            51689
          ],
          "temperature": 0,
          "avg_logprob": -0.21827003,
          "compression_ratio": 1.516129,
          "no_speech_prob": 8.2928987e-13
        },
        {
          "id": 267,
          "seek": 54516,
          "start": 1357.386,
          "end": 1365.306,
          "text": " right now the way the models work is you have an input it maps it to an output and this is",
          "tokens": [
            50365,
            558,
            586,
            264,
            636,
            264,
            5245,
            589,
            307,
            291,
            362,
            364,
            4846,
            309,
            11317,
            309,
            281,
            364,
            5598,
            293,
            341,
            307,
            50761
          ],
          "temperature": 0,
          "avg_logprob": -0.066850096,
          "compression_ratio": 1.9585493,
          "no_speech_prob": 1.5070815e-12
        },
        {
          "id": 268,
          "seek": 54516,
          "start": 1365.306,
          "end": 1372.2661,
          "text": " amortizing a process that the the real process which we think is like what intelligence is",
          "tokens": [
            50761,
            669,
            477,
            3319,
            257,
            1399,
            300,
            264,
            264,
            957,
            1399,
            597,
            321,
            519,
            307,
            411,
            437,
            7599,
            307,
            51109
          ],
          "temperature": 0,
          "avg_logprob": -0.066850096,
          "compression_ratio": 1.9585493,
          "no_speech_prob": 1.5070815e-12
        },
        {
          "id": 269,
          "seek": 54516,
          "start": 1372.2661,
          "end": 1378.566,
          "text": " which is like you have some prior over how the world could be like what are the causes that make",
          "tokens": [
            51109,
            597,
            307,
            411,
            291,
            362,
            512,
            4059,
            670,
            577,
            264,
            1002,
            727,
            312,
            411,
            437,
            366,
            264,
            7700,
            300,
            652,
            51424
          ],
          "temperature": 0,
          "avg_logprob": -0.066850096,
          "compression_ratio": 1.9585493,
          "no_speech_prob": 1.5070815e-12
        },
        {
          "id": 270,
          "seek": 54516,
          "start": 1378.566,
          "end": 1384.186,
          "text": " the world the way that it is and then the way when you see some observation you should be like okay",
          "tokens": [
            51424,
            264,
            1002,
            264,
            636,
            300,
            309,
            307,
            293,
            550,
            264,
            636,
            562,
            291,
            536,
            512,
            14816,
            291,
            820,
            312,
            411,
            1392,
            51705
          ],
          "temperature": 0,
          "avg_logprob": -0.066850096,
          "compression_ratio": 1.9585493,
          "no_speech_prob": 1.5070815e-12
        },
        {
          "id": 271,
          "seek": 57196,
          "start": 1384.186,
          "end": 1391.046,
          "text": " here's all the ways the world could be um this cause explains what's happening best now this",
          "tokens": [
            50365,
            510,
            311,
            439,
            264,
            2098,
            264,
            1002,
            727,
            312,
            1105,
            341,
            3082,
            13948,
            437,
            311,
            2737,
            1151,
            586,
            341,
            50708
          ],
          "temperature": 0,
          "avg_logprob": -0.045506213,
          "compression_ratio": 1.9458333,
          "no_speech_prob": 1.3044786e-12
        },
        {
          "id": 272,
          "seek": 57196,
          "start": 1391.046,
          "end": 1398.126,
          "text": " like doing this calculation over every possible cause is computationally intractable so then you",
          "tokens": [
            50708,
            411,
            884,
            341,
            17108,
            670,
            633,
            1944,
            3082,
            307,
            24903,
            379,
            560,
            1897,
            712,
            370,
            550,
            291,
            51062
          ],
          "temperature": 0,
          "avg_logprob": -0.045506213,
          "compression_ratio": 1.9458333,
          "no_speech_prob": 1.3044786e-12
        },
        {
          "id": 273,
          "seek": 57196,
          "start": 1398.126,
          "end": 1403.306,
          "text": " just have to sample like oh here's a potential cause does this explain this observation uh no",
          "tokens": [
            51062,
            445,
            362,
            281,
            6889,
            411,
            1954,
            510,
            311,
            257,
            3995,
            3082,
            775,
            341,
            2903,
            341,
            14816,
            2232,
            572,
            51321
          ],
          "temperature": 0,
          "avg_logprob": -0.045506213,
          "compression_ratio": 1.9458333,
          "no_speech_prob": 1.3044786e-12
        },
        {
          "id": 274,
          "seek": 57196,
          "start": 1403.306,
          "end": 1408.826,
          "text": " forget it let's let's keep sampling and then eventually you get the cause the cause then",
          "tokens": [
            51321,
            2870,
            309,
            718,
            311,
            718,
            311,
            1066,
            21179,
            293,
            550,
            4728,
            291,
            483,
            264,
            3082,
            264,
            3082,
            550,
            51597
          ],
          "temperature": 0,
          "avg_logprob": -0.045506213,
          "compression_ratio": 1.9458333,
          "no_speech_prob": 1.3044786e-12
        },
        {
          "id": 275,
          "seek": 57196,
          "start": 1408.826,
          "end": 1414.066,
          "text": " the cause explains the observation and then this becomes your posterior that's actually pretty",
          "tokens": [
            51597,
            264,
            3082,
            13948,
            264,
            14816,
            293,
            550,
            341,
            3643,
            428,
            33529,
            300,
            311,
            767,
            1238,
            51859
          ],
          "temperature": 0,
          "avg_logprob": -0.045506213,
          "compression_ratio": 1.9458333,
          "no_speech_prob": 1.3044786e-12
        },
        {
          "id": 276,
          "seek": 60184,
          "start": 1414.066,
          "end": 1418.306,
          "text": " good i think of sort of yeah so yeah this bayesian inference like in general is like of this very",
          "tokens": [
            50365,
            665,
            741,
            519,
            295,
            1333,
            295,
            1338,
            370,
            1338,
            341,
            13642,
            42434,
            38253,
            411,
            294,
            2674,
            307,
            411,
            295,
            341,
            588,
            50577
          ],
          "temperature": 0,
          "avg_logprob": -0.057652015,
          "compression_ratio": 1.9659864,
          "no_speech_prob": 1.90557e-12
        },
        {
          "id": 277,
          "seek": 60184,
          "start": 1418.306,
          "end": 1423.286,
          "text": " intractable thing right it the algorithms that we have for doing that tend to require taking a lot",
          "tokens": [
            50577,
            560,
            1897,
            712,
            551,
            558,
            309,
            264,
            14642,
            300,
            321,
            362,
            337,
            884,
            300,
            3928,
            281,
            3651,
            1940,
            257,
            688,
            50826
          ],
          "temperature": 0,
          "avg_logprob": -0.057652015,
          "compression_ratio": 1.9659864,
          "no_speech_prob": 1.90557e-12
        },
        {
          "id": 278,
          "seek": 60184,
          "start": 1423.286,
          "end": 1429.066,
          "text": " of samples monte carlo methods taking a lot of samples yeah and taking samples takes time i mean",
          "tokens": [
            50826,
            295,
            10938,
            35437,
            1032,
            752,
            7150,
            1940,
            257,
            688,
            295,
            10938,
            1338,
            293,
            1940,
            10938,
            2516,
            565,
            741,
            914,
            51115
          ],
          "temperature": 0,
          "avg_logprob": -0.057652015,
          "compression_ratio": 1.9659864,
          "no_speech_prob": 1.90557e-12
        },
        {
          "id": 279,
          "seek": 60184,
          "start": 1429.066,
          "end": 1433.026,
          "text": " this is like the original like baltimore machines and stuff we're using yeah techniques like this",
          "tokens": [
            51115,
            341,
            307,
            411,
            264,
            3380,
            411,
            3119,
            83,
            21917,
            8379,
            293,
            1507,
            321,
            434,
            1228,
            1338,
            7512,
            411,
            341,
            51313
          ],
          "temperature": 0,
          "avg_logprob": -0.057652015,
          "compression_ratio": 1.9659864,
          "no_speech_prob": 1.90557e-12
        },
        {
          "id": 280,
          "seek": 60184,
          "start": 1433.026,
          "end": 1439.346,
          "text": " um and still it's used with probabilistic programming other types of methods often and so",
          "tokens": [
            51313,
            1105,
            293,
            920,
            309,
            311,
            1143,
            365,
            31959,
            3142,
            9410,
            661,
            3467,
            295,
            7150,
            2049,
            293,
            370,
            51629
          ],
          "temperature": 0,
          "avg_logprob": -0.057652015,
          "compression_ratio": 1.9659864,
          "no_speech_prob": 1.90557e-12
        },
        {
          "id": 281,
          "seek": 60184,
          "start": 1439.346,
          "end": 1443.686,
          "text": " uh yeah so the bayesian inference problem which is like basically the problem of like perception",
          "tokens": [
            51629,
            2232,
            1338,
            370,
            264,
            13642,
            42434,
            38253,
            1154,
            597,
            307,
            411,
            1936,
            264,
            1154,
            295,
            411,
            12860,
            51846
          ],
          "temperature": 0,
          "avg_logprob": -0.057652015,
          "compression_ratio": 1.9659864,
          "no_speech_prob": 1.90557e-12
        },
        {
          "id": 282,
          "seek": 63146,
          "start": 1443.686,
          "end": 1448.626,
          "text": " like given some model of the world and given some data like how should i update my what what are the",
          "tokens": [
            50365,
            411,
            2212,
            512,
            2316,
            295,
            264,
            1002,
            293,
            2212,
            512,
            1412,
            411,
            577,
            820,
            741,
            5623,
            452,
            437,
            437,
            366,
            264,
            50612
          ],
          "temperature": 0,
          "avg_logprob": -0.07304677,
          "compression_ratio": 1.976,
          "no_speech_prob": 1.3887374e-12
        },
        {
          "id": 283,
          "seek": 63146,
          "start": 1448.626,
          "end": 1454.706,
          "text": " like the the variables you know missing variables in my in my internal model and i guess the idea",
          "tokens": [
            50612,
            411,
            264,
            264,
            9102,
            291,
            458,
            5361,
            9102,
            294,
            452,
            294,
            452,
            6920,
            2316,
            293,
            741,
            2041,
            264,
            1558,
            50916
          ],
          "temperature": 0,
          "avg_logprob": -0.07304677,
          "compression_ratio": 1.976,
          "no_speech_prob": 1.3887374e-12
        },
        {
          "id": 284,
          "seek": 63146,
          "start": 1454.706,
          "end": 1461.626,
          "text": " is that neural networks are hopefully um obviously there's mechanistically the neural network is not",
          "tokens": [
            50916,
            307,
            300,
            18161,
            9590,
            366,
            4696,
            1105,
            2745,
            456,
            311,
            4236,
            20458,
            264,
            18161,
            3209,
            307,
            406,
            51262
          ],
          "temperature": 0,
          "avg_logprob": -0.07304677,
          "compression_ratio": 1.976,
          "no_speech_prob": 1.3887374e-12
        },
        {
          "id": 285,
          "seek": 63146,
          "start": 1461.626,
          "end": 1467.5061,
          "text": " starting with like here is my model of the world and i'm going to try to explain this data but the",
          "tokens": [
            51262,
            2891,
            365,
            411,
            510,
            307,
            452,
            2316,
            295,
            264,
            1002,
            293,
            741,
            478,
            516,
            281,
            853,
            281,
            2903,
            341,
            1412,
            457,
            264,
            51556
          ],
          "temperature": 0,
          "avg_logprob": -0.07304677,
          "compression_ratio": 1.976,
          "no_speech_prob": 1.3887374e-12
        },
        {
          "id": 286,
          "seek": 63146,
          "start": 1467.5061,
          "end": 1473.546,
          "text": " hope is that instead of starting with um hey does this cause explanation no here did this cause",
          "tokens": [
            51556,
            1454,
            307,
            300,
            2602,
            295,
            2891,
            365,
            1105,
            4177,
            775,
            341,
            3082,
            10835,
            572,
            510,
            630,
            341,
            3082,
            51858
          ],
          "temperature": 0,
          "avg_logprob": -0.07304677,
          "compression_ratio": 1.976,
          "no_speech_prob": 1.3887374e-12
        },
        {
          "id": 287,
          "seek": 66132,
          "start": 1473.546,
          "end": 1477.7661,
          "text": " explain this explanation yes what you do is just like observation what's the most what's the cause",
          "tokens": [
            50365,
            2903,
            341,
            10835,
            2086,
            437,
            291,
            360,
            307,
            445,
            411,
            14816,
            437,
            311,
            264,
            881,
            437,
            311,
            264,
            3082,
            50576
          ],
          "temperature": 0,
          "avg_logprob": -0.05740657,
          "compression_ratio": 2.0070176,
          "no_speech_prob": 2.1677955e-12
        },
        {
          "id": 288,
          "seek": 66132,
          "start": 1477.7661,
          "end": 1482.066,
          "text": " that we the neural net thinks is the best observation to cause so the feed forward like",
          "tokens": [
            50576,
            300,
            321,
            264,
            18161,
            2533,
            7309,
            307,
            264,
            1151,
            14816,
            281,
            3082,
            370,
            264,
            3154,
            2128,
            411,
            50791
          ],
          "temperature": 0,
          "avg_logprob": -0.05740657,
          "compression_ratio": 2.0070176,
          "no_speech_prob": 2.1677955e-12
        },
        {
          "id": 289,
          "seek": 66132,
          "start": 1482.066,
          "end": 1486.2661,
          "text": " goes observation to cause observation to cause to then output that yes you don't have to you don't",
          "tokens": [
            50791,
            1709,
            14816,
            281,
            3082,
            14816,
            281,
            3082,
            281,
            550,
            5598,
            300,
            2086,
            291,
            500,
            380,
            362,
            281,
            291,
            500,
            380,
            51001
          ],
          "temperature": 0,
          "avg_logprob": -0.05740657,
          "compression_ratio": 2.0070176,
          "no_speech_prob": 2.1677955e-12
        },
        {
          "id": 290,
          "seek": 66132,
          "start": 1486.2661,
          "end": 1490.286,
          "text": " have to evaluate all these energy values or whatever and sample around to make them higher",
          "tokens": [
            51001,
            362,
            281,
            13059,
            439,
            613,
            2281,
            4190,
            420,
            2035,
            293,
            6889,
            926,
            281,
            652,
            552,
            2946,
            51202
          ],
          "temperature": 0,
          "avg_logprob": -0.05740657,
          "compression_ratio": 2.0070176,
          "no_speech_prob": 2.1677955e-12
        },
        {
          "id": 291,
          "seek": 66132,
          "start": 1490.286,
          "end": 1497.646,
          "text": " and lower um you just say um approximately that process would result in this being the top one or",
          "tokens": [
            51202,
            293,
            3126,
            1105,
            291,
            445,
            584,
            1105,
            10447,
            300,
            1399,
            576,
            1874,
            294,
            341,
            885,
            264,
            1192,
            472,
            420,
            51570
          ],
          "temperature": 0,
          "avg_logprob": -0.05740657,
          "compression_ratio": 2.0070176,
          "no_speech_prob": 2.1677955e-12
        },
        {
          "id": 292,
          "seek": 66132,
          "start": 1497.646,
          "end": 1502.706,
          "text": " something like that yeah one way to think about it might be that test time compute inference time",
          "tokens": [
            51570,
            746,
            411,
            300,
            1338,
            472,
            636,
            281,
            519,
            466,
            309,
            1062,
            312,
            300,
            1500,
            565,
            14722,
            38253,
            565,
            51823
          ],
          "temperature": 0,
          "avg_logprob": -0.05740657,
          "compression_ratio": 2.0070176,
          "no_speech_prob": 2.1677955e-12
        },
        {
          "id": 293,
          "seek": 69048,
          "start": 1502.706,
          "end": 1508.2461,
          "text": " compute is actually doing this sampling again because you literally read its shade of thought",
          "tokens": [
            50365,
            14722,
            307,
            767,
            884,
            341,
            21179,
            797,
            570,
            291,
            3736,
            1401,
            1080,
            11466,
            295,
            1194,
            50642
          ],
          "temperature": 0,
          "avg_logprob": -0.05452221,
          "compression_ratio": 1.7984496,
          "no_speech_prob": 1.7969713e-12
        },
        {
          "id": 294,
          "seek": 69048,
          "start": 1508.2461,
          "end": 1512.826,
          "text": " it's like actually doing this toy example we're talking about where it's like oh can i sell this",
          "tokens": [
            50642,
            309,
            311,
            411,
            767,
            884,
            341,
            12058,
            1365,
            321,
            434,
            1417,
            466,
            689,
            309,
            311,
            411,
            1954,
            393,
            741,
            3607,
            341,
            50871
          ],
          "temperature": 0,
          "avg_logprob": -0.05452221,
          "compression_ratio": 1.7984496,
          "no_speech_prob": 1.7969713e-12
        },
        {
          "id": 295,
          "seek": 69048,
          "start": 1512.826,
          "end": 1517.806,
          "text": " problem by doing x yeah i need a different approach and this raises the question i mean",
          "tokens": [
            50871,
            1154,
            538,
            884,
            2031,
            1338,
            741,
            643,
            257,
            819,
            3109,
            293,
            341,
            19658,
            264,
            1168,
            741,
            914,
            51120
          ],
          "temperature": 0,
          "avg_logprob": -0.05452221,
          "compression_ratio": 1.7984496,
          "no_speech_prob": 1.7969713e-12
        },
        {
          "id": 296,
          "seek": 69048,
          "start": 1517.806,
          "end": 1523.786,
          "text": " over time it is the case that the capabilities which were uh which required inference time",
          "tokens": [
            51120,
            670,
            565,
            309,
            307,
            264,
            1389,
            300,
            264,
            10862,
            597,
            645,
            2232,
            597,
            4739,
            38253,
            565,
            51419
          ],
          "temperature": 0,
          "avg_logprob": -0.05452221,
          "compression_ratio": 1.7984496,
          "no_speech_prob": 1.7969713e-12
        },
        {
          "id": 297,
          "seek": 69048,
          "start": 1523.786,
          "end": 1528.806,
          "text": " compute to elicit get distilled into the model so you're amortizing the thing which previously",
          "tokens": [
            51419,
            14722,
            281,
            806,
            8876,
            483,
            1483,
            6261,
            666,
            264,
            2316,
            370,
            291,
            434,
            669,
            477,
            3319,
            264,
            551,
            597,
            8046,
            51670
          ],
          "temperature": 0,
          "avg_logprob": -0.05452221,
          "compression_ratio": 1.7984496,
          "no_speech_prob": 1.7969713e-12
        },
        {
          "id": 298,
          "seek": 71658,
          "start": 1528.806,
          "end": 1532.926,
          "text": " So you needed to do these like rollouts, like Monte Carlo rollouts to to figure out.",
          "tokens": [
            50365,
            407,
            291,
            2978,
            281,
            360,
            613,
            411,
            3373,
            7711,
            11,
            411,
            38105,
            45112,
            3373,
            7711,
            281,
            281,
            2573,
            484,
            13,
            50571
          ],
          "temperature": 0,
          "avg_logprob": -0.16054395,
          "compression_ratio": 1.7298387,
          "no_speech_prob": 2.218934e-12
        },
        {
          "id": 299,
          "seek": 71658,
          "start": 1533.2461,
          "end": 1542.206,
          "text": " And so in general, maybe there's this principle of digital minds, which can be copied, have different tradeoffs, which are relevant than biological minds, which cannot.",
          "tokens": [
            50587,
            400,
            370,
            294,
            2674,
            11,
            1310,
            456,
            311,
            341,
            8665,
            295,
            4562,
            9634,
            11,
            597,
            393,
            312,
            25365,
            11,
            362,
            819,
            4923,
            19231,
            11,
            597,
            366,
            7340,
            813,
            13910,
            9634,
            11,
            597,
            2644,
            13,
            51035
          ],
          "temperature": 0,
          "avg_logprob": -0.16054395,
          "compression_ratio": 1.7298387,
          "no_speech_prob": 2.218934e-12
        },
        {
          "id": 300,
          "seek": 71658,
          "start": 1542.666,
          "end": 1548.026,
          "text": " And so in general, it should make sense to amortize more things because you can literally copy the amortization, right?",
          "tokens": [
            51058,
            400,
            370,
            294,
            2674,
            11,
            309,
            820,
            652,
            2020,
            281,
            669,
            477,
            1125,
            544,
            721,
            570,
            291,
            393,
            3736,
            5055,
            264,
            669,
            477,
            2144,
            11,
            558,
            30,
            51326
          ],
          "temperature": 0,
          "avg_logprob": -0.16054395,
          "compression_ratio": 1.7298387,
          "no_speech_prob": 2.218934e-12
        },
        {
          "id": 301,
          "seek": 71658,
          "start": 1548.066,
          "end": 1551.2461,
          "text": " Or copy the things that you have sort of like built in.",
          "tokens": [
            51328,
            1610,
            5055,
            264,
            721,
            300,
            291,
            362,
            1333,
            295,
            411,
            3094,
            294,
            13,
            51487
          ],
          "temperature": 0,
          "avg_logprob": -0.16054395,
          "compression_ratio": 1.7298387,
          "no_speech_prob": 2.218934e-12
        },
        {
          "id": 302,
          "seek": 73902,
          "start": 1551.2461,
          "end": 1555.5061,
          "text": " yeah um and it's maybe this is a tangential question where it might be interesting to",
          "tokens": [
            50365,
            1338,
            1105,
            293,
            309,
            311,
            1310,
            341,
            307,
            257,
            10266,
            2549,
            1168,
            689,
            309,
            1062,
            312,
            1880,
            281,
            50578
          ],
          "temperature": 0,
          "avg_logprob": -0.04299674,
          "compression_ratio": 1.7602997,
          "no_speech_prob": 1.9275644e-12
        },
        {
          "id": 303,
          "seek": 73902,
          "start": 1555.5061,
          "end": 1560.646,
          "text": " speculate about in the future as these things become more intelligent and the way we train",
          "tokens": [
            50578,
            40775,
            466,
            294,
            264,
            2027,
            382,
            613,
            721,
            1813,
            544,
            13232,
            293,
            264,
            636,
            321,
            3847,
            50835
          ],
          "temperature": 0,
          "avg_logprob": -0.04299674,
          "compression_ratio": 1.7602997,
          "no_speech_prob": 1.9275644e-12
        },
        {
          "id": 304,
          "seek": 73902,
          "start": 1560.646,
          "end": 1568.606,
          "text": " them becomes more economically rational what will make sense to amortize into these minds which",
          "tokens": [
            50835,
            552,
            3643,
            544,
            26811,
            15090,
            437,
            486,
            652,
            2020,
            281,
            669,
            477,
            1125,
            666,
            613,
            9634,
            597,
            51233
          ],
          "temperature": 0,
          "avg_logprob": -0.04299674,
          "compression_ratio": 1.7602997,
          "no_speech_prob": 1.9275644e-12
        },
        {
          "id": 305,
          "seek": 73902,
          "start": 1568.606,
          "end": 1573.206,
          "text": " evolution did not think it was worth amortizing into biological minds they do you have to retrain",
          "tokens": [
            51233,
            9303,
            630,
            406,
            519,
            309,
            390,
            3163,
            669,
            477,
            3319,
            666,
            13910,
            9634,
            436,
            360,
            291,
            362,
            281,
            1533,
            7146,
            51463
          ],
          "temperature": 0,
          "avg_logprob": -0.04299674,
          "compression_ratio": 1.7602997,
          "no_speech_prob": 1.9275644e-12
        },
        {
          "id": 306,
          "seek": 73902,
          "start": 1573.206,
          "end": 1577.566,
          "text": " right i mean first of all i think the probabilistic ai people would be like of course you need test",
          "tokens": [
            51463,
            558,
            741,
            914,
            700,
            295,
            439,
            741,
            519,
            264,
            31959,
            3142,
            9783,
            561,
            576,
            312,
            411,
            295,
            1164,
            291,
            643,
            1500,
            51681
          ],
          "temperature": 0,
          "avg_logprob": -0.04299674,
          "compression_ratio": 1.7602997,
          "no_speech_prob": 1.9275644e-12
        },
        {
          "id": 307,
          "seek": 76534,
          "start": 1577.566,
          "end": 1582.4861,
          "text": " time compute because this inference problem is really hard and the only ways we know how to do",
          "tokens": [
            50365,
            565,
            14722,
            570,
            341,
            38253,
            1154,
            307,
            534,
            1152,
            293,
            264,
            787,
            2098,
            321,
            458,
            577,
            281,
            360,
            50611
          ],
          "temperature": 0,
          "avg_logprob": -0.03599006,
          "compression_ratio": 1.9380531,
          "no_speech_prob": 2.1675485e-12
        },
        {
          "id": 308,
          "seek": 76534,
          "start": 1582.4861,
          "end": 1585.846,
          "text": " it involve lots of test time compute otherwise it's just a crappy approximation that's never",
          "tokens": [
            50611,
            309,
            9494,
            3195,
            295,
            1500,
            565,
            14722,
            5911,
            309,
            311,
            445,
            257,
            36531,
            28023,
            300,
            311,
            1128,
            50779
          ],
          "temperature": 0,
          "avg_logprob": -0.03599006,
          "compression_ratio": 1.9380531,
          "no_speech_prob": 2.1675485e-12
        },
        {
          "id": 309,
          "seek": 76534,
          "start": 1585.846,
          "end": 1589.566,
          "text": " gonna like you have to do infinite data or something to like make this so i think that",
          "tokens": [
            50779,
            799,
            411,
            291,
            362,
            281,
            360,
            13785,
            1412,
            420,
            746,
            281,
            411,
            652,
            341,
            370,
            741,
            519,
            300,
            50965
          ],
          "temperature": 0,
          "avg_logprob": -0.03599006,
          "compression_ratio": 1.9380531,
          "no_speech_prob": 2.1675485e-12
        },
        {
          "id": 310,
          "seek": 76534,
          "start": 1589.566,
          "end": 1592.666,
          "text": " some of the probabilistic people will be like no it's like inherently probabilistic and like",
          "tokens": [
            50965,
            512,
            295,
            264,
            31959,
            3142,
            561,
            486,
            312,
            411,
            572,
            309,
            311,
            411,
            27993,
            31959,
            3142,
            293,
            411,
            51120
          ],
          "temperature": 0,
          "avg_logprob": -0.03599006,
          "compression_ratio": 1.9380531,
          "no_speech_prob": 2.1675485e-12
        },
        {
          "id": 311,
          "seek": 76534,
          "start": 1592.666,
          "end": 1597.186,
          "text": " amortizing it in this way like just doesn't make sense and so and they might then also point to",
          "tokens": [
            51120,
            669,
            477,
            3319,
            309,
            294,
            341,
            636,
            411,
            445,
            1177,
            380,
            652,
            2020,
            293,
            370,
            293,
            436,
            1062,
            550,
            611,
            935,
            281,
            51346
          ],
          "temperature": 0,
          "avg_logprob": -0.03599006,
          "compression_ratio": 1.9380531,
          "no_speech_prob": 2.1675485e-12
        },
        {
          "id": 312,
          "seek": 76534,
          "start": 1597.186,
          "end": 1600.546,
          "text": " the brain and say okay well the brain the neurons are kind of stochastic and they're sampling and",
          "tokens": [
            51346,
            264,
            3567,
            293,
            584,
            1392,
            731,
            264,
            3567,
            264,
            22027,
            366,
            733,
            295,
            342,
            8997,
            2750,
            293,
            436,
            434,
            21179,
            293,
            51514
          ],
          "temperature": 0,
          "avg_logprob": -0.03599006,
          "compression_ratio": 1.9380531,
          "no_speech_prob": 2.1675485e-12
        },
        {
          "id": 313,
          "seek": 76534,
          "start": 1600.546,
          "end": 1604.7461,
          "text": " they're doing doing things and so maybe the brain actually is doing more like the non-amortized",
          "tokens": [
            51514,
            436,
            434,
            884,
            884,
            721,
            293,
            370,
            1310,
            264,
            3567,
            767,
            307,
            884,
            544,
            411,
            264,
            2107,
            12,
            335,
            477,
            1602,
            51724
          ],
          "temperature": 0,
          "avg_logprob": -0.03599006,
          "compression_ratio": 1.9380531,
          "no_speech_prob": 2.1675485e-12
        },
        {
          "id": 314,
          "seek": 79252,
          "start": 1604.7461,
          "end": 1611.2261,
          "text": " inference the real inference um but it's also kind of strange how perception can work in just like",
          "tokens": [
            50365,
            38253,
            264,
            957,
            38253,
            1105,
            457,
            309,
            311,
            611,
            733,
            295,
            5861,
            577,
            12860,
            393,
            589,
            294,
            445,
            411,
            50689
          ],
          "temperature": 0,
          "avg_logprob": -0.055378582,
          "compression_ratio": 1.7854406,
          "no_speech_prob": 1.2595768e-12
        },
        {
          "id": 315,
          "seek": 79252,
          "start": 1611.2261,
          "end": 1614.846,
          "text": " milliseconds or whatever it doesn't seem like it uses that much sampling so it's also clearly also",
          "tokens": [
            50689,
            34184,
            420,
            2035,
            309,
            1177,
            380,
            1643,
            411,
            309,
            4960,
            300,
            709,
            21179,
            370,
            309,
            311,
            611,
            4448,
            611,
            50870
          ],
          "temperature": 0,
          "avg_logprob": -0.055378582,
          "compression_ratio": 1.7854406,
          "no_speech_prob": 1.2595768e-12
        },
        {
          "id": 316,
          "seek": 79252,
          "start": 1614.846,
          "end": 1620.806,
          "text": " doing some kind of um baking things into into like approximate forward passes or something like that",
          "tokens": [
            50870,
            884,
            512,
            733,
            295,
            1105,
            12102,
            721,
            666,
            666,
            411,
            30874,
            2128,
            11335,
            420,
            746,
            411,
            300,
            51168
          ],
          "temperature": 0,
          "avg_logprob": -0.055378582,
          "compression_ratio": 1.7854406,
          "no_speech_prob": 1.2595768e-12
        },
        {
          "id": 317,
          "seek": 79252,
          "start": 1620.806,
          "end": 1626.366,
          "text": " to do this and yeah so in the future you know i don't know i mean i think",
          "tokens": [
            51168,
            281,
            360,
            341,
            293,
            1338,
            370,
            294,
            264,
            2027,
            291,
            458,
            741,
            500,
            380,
            458,
            741,
            914,
            741,
            519,
            51446
          ],
          "temperature": 0,
          "avg_logprob": -0.055378582,
          "compression_ratio": 1.7854406,
          "no_speech_prob": 1.2595768e-12
        },
        {
          "id": 318,
          "seek": 79252,
          "start": 1626.366,
          "end": 1633.7261,
          "text": " is it already a trend to some degree that things that are people were having to use test time",
          "tokens": [
            51446,
            307,
            309,
            1217,
            257,
            6028,
            281,
            512,
            4314,
            300,
            721,
            300,
            366,
            561,
            645,
            1419,
            281,
            764,
            1500,
            565,
            51814
          ],
          "temperature": 0,
          "avg_logprob": -0.055378582,
          "compression_ratio": 1.7854406,
          "no_speech_prob": 1.2595768e-12
        },
        {
          "id": 319,
          "seek": 82150,
          "start": 1633.7261,
          "end": 1641.786,
          "text": " compute for getting like used to train back the the base model right yeah yeah that so now it can",
          "tokens": [
            50365,
            14722,
            337,
            1242,
            411,
            1143,
            281,
            3847,
            646,
            264,
            264,
            3096,
            2316,
            558,
            1338,
            1338,
            300,
            370,
            586,
            309,
            393,
            50768
          ],
          "temperature": 0,
          "avg_logprob": -0.04627536,
          "compression_ratio": 1.7263157,
          "no_speech_prob": 9.733307e-13
        },
        {
          "id": 320,
          "seek": 1645,
          "start": 1641.786,
          "end": 1657.052,
          "text": " do it in one pass right yeah so i mean i think yeah you know maybe evolution did or didn do that uh i think evolution still has to pass everything through the genome right to build the network so and the environment in which humans are living is very",
          "tokens": [
            50768,
            360,
            309,
            294,
            472,
            1320,
            558,
            1338,
            370,
            741,
            914,
            741,
            519,
            1338,
            291,
            458,
            1310,
            9303,
            630,
            420,
            994,
            380,
            360,
            300,
            51090,
            51090,
            2232,
            741,
            519,
            9303,
            920,
            575,
            281,
            1320,
            1203,
            807,
            264,
            50672,
            50672,
            21953,
            558,
            281,
            1322,
            264,
            3209,
            370,
            293,
            264,
            2823,
            294,
            597,
            6255,
            366,
            2647,
            307,
            588,
            50925
          ],
          "temperature": 0,
          "avg_logprob": -0.04958743,
          "compression_ratio": 1.8037736,
          "no_speech_prob": 1.655458e-12
        },
        {
          "id": 321,
          "seek": 1645,
          "start": 1657.052,
          "end": 1664.612,
          "text": " dynamic right and so maybe that's if we believe this is true that that there's a learning subsystem",
          "tokens": [
            50925,
            8546,
            558,
            293,
            370,
            1310,
            300,
            311,
            498,
            321,
            1697,
            341,
            307,
            2074,
            300,
            300,
            456,
            311,
            257,
            2539,
            2090,
            9321,
            51303
          ],
          "temperature": 0,
          "avg_logprob": -0.04958743,
          "compression_ratio": 1.8037736,
          "no_speech_prob": 1.655458e-12
        },
        {
          "id": 322,
          "seek": 1645,
          "start": 1664.612,
          "end": 1668.4121,
          "text": " per steve burns and a steering subsystem the learning subsystem doesn't have a lot of like",
          "tokens": [
            51303,
            680,
            2126,
            303,
            22684,
            293,
            257,
            14823,
            2090,
            9321,
            264,
            2539,
            2090,
            9321,
            1177,
            380,
            362,
            257,
            688,
            295,
            411,
            51493
          ],
          "temperature": 0,
          "avg_logprob": -0.04958743,
          "compression_ratio": 1.8037736,
          "no_speech_prob": 1.655458e-12
        },
        {
          "id": 323,
          "seek": 1645,
          "start": 1668.4121,
          "end": 1673.3721,
          "text": " pre-initialization or pre-training um it has a certain architecture but then within lifetime it",
          "tokens": [
            51493,
            659,
            12,
            259,
            270,
            831,
            2144,
            420,
            659,
            12,
            17227,
            1760,
            1105,
            309,
            575,
            257,
            1629,
            9482,
            457,
            550,
            1951,
            11364,
            309,
            51741
          ],
          "temperature": 0,
          "avg_logprob": -0.04958743,
          "compression_ratio": 1.8037736,
          "no_speech_prob": 1.655458e-12
        },
        {
          "id": 324,
          "seek": 4397,
          "start": 1673.3721,
          "end": 1679.072,
          "text": " learns um then evolution didn't you know actually like amortize that much into that network right",
          "tokens": [
            50365,
            27152,
            1105,
            550,
            9303,
            994,
            380,
            291,
            458,
            767,
            411,
            669,
            477,
            1125,
            300,
            709,
            666,
            300,
            3209,
            558,
            50650
          ],
          "temperature": 0,
          "avg_logprob": -0.062250014,
          "compression_ratio": 1.7168459,
          "no_speech_prob": 1.4898973e-12
        },
        {
          "id": 325,
          "seek": 4397,
          "start": 1679.072,
          "end": 1684.0121,
          "text": " it amortized it instead into a set of innate behaviors in a set of these bootstrapping cost",
          "tokens": [
            50650,
            309,
            669,
            477,
            1602,
            309,
            2602,
            666,
            257,
            992,
            295,
            41766,
            15501,
            294,
            257,
            992,
            295,
            613,
            11450,
            19639,
            3759,
            2063,
            50897
          ],
          "temperature": 0,
          "avg_logprob": -0.062250014,
          "compression_ratio": 1.7168459,
          "no_speech_prob": 1.4898973e-12
        },
        {
          "id": 326,
          "seek": 4397,
          "start": 1684.0121,
          "end": 1689.552,
          "text": " functions or ways of building up very particular reward signals yeah yeah this framework helps",
          "tokens": [
            50897,
            6828,
            420,
            2098,
            295,
            2390,
            493,
            588,
            1729,
            7782,
            12354,
            1338,
            1338,
            341,
            8388,
            3665,
            51174
          ],
          "temperature": 0,
          "avg_logprob": -0.062250014,
          "compression_ratio": 1.7168459,
          "no_speech_prob": 1.4898973e-12
        },
        {
          "id": 327,
          "seek": 4397,
          "start": 1689.552,
          "end": 1695.452,
          "text": " explain this um mystery that people have pointed out and i've asked a few guests about which is",
          "tokens": [
            51174,
            2903,
            341,
            1105,
            11422,
            300,
            561,
            362,
            10932,
            484,
            293,
            741,
            600,
            2351,
            257,
            1326,
            9804,
            466,
            597,
            307,
            51469
          ],
          "temperature": 0,
          "avg_logprob": -0.062250014,
          "compression_ratio": 1.7168459,
          "no_speech_prob": 1.4898973e-12
        },
        {
          "id": 328,
          "seek": 4397,
          "start": 1695.452,
          "end": 1701.8921,
          "text": " if you want to analogize evolution to pre-training well how do you explain the fact that so little",
          "tokens": [
            51469,
            498,
            291,
            528,
            281,
            16660,
            1125,
            9303,
            281,
            659,
            12,
            17227,
            1760,
            731,
            577,
            360,
            291,
            2903,
            264,
            1186,
            300,
            370,
            707,
            51791
          ],
          "temperature": 0,
          "avg_logprob": -0.062250014,
          "compression_ratio": 1.7168459,
          "no_speech_prob": 1.4898973e-12
        },
        {
          "id": 329,
          "seek": 7249,
          "start": 1701.8921,
          "end": 1707.552,
          "text": " information is conveyed through the genome so three gigabytes is the size of the total human",
          "tokens": [
            50365,
            1589,
            307,
            49340,
            807,
            264,
            21953,
            370,
            1045,
            42741,
            307,
            264,
            2744,
            295,
            264,
            3217,
            1952,
            50648
          ],
          "temperature": 0,
          "avg_logprob": -0.041808993,
          "compression_ratio": 1.7890625,
          "no_speech_prob": 1.9732863e-12
        },
        {
          "id": 330,
          "seek": 7249,
          "start": 1707.552,
          "end": 1711.0321,
          "text": " genome obviously a small fraction of that is actually relevant to coding at the brain yeah",
          "tokens": [
            50648,
            21953,
            2745,
            257,
            1359,
            14135,
            295,
            300,
            307,
            767,
            7340,
            281,
            17720,
            412,
            264,
            3567,
            1338,
            50822
          ],
          "temperature": 0,
          "avg_logprob": -0.041808993,
          "compression_ratio": 1.7890625,
          "no_speech_prob": 1.9732863e-12
        },
        {
          "id": 331,
          "seek": 7249,
          "start": 1711.0321,
          "end": 1717.792,
          "text": " um and if previously people made this analogy that actually uh evolution has found the hyper",
          "tokens": [
            50822,
            1105,
            293,
            498,
            8046,
            561,
            1027,
            341,
            21663,
            300,
            767,
            2232,
            9303,
            575,
            1352,
            264,
            9848,
            51160
          ],
          "temperature": 0,
          "avg_logprob": -0.041808993,
          "compression_ratio": 1.7890625,
          "no_speech_prob": 1.9732863e-12
        },
        {
          "id": 332,
          "seek": 7249,
          "start": 1717.792,
          "end": 1722.092,
          "text": " parameters of the model the the numbers which tell you how many layers should there be the",
          "tokens": [
            51160,
            9834,
            295,
            264,
            2316,
            264,
            264,
            3547,
            597,
            980,
            291,
            577,
            867,
            7914,
            820,
            456,
            312,
            264,
            51375
          ],
          "temperature": 0,
          "avg_logprob": -0.041808993,
          "compression_ratio": 1.7890625,
          "no_speech_prob": 1.9732863e-12
        },
        {
          "id": 333,
          "seek": 7249,
          "start": 1722.092,
          "end": 1726.572,
          "text": " architecture basically right like how should things be wired together but if a big part of",
          "tokens": [
            51375,
            9482,
            1936,
            558,
            411,
            577,
            820,
            721,
            312,
            27415,
            1214,
            457,
            498,
            257,
            955,
            644,
            295,
            51599
          ],
          "temperature": 0,
          "avg_logprob": -0.041808993,
          "compression_ratio": 1.7890625,
          "no_speech_prob": 1.9732863e-12
        },
        {
          "id": 334,
          "seek": 9717,
          "start": 1726.572,
          "end": 1732.292,
          "text": " the story that increases sample efficiency aids learning generally makes systems more performant",
          "tokens": [
            50365,
            264,
            1657,
            300,
            8637,
            6889,
            10493,
            28447,
            2539,
            5101,
            1669,
            3652,
            544,
            2042,
            394,
            50651
          ],
          "temperature": 0,
          "avg_logprob": -0.045829978,
          "compression_ratio": 1.9753087,
          "no_speech_prob": 1.9429772e-12
        },
        {
          "id": 335,
          "seek": 9717,
          "start": 1732.292,
          "end": 1738.972,
          "text": " is the reward function is the loss function yeah and if evolution found those loss functions which",
          "tokens": [
            50651,
            307,
            264,
            7782,
            2445,
            307,
            264,
            4470,
            2445,
            1338,
            293,
            498,
            9303,
            1352,
            729,
            4470,
            6828,
            597,
            50985
          ],
          "temperature": 0,
          "avg_logprob": -0.045829978,
          "compression_ratio": 1.9753087,
          "no_speech_prob": 1.9429772e-12
        },
        {
          "id": 336,
          "seek": 9717,
          "start": 1738.972,
          "end": 1744.972,
          "text": " aid learning then it actually kind of makes sense how so you can like build an intelligence with so",
          "tokens": [
            50985,
            9418,
            2539,
            550,
            309,
            767,
            733,
            295,
            1669,
            2020,
            577,
            370,
            291,
            393,
            411,
            1322,
            364,
            7599,
            365,
            370,
            51285
          ],
          "temperature": 0,
          "avg_logprob": -0.045829978,
          "compression_ratio": 1.9753087,
          "no_speech_prob": 1.9429772e-12
        },
        {
          "id": 337,
          "seek": 9717,
          "start": 1744.972,
          "end": 1748.952,
          "text": " little information because like the reward function are you like right in python right",
          "tokens": [
            51285,
            707,
            1589,
            570,
            411,
            264,
            7782,
            2445,
            366,
            291,
            411,
            558,
            294,
            38797,
            558,
            51484
          ],
          "temperature": 0,
          "avg_logprob": -0.045829978,
          "compression_ratio": 1.9753087,
          "no_speech_prob": 1.9429772e-12
        },
        {
          "id": 338,
          "seek": 9717,
          "start": 1748.952,
          "end": 1752.9121,
          "text": " the reward function is like literally a line yeah and so you just like have like a thousand lines",
          "tokens": [
            51484,
            264,
            7782,
            2445,
            307,
            411,
            3736,
            257,
            1622,
            1338,
            293,
            370,
            291,
            445,
            411,
            362,
            411,
            257,
            4714,
            3876,
            51682
          ],
          "temperature": 0,
          "avg_logprob": -0.045829978,
          "compression_ratio": 1.9753087,
          "no_speech_prob": 1.9429772e-12
        },
        {
          "id": 339,
          "seek": 12351,
          "start": 1752.9121,
          "end": 1757.792,
          "text": " like this and that doesn't take up that much space yes and it also gets to do this generalization",
          "tokens": [
            50365,
            411,
            341,
            293,
            300,
            1177,
            380,
            747,
            493,
            300,
            709,
            1901,
            2086,
            293,
            309,
            611,
            2170,
            281,
            360,
            341,
            2674,
            2144,
            50609
          ],
          "temperature": 0,
          "avg_logprob": -0.032382395,
          "compression_ratio": 1.9624573,
          "no_speech_prob": 2.5740013e-12
        },
        {
          "id": 340,
          "seek": 12351,
          "start": 1757.792,
          "end": 1761.2521,
          "text": " thing with the thing the thing i was describing where we were talking with about the spider right",
          "tokens": [
            50609,
            551,
            365,
            264,
            551,
            264,
            551,
            741,
            390,
            16141,
            689,
            321,
            645,
            1417,
            365,
            466,
            264,
            17614,
            558,
            50782
          ],
          "temperature": 0,
          "avg_logprob": -0.032382395,
          "compression_ratio": 1.9624573,
          "no_speech_prob": 2.5740013e-12
        },
        {
          "id": 341,
          "seek": 12351,
          "start": 1761.2521,
          "end": 1765.092,
          "text": " of where it learns that just the word spider you know triggers the spider you know reflex or",
          "tokens": [
            50782,
            295,
            689,
            309,
            27152,
            300,
            445,
            264,
            1349,
            17614,
            291,
            458,
            22827,
            264,
            17614,
            291,
            458,
            23802,
            420,
            50974
          ],
          "temperature": 0,
          "avg_logprob": -0.032382395,
          "compression_ratio": 1.9624573,
          "no_speech_prob": 2.5740013e-12
        },
        {
          "id": 342,
          "seek": 12351,
          "start": 1765.092,
          "end": 1771.472,
          "text": " whatever um it gets to exploit that too right so it gets to build a reward function that actually",
          "tokens": [
            50974,
            2035,
            1105,
            309,
            2170,
            281,
            25924,
            300,
            886,
            558,
            370,
            309,
            2170,
            281,
            1322,
            257,
            7782,
            2445,
            300,
            767,
            51293
          ],
          "temperature": 0,
          "avg_logprob": -0.032382395,
          "compression_ratio": 1.9624573,
          "no_speech_prob": 2.5740013e-12
        },
        {
          "id": 343,
          "seek": 12351,
          "start": 1771.472,
          "end": 1775.552,
          "text": " has a bunch of generalization in it just by specifying these innate spider stuff and the",
          "tokens": [
            51293,
            575,
            257,
            3840,
            295,
            2674,
            2144,
            294,
            309,
            445,
            538,
            1608,
            5489,
            613,
            41766,
            17614,
            1507,
            293,
            264,
            51497
          ],
          "temperature": 0,
          "avg_logprob": -0.032382395,
          "compression_ratio": 1.9624573,
          "no_speech_prob": 2.5740013e-12
        },
        {
          "id": 344,
          "seek": 12351,
          "start": 1775.552,
          "end": 1779.612,
          "text": " thought assessors as steve calls them that do the learning um so that's like a potentially a really",
          "tokens": [
            51497,
            1194,
            5877,
            830,
            382,
            2126,
            303,
            5498,
            552,
            300,
            360,
            264,
            2539,
            1105,
            370,
            300,
            311,
            411,
            257,
            7263,
            257,
            534,
            51700
          ],
          "temperature": 0,
          "avg_logprob": -0.032382395,
          "compression_ratio": 1.9624573,
          "no_speech_prob": 2.5740013e-12
        },
        {
          "id": 345,
          "seek": 15021,
          "start": 1779.612,
          "end": 1784.6321,
          "text": " compact solution to building up these more complex reward functions too that you need.",
          "tokens": [
            50365,
            14679,
            3827,
            281,
            2390,
            493,
            613,
            544,
            3997,
            7782,
            6828,
            886,
            300,
            291,
            643,
            13,
            50616
          ],
          "temperature": 0,
          "avg_logprob": -0.096175656,
          "compression_ratio": 2.0402684,
          "no_speech_prob": 1.8539942e-12
        },
        {
          "id": 346,
          "seek": 15021,
          "start": 1784.7521,
          "end": 1788.032,
          "text": " So it doesn't have to anticipate everything about the future of the reward function, just",
          "tokens": [
            50622,
            407,
            309,
            1177,
            380,
            362,
            281,
            21685,
            1203,
            466,
            264,
            2027,
            295,
            264,
            7782,
            2445,
            11,
            445,
            50786
          ],
          "temperature": 0,
          "avg_logprob": -0.096175656,
          "compression_ratio": 2.0402684,
          "no_speech_prob": 1.8539942e-12
        },
        {
          "id": 347,
          "seek": 15021,
          "start": 1788.032,
          "end": 1791.592,
          "text": " anticipate what variables are relevant, what are heuristics for like finding what those",
          "tokens": [
            50786,
            21685,
            437,
            9102,
            366,
            7340,
            11,
            437,
            366,
            415,
            374,
            6006,
            337,
            411,
            5006,
            437,
            729,
            50964
          ],
          "temperature": 0,
          "avg_logprob": -0.096175656,
          "compression_ratio": 2.0402684,
          "no_speech_prob": 1.8539942e-12
        },
        {
          "id": 348,
          "seek": 15021,
          "start": 1791.592,
          "end": 1792.352,
          "text": " variables are.",
          "tokens": [
            50964,
            9102,
            366,
            13,
            51002
          ],
          "temperature": 0,
          "avg_logprob": -0.096175656,
          "compression_ratio": 2.0402684,
          "no_speech_prob": 1.8539942e-12
        },
        {
          "id": 349,
          "seek": 15021,
          "start": 1793.312,
          "end": 1796.692,
          "text": " And then, yeah, so then it has to have like a very compact specification for like the",
          "tokens": [
            51050,
            400,
            550,
            11,
            1338,
            11,
            370,
            550,
            309,
            575,
            281,
            362,
            411,
            257,
            588,
            14679,
            31256,
            337,
            411,
            264,
            51219
          ],
          "temperature": 0,
          "avg_logprob": -0.096175656,
          "compression_ratio": 2.0402684,
          "no_speech_prob": 1.8539942e-12
        },
        {
          "id": 350,
          "seek": 15021,
          "start": 1796.692,
          "end": 1799.712,
          "text": " learning algorithm and basic architecture of the learning subsystem.",
          "tokens": [
            51219,
            2539,
            9284,
            293,
            3875,
            9482,
            295,
            264,
            2539,
            2090,
            9321,
            13,
            51370
          ],
          "temperature": 0,
          "avg_logprob": -0.096175656,
          "compression_ratio": 2.0402684,
          "no_speech_prob": 1.8539942e-12
        },
        {
          "id": 351,
          "seek": 15021,
          "start": 1800.232,
          "end": 1804.332,
          "text": " And then it has to specify all this Python code of like all the stuff about the spiders",
          "tokens": [
            51396,
            400,
            550,
            309,
            575,
            281,
            16500,
            439,
            341,
            15329,
            3089,
            295,
            411,
            439,
            264,
            1507,
            466,
            264,
            32171,
            51601
          ],
          "temperature": 0,
          "avg_logprob": -0.096175656,
          "compression_ratio": 2.0402684,
          "no_speech_prob": 1.8539942e-12
        },
        {
          "id": 352,
          "seek": 15021,
          "start": 1804.332,
          "end": 1807.1721,
          "text": " and all the stuff about friends and all the stuff about your mother and all the stuff",
          "tokens": [
            51601,
            293,
            439,
            264,
            1507,
            466,
            1855,
            293,
            439,
            264,
            1507,
            466,
            428,
            2895,
            293,
            439,
            264,
            1507,
            51743
          ],
          "temperature": 0,
          "avg_logprob": -0.096175656,
          "compression_ratio": 2.0402684,
          "no_speech_prob": 1.8539942e-12
        },
        {
          "id": 353,
          "seek": 17777,
          "start": 1807.1721,
          "end": 1812.092,
          "text": " about mating and social groups and joint eye contact.",
          "tokens": [
            50365,
            466,
            49955,
            293,
            2093,
            3935,
            293,
            7225,
            3313,
            3385,
            13,
            50611
          ],
          "temperature": 0,
          "avg_logprob": -0.18850455,
          "compression_ratio": 1.6211454,
          "no_speech_prob": 9.360154e-13
        },
        {
          "id": 354,
          "seek": 17777,
          "start": 1812.1721,
          "end": 1813.5121,
          "text": " It has to specify all that stuff.",
          "tokens": [
            50615,
            467,
            575,
            281,
            16500,
            439,
            300,
            1507,
            13,
            50682
          ],
          "temperature": 0,
          "avg_logprob": -0.18850455,
          "compression_ratio": 1.6211454,
          "no_speech_prob": 9.360154e-13
        },
        {
          "id": 355,
          "seek": 17777,
          "start": 1815.292,
          "end": 1816.2521,
          "text": " And so is this really true?",
          "tokens": [
            50771,
            400,
            370,
            307,
            341,
            534,
            2074,
            30,
            50819
          ],
          "temperature": 0,
          "avg_logprob": -0.18850455,
          "compression_ratio": 1.6211454,
          "no_speech_prob": 9.360154e-13
        },
        {
          "id": 356,
          "seek": 17777,
          "start": 1816.3721,
          "end": 1820.1321,
          "text": " And so I think that there is some evidence for it.",
          "tokens": [
            50825,
            400,
            370,
            286,
            519,
            300,
            456,
            307,
            512,
            4467,
            337,
            309,
            13,
            51013
          ],
          "temperature": 0,
          "avg_logprob": -0.18850455,
          "compression_ratio": 1.6211454,
          "no_speech_prob": 9.360154e-13
        },
        {
          "id": 357,
          "seek": 17777,
          "start": 1820.1321,
          "end": 1826.472,
          "text": " So Fei Chen and Evan McCosco and various other researchers who have been doing these",
          "tokens": [
            51013,
            407,
            39587,
            13682,
            293,
            22613,
            12061,
            329,
            1291,
            293,
            3683,
            661,
            10309,
            567,
            362,
            668,
            884,
            613,
            51330
          ],
          "temperature": 0,
          "avg_logprob": -0.18850455,
          "compression_ratio": 1.6211454,
          "no_speech_prob": 9.360154e-13
        },
        {
          "id": 358,
          "seek": 17777,
          "start": 1826.472,
          "end": 1827.352,
          "text": " single cell atlases.",
          "tokens": [
            51330,
            2167,
            2815,
            412,
            75,
            1957,
            13,
            51374
          ],
          "temperature": 0,
          "avg_logprob": -0.18850455,
          "compression_ratio": 1.6211454,
          "no_speech_prob": 9.360154e-13
        },
        {
          "id": 359,
          "seek": 17777,
          "start": 1827.5121,
          "end": 1832.952,
          "text": " So one of the things that neuroscience technology or scaling up neuroscience technology, again,",
          "tokens": [
            51382,
            407,
            472,
            295,
            264,
            721,
            300,
            42762,
            2899,
            420,
            21589,
            493,
            42762,
            2899,
            11,
            797,
            11,
            51654
          ],
          "temperature": 0,
          "avg_logprob": -0.18850455,
          "compression_ratio": 1.6211454,
          "no_speech_prob": 9.360154e-13
        },
        {
          "id": 360,
          "seek": 20355,
          "start": 1832.952,
          "end": 1840.292,
          "text": " this is kind of like my one of my obsessions um has done uh through through um the brain initiative",
          "tokens": [
            50365,
            341,
            307,
            733,
            295,
            411,
            452,
            472,
            295,
            452,
            3181,
            9069,
            1105,
            575,
            1096,
            2232,
            807,
            807,
            1105,
            264,
            3567,
            11552,
            50732
          ],
          "temperature": 0,
          "avg_logprob": -0.07435505,
          "compression_ratio": 1.9551021,
          "no_speech_prob": 1.0565036e-12
        },
        {
          "id": 361,
          "seek": 20355,
          "start": 1840.292,
          "end": 1844.4121,
          "text": " the big you know neuroscience funding programs they've basically gone through different areas",
          "tokens": [
            50732,
            264,
            955,
            291,
            458,
            42762,
            6137,
            4268,
            436,
            600,
            1936,
            2780,
            807,
            819,
            3179,
            50938
          ],
          "temperature": 0,
          "avg_logprob": -0.07435505,
          "compression_ratio": 1.9551021,
          "no_speech_prob": 1.0565036e-12
        },
        {
          "id": 362,
          "seek": 20355,
          "start": 1844.4121,
          "end": 1851.072,
          "text": " especially the mouse brain and map like where are the different cell types um how many different",
          "tokens": [
            50938,
            2318,
            264,
            9719,
            3567,
            293,
            4471,
            411,
            689,
            366,
            264,
            819,
            2815,
            3467,
            1105,
            577,
            867,
            819,
            51271
          ],
          "temperature": 0,
          "avg_logprob": -0.07435505,
          "compression_ratio": 1.9551021,
          "no_speech_prob": 1.0565036e-12
        },
        {
          "id": 363,
          "seek": 20355,
          "start": 1851.072,
          "end": 1855.4921,
          "text": " types of cells are there in different areas of cortex are they the same across different areas",
          "tokens": [
            51271,
            3467,
            295,
            5438,
            366,
            456,
            294,
            819,
            3179,
            295,
            33312,
            366,
            436,
            264,
            912,
            2108,
            819,
            3179,
            51492
          ],
          "temperature": 0,
          "avg_logprob": -0.07435505,
          "compression_ratio": 1.9551021,
          "no_speech_prob": 1.0565036e-12
        },
        {
          "id": 364,
          "seek": 20355,
          "start": 1855.4921,
          "end": 1858.592,
          "text": " and then you then you look at these subcortical regions which are more like the like steering",
          "tokens": [
            51492,
            293,
            550,
            291,
            550,
            291,
            574,
            412,
            613,
            1422,
            66,
            477,
            804,
            10682,
            597,
            366,
            544,
            411,
            264,
            411,
            14823,
            51647
          ],
          "temperature": 0,
          "avg_logprob": -0.07435505,
          "compression_ratio": 1.9551021,
          "no_speech_prob": 1.0565036e-12
        },
        {
          "id": 365,
          "seek": 22919,
          "start": 1858.592,
          "end": 1863.572,
          "text": " subsystem or reward function generating regions how many different types of cells do they have",
          "tokens": [
            50365,
            2090,
            9321,
            420,
            7782,
            2445,
            17746,
            10682,
            577,
            867,
            819,
            3467,
            295,
            5438,
            360,
            436,
            362,
            50614
          ],
          "temperature": 0,
          "avg_logprob": -0.04360607,
          "compression_ratio": 1.8984375,
          "no_speech_prob": 7.491798e-13
        },
        {
          "id": 366,
          "seek": 22919,
          "start": 1863.572,
          "end": 1868.1721,
          "text": " and which neurons types do they have we don't know how they're all connected and exactly what they do",
          "tokens": [
            50614,
            293,
            597,
            22027,
            3467,
            360,
            436,
            362,
            321,
            500,
            380,
            458,
            577,
            436,
            434,
            439,
            4582,
            293,
            2293,
            437,
            436,
            360,
            50844
          ],
          "temperature": 0,
          "avg_logprob": -0.04360607,
          "compression_ratio": 1.8984375,
          "no_speech_prob": 7.491798e-13
        },
        {
          "id": 367,
          "seek": 22919,
          "start": 1868.1721,
          "end": 1872.092,
          "text": " or what the circuits are what they mean but you can just like quantify like how many different",
          "tokens": [
            50844,
            420,
            437,
            264,
            26354,
            366,
            437,
            436,
            914,
            457,
            291,
            393,
            445,
            411,
            40421,
            411,
            577,
            867,
            819,
            51040
          ],
          "temperature": 0,
          "avg_logprob": -0.04360607,
          "compression_ratio": 1.8984375,
          "no_speech_prob": 7.491798e-13
        },
        {
          "id": 368,
          "seek": 22919,
          "start": 1872.092,
          "end": 1882.7721,
          "text": " kinds of cells are there um with sequencing the rna and there are a lot more weird and diverse",
          "tokens": [
            51040,
            3685,
            295,
            5438,
            366,
            456,
            1105,
            365,
            32693,
            264,
            367,
            629,
            293,
            456,
            366,
            257,
            688,
            544,
            3657,
            293,
            9521,
            51574
          ],
          "temperature": 0,
          "avg_logprob": -0.04360607,
          "compression_ratio": 1.8984375,
          "no_speech_prob": 7.491798e-13
        },
        {
          "id": 369,
          "seek": 22919,
          "start": 1882.7721,
          "end": 1887.472,
          "text": " and bespoke cell types in the steering subsystem basically than there are in the learning subsystem",
          "tokens": [
            51574,
            293,
            4097,
            48776,
            2815,
            3467,
            294,
            264,
            14823,
            2090,
            9321,
            1936,
            813,
            456,
            366,
            294,
            264,
            2539,
            2090,
            9321,
            51809
          ],
          "temperature": 0,
          "avg_logprob": -0.04360607,
          "compression_ratio": 1.8984375,
          "no_speech_prob": 7.491798e-13
        },
        {
          "id": 370,
          "seek": 25807,
          "start": 1887.472,
          "end": 1894.032,
          "text": " Like the cortical cell types, there's enough to build. It seems like there's enough to build a learning algorithm up there and specify some hyperparameters.",
          "tokens": [
            50365,
            1743,
            264,
            11278,
            804,
            2815,
            3467,
            11,
            456,
            311,
            1547,
            281,
            1322,
            13,
            467,
            2544,
            411,
            456,
            311,
            1547,
            281,
            1322,
            257,
            2539,
            9284,
            493,
            456,
            293,
            16500,
            512,
            9848,
            2181,
            335,
            6202,
            13,
            50693
          ],
          "temperature": 0,
          "avg_logprob": -0.120891064,
          "compression_ratio": 1.8214285,
          "no_speech_prob": 1.38861e-12
        },
        {
          "id": 371,
          "seek": 25807,
          "start": 1894.712,
          "end": 1905.2521,
          "text": " And in the in the steering subsystem, there's like a gazillion, you know, thousands of really weird cells, which might be like the one for the spider flinch reflex and the one for I'm about to taste salt.",
          "tokens": [
            50727,
            400,
            294,
            264,
            294,
            264,
            14823,
            2090,
            9321,
            11,
            456,
            311,
            411,
            257,
            26232,
            11836,
            11,
            291,
            458,
            11,
            5383,
            295,
            534,
            3657,
            5438,
            11,
            597,
            1062,
            312,
            411,
            264,
            472,
            337,
            264,
            17614,
            932,
            12415,
            23802,
            293,
            264,
            472,
            337,
            286,
            478,
            466,
            281,
            3939,
            5139,
            13,
            51254
          ],
          "temperature": 0,
          "avg_logprob": -0.120891064,
          "compression_ratio": 1.8214285,
          "no_speech_prob": 1.38861e-12
        },
        {
          "id": 372,
          "seek": 25807,
          "start": 1905.3921,
          "end": 1909.112,
          "text": " Why would each reward function need a different cell type?",
          "tokens": [
            51261,
            1545,
            576,
            1184,
            7782,
            2445,
            643,
            257,
            819,
            2815,
            2010,
            30,
            51447
          ],
          "temperature": 0,
          "avg_logprob": -0.120891064,
          "compression_ratio": 1.8214285,
          "no_speech_prob": 1.38861e-12
        },
        {
          "id": 373,
          "seek": 25807,
          "start": 1909.472,
          "end": 1916.792,
          "text": " Well, so this is where you get innately wired circuits. Right. So in the learning algorithm part in this in the learning learning subsystem.",
          "tokens": [
            51465,
            1042,
            11,
            370,
            341,
            307,
            689,
            291,
            483,
            7714,
            1592,
            27415,
            26354,
            13,
            1779,
            13,
            407,
            294,
            264,
            2539,
            9284,
            644,
            294,
            341,
            294,
            264,
            2539,
            2539,
            2090,
            9321,
            13,
            51831
          ],
          "temperature": 0,
          "avg_logprob": -0.120891064,
          "compression_ratio": 1.8214285,
          "no_speech_prob": 1.38861e-12
        },
        {
          "id": 374,
          "seek": 28807,
          "start": 1917.472,
          "end": 1921.4921,
          "text": " um you set up specify the initial architecture you specify a learning algorithm is all all the",
          "tokens": [
            50365,
            1105,
            291,
            992,
            493,
            16500,
            264,
            5883,
            9482,
            291,
            16500,
            257,
            2539,
            9284,
            307,
            439,
            439,
            264,
            50566
          ],
          "temperature": 0,
          "avg_logprob": -0.058073778,
          "compression_ratio": 1.9204153,
          "no_speech_prob": 1.769109e-12
        },
        {
          "id": 375,
          "seek": 28807,
          "start": 1921.4921,
          "end": 1926.332,
          "text": " all the all the juices is happening through plasticity of the synapses changes of the",
          "tokens": [
            50566,
            439,
            264,
            439,
            264,
            37027,
            307,
            2737,
            807,
            5900,
            507,
            295,
            264,
            5451,
            2382,
            279,
            2962,
            295,
            264,
            50808
          ],
          "temperature": 0,
          "avg_logprob": -0.058073778,
          "compression_ratio": 1.9204153,
          "no_speech_prob": 1.769109e-12
        },
        {
          "id": 376,
          "seek": 28807,
          "start": 1926.332,
          "end": 1931.232,
          "text": " synapses within that big network but it's kind of like a relatively repeating architecture",
          "tokens": [
            50808,
            5451,
            2382,
            279,
            1951,
            300,
            955,
            3209,
            457,
            309,
            311,
            733,
            295,
            411,
            257,
            7226,
            18617,
            9482,
            51053
          ],
          "temperature": 0,
          "avg_logprob": -0.058073778,
          "compression_ratio": 1.9204153,
          "no_speech_prob": 1.769109e-12
        },
        {
          "id": 377,
          "seek": 28807,
          "start": 1931.232,
          "end": 1936.972,
          "text": " um how it's initialized it's just like um the amount of python code needed to make you know",
          "tokens": [
            51053,
            1105,
            577,
            309,
            311,
            5883,
            1602,
            309,
            311,
            445,
            411,
            1105,
            264,
            2372,
            295,
            38797,
            3089,
            2978,
            281,
            652,
            291,
            458,
            51340
          ],
          "temperature": 0,
          "avg_logprob": -0.058073778,
          "compression_ratio": 1.9204153,
          "no_speech_prob": 1.769109e-12
        },
        {
          "id": 378,
          "seek": 28807,
          "start": 1936.972,
          "end": 1941.552,
          "text": " an eight-layer transformer is not that different from one to make a three-layer transformer right",
          "tokens": [
            51340,
            364,
            3180,
            12,
            8376,
            260,
            31782,
            307,
            406,
            300,
            819,
            490,
            472,
            281,
            652,
            257,
            1045,
            12,
            8376,
            260,
            31782,
            558,
            51569
          ],
          "temperature": 0,
          "avg_logprob": -0.058073778,
          "compression_ratio": 1.9204153,
          "no_speech_prob": 1.769109e-12
        },
        {
          "id": 379,
          "seek": 28807,
          "start": 1941.552,
          "end": 1946.052,
          "text": " you're just replicating yeah whereas all this python code for the reward function you know if",
          "tokens": [
            51569,
            291,
            434,
            445,
            3248,
            30541,
            1338,
            9735,
            439,
            341,
            38797,
            3089,
            337,
            264,
            7782,
            2445,
            291,
            458,
            498,
            51794
          ],
          "temperature": 0,
          "avg_logprob": -0.058073778,
          "compression_ratio": 1.9204153,
          "no_speech_prob": 1.769109e-12
        },
        {
          "id": 380,
          "seek": 31665,
          "start": 1946.052,
          "end": 1950.472,
          "text": " superior click list sees something that's skittering and you know you're feeling goosebumps",
          "tokens": [
            50365,
            13028,
            2052,
            1329,
            8194,
            746,
            300,
            311,
            1110,
            3904,
            278,
            293,
            291,
            458,
            291,
            434,
            2633,
            48305,
            50586
          ],
          "temperature": 0,
          "avg_logprob": -0.07070531,
          "compression_ratio": 1.8398438,
          "no_speech_prob": 1.5922398e-12
        },
        {
          "id": 381,
          "seek": 31665,
          "start": 1950.472,
          "end": 1955.1721,
          "text": " on your skin or whatever then trigger spider reflex that's just a bunch of like bespoke",
          "tokens": [
            50586,
            322,
            428,
            3178,
            420,
            2035,
            550,
            7875,
            17614,
            23802,
            300,
            311,
            445,
            257,
            3840,
            295,
            411,
            4097,
            48776,
            50821
          ],
          "temperature": 0,
          "avg_logprob": -0.07070531,
          "compression_ratio": 1.8398438,
          "no_speech_prob": 1.5922398e-12
        },
        {
          "id": 382,
          "seek": 31665,
          "start": 1955.1721,
          "end": 1963.532,
          "text": " species specific uh situation specific crap that no the cortex doesn't know about spiders it just",
          "tokens": [
            50821,
            6172,
            2685,
            2232,
            2590,
            2685,
            12426,
            300,
            572,
            264,
            33312,
            1177,
            380,
            458,
            466,
            32171,
            309,
            445,
            51239
          ],
          "temperature": 0,
          "avg_logprob": -0.07070531,
          "compression_ratio": 1.8398438,
          "no_speech_prob": 1.5922398e-12
        },
        {
          "id": 383,
          "seek": 31665,
          "start": 1963.532,
          "end": 1969.1321,
          "text": " knows about layers and right and learning the only way to have this like write this reward function",
          "tokens": [
            51239,
            3255,
            466,
            7914,
            293,
            558,
            293,
            2539,
            264,
            787,
            636,
            281,
            362,
            341,
            411,
            2464,
            341,
            7782,
            2445,
            51519
          ],
          "temperature": 0,
          "avg_logprob": -0.07070531,
          "compression_ratio": 1.8398438,
          "no_speech_prob": 1.5922398e-12
        },
        {
          "id": 384,
          "seek": 31665,
          "start": 1969.1321,
          "end": 1973.732,
          "text": " yeah is to have a special cell type yeah yeah well i think so i think you either have to have",
          "tokens": [
            51519,
            1338,
            307,
            281,
            362,
            257,
            2121,
            2815,
            2010,
            1338,
            1338,
            731,
            741,
            519,
            370,
            741,
            519,
            291,
            2139,
            362,
            281,
            362,
            51749
          ],
          "temperature": 0,
          "avg_logprob": -0.07070531,
          "compression_ratio": 1.8398438,
          "no_speech_prob": 1.5922398e-12
        },
        {
          "id": 385,
          "seek": 34433,
          "start": 1973.732,
          "end": 1979.292,
          "text": " the special cell types or you have to somehow otherwise get special wiring rules that evolution",
          "tokens": [
            50365,
            264,
            2121,
            2815,
            3467,
            420,
            291,
            362,
            281,
            6063,
            5911,
            483,
            2121,
            27520,
            4474,
            300,
            9303,
            50643
          ],
          "temperature": 0,
          "avg_logprob": -0.065992355,
          "compression_ratio": 1.7183099,
          "no_speech_prob": 1.3251421e-12
        },
        {
          "id": 386,
          "seek": 34433,
          "start": 1979.292,
          "end": 1985.1521,
          "text": " can say this neuron needs to wire to this neuron without any learning. And the way that that is",
          "tokens": [
            50643,
            393,
            584,
            341,
            34090,
            2203,
            281,
            6234,
            281,
            341,
            34090,
            1553,
            604,
            2539,
            13,
            400,
            264,
            636,
            300,
            300,
            307,
            50936
          ],
          "temperature": 0,
          "avg_logprob": -0.065992355,
          "compression_ratio": 1.7183099,
          "no_speech_prob": 1.3251421e-12
        },
        {
          "id": 387,
          "seek": 34433,
          "start": 1985.1521,
          "end": 1989.6721,
          "text": " most likely to happen, I think, is that those cells express like different receptors and proteins",
          "tokens": [
            50936,
            881,
            3700,
            281,
            1051,
            11,
            286,
            519,
            11,
            307,
            300,
            729,
            5438,
            5109,
            411,
            819,
            34102,
            293,
            15577,
            51162
          ],
          "temperature": 0,
          "avg_logprob": -0.065992355,
          "compression_ratio": 1.7183099,
          "no_speech_prob": 1.3251421e-12
        },
        {
          "id": 388,
          "seek": 34433,
          "start": 1989.6721,
          "end": 1996.572,
          "text": " that say, OK, when this one comes in contact with this one, let's form a synapse. So it's genetic",
          "tokens": [
            51162,
            300,
            584,
            11,
            2264,
            11,
            562,
            341,
            472,
            1487,
            294,
            3385,
            365,
            341,
            472,
            11,
            718,
            311,
            1254,
            257,
            5451,
            11145,
            13,
            407,
            309,
            311,
            12462,
            51507
          ],
          "temperature": 0,
          "avg_logprob": -0.065992355,
          "compression_ratio": 1.7183099,
          "no_speech_prob": 1.3251421e-12
        },
        {
          "id": 389,
          "seek": 34433,
          "start": 1996.572,
          "end": 2001.932,
          "text": " wiring. Yeah. And those need cell types to do it. Yeah. I'm sure this would make a lot more sense if",
          "tokens": [
            51507,
            27520,
            13,
            865,
            13,
            400,
            729,
            643,
            2815,
            3467,
            281,
            360,
            309,
            13,
            865,
            13,
            286,
            478,
            988,
            341,
            576,
            652,
            257,
            688,
            544,
            2020,
            498,
            51775
          ],
          "temperature": 0,
          "avg_logprob": -0.065992355,
          "compression_ratio": 1.7183099,
          "no_speech_prob": 1.3251421e-12
        },
        {
          "id": 390,
          "seek": 37253,
          "start": 2001.932,
          "end": 2007.532,
          "text": " new 101 neuroscience but like it seems like there's still a lot of complexity",
          "tokens": [
            50365,
            777,
            21055,
            42762,
            457,
            411,
            309,
            2544,
            411,
            456,
            311,
            920,
            257,
            688,
            295,
            14024,
            50645
          ],
          "temperature": 0,
          "avg_logprob": -0.13404219,
          "compression_ratio": 1.798969,
          "no_speech_prob": 1.1694382e-12
        },
        {
          "id": 391,
          "seek": 37253,
          "start": 2007.532,
          "end": 2015.072,
          "text": " or generality rather in the steering system so in the steering system has its own visual",
          "tokens": [
            50645,
            420,
            1337,
            1860,
            2831,
            294,
            264,
            14823,
            1185,
            370,
            294,
            264,
            14823,
            1185,
            575,
            1080,
            1065,
            5056,
            51022
          ],
          "temperature": 0,
          "avg_logprob": -0.13404219,
          "compression_ratio": 1.798969,
          "no_speech_prob": 1.1694382e-12
        },
        {
          "id": 392,
          "seek": 37253,
          "start": 2015.072,
          "end": 2022.8721,
          "text": " uh system that's separate from the visual cortex yeah different features still need to",
          "tokens": [
            51022,
            2232,
            1185,
            300,
            311,
            4994,
            490,
            264,
            5056,
            33312,
            1338,
            819,
            4122,
            920,
            643,
            281,
            51412
          ],
          "temperature": 0,
          "avg_logprob": -0.13404219,
          "compression_ratio": 1.798969,
          "no_speech_prob": 1.1694382e-12
        },
        {
          "id": 393,
          "seek": 37253,
          "start": 2022.8721,
          "end": 2028.552,
          "text": " plug into that vision system in the so like the spider thing needs to plug into it and also the",
          "tokens": [
            51412,
            5452,
            666,
            300,
            5201,
            1185,
            294,
            264,
            370,
            411,
            264,
            17614,
            551,
            2203,
            281,
            5452,
            666,
            309,
            293,
            611,
            264,
            51696
          ],
          "temperature": 0,
          "avg_logprob": -0.13404219,
          "compression_ratio": 1.798969,
          "no_speech_prob": 1.1694382e-12
        },
        {
          "id": 394,
          "seek": 39915,
          "start": 2028.552,
          "end": 2038.292,
          "text": " um the uh love thing needs to plug into it etc etc yes so it seems complicated like no it's still",
          "tokens": [
            50365,
            1105,
            264,
            2232,
            959,
            551,
            2203,
            281,
            5452,
            666,
            309,
            5183,
            5183,
            2086,
            370,
            309,
            2544,
            6179,
            411,
            572,
            309,
            311,
            920,
            50852
          ],
          "temperature": 0,
          "avg_logprob": -0.07731661,
          "compression_ratio": 1.7793428,
          "no_speech_prob": 1.3940459e-12
        },
        {
          "id": 395,
          "seek": 39915,
          "start": 2038.292,
          "end": 2042.832,
          "text": " complicated that's that's all the more reason why a lot of the genomic you know real estate",
          "tokens": [
            50852,
            6179,
            300,
            311,
            300,
            311,
            439,
            264,
            544,
            1778,
            983,
            257,
            688,
            295,
            264,
            1049,
            21401,
            291,
            458,
            957,
            9749,
            51079
          ],
          "temperature": 0,
          "avg_logprob": -0.07731661,
          "compression_ratio": 1.7793428,
          "no_speech_prob": 1.3940459e-12
        },
        {
          "id": 396,
          "seek": 39915,
          "start": 2042.832,
          "end": 2048.172,
          "text": " in the genome and in terms of these different cell types and so on would go into wiring up the",
          "tokens": [
            51079,
            294,
            264,
            21953,
            293,
            294,
            2115,
            295,
            613,
            819,
            2815,
            3467,
            293,
            370,
            322,
            576,
            352,
            666,
            27520,
            493,
            264,
            51346
          ],
          "temperature": 0,
          "avg_logprob": -0.07731661,
          "compression_ratio": 1.7793428,
          "no_speech_prob": 1.3940459e-12
        },
        {
          "id": 397,
          "seek": 39915,
          "start": 2048.172,
          "end": 2053.892,
          "text": " steering subsystem you can be pre-wiring it can we tell how much of the genome is like clearly",
          "tokens": [
            51346,
            14823,
            2090,
            9321,
            291,
            393,
            312,
            659,
            12,
            86,
            5057,
            309,
            393,
            321,
            980,
            577,
            709,
            295,
            264,
            21953,
            307,
            411,
            4448,
            51632
          ],
          "temperature": 0,
          "avg_logprob": -0.07731661,
          "compression_ratio": 1.7793428,
          "no_speech_prob": 1.3940459e-12
        },
        {
          "id": 398,
          "seek": 42449,
          "start": 2053.892,
          "end": 2059.172,
          "text": " working so i guess you could tell how many are relevant to the producing the rna that manifest",
          "tokens": [
            50365,
            1364,
            370,
            741,
            2041,
            291,
            727,
            980,
            577,
            867,
            366,
            7340,
            281,
            264,
            10501,
            264,
            367,
            629,
            300,
            10067,
            50629
          ],
          "temperature": 0,
          "avg_logprob": -0.05440267,
          "compression_ratio": 1.9288136,
          "no_speech_prob": 2.325431e-12
        },
        {
          "id": 399,
          "seek": 42449,
          "start": 2059.172,
          "end": 2063.092,
          "text": " or the epigenetics that manifest in different cell types in the brain right yeah this is what the",
          "tokens": [
            50629,
            420,
            264,
            2388,
            3213,
            15793,
            300,
            10067,
            294,
            819,
            2815,
            3467,
            294,
            264,
            3567,
            558,
            1338,
            341,
            307,
            437,
            264,
            50825
          ],
          "temperature": 0,
          "avg_logprob": -0.05440267,
          "compression_ratio": 1.9288136,
          "no_speech_prob": 2.325431e-12
        },
        {
          "id": 400,
          "seek": 42449,
          "start": 2063.092,
          "end": 2066.172,
          "text": " cell types helps you get at it i don't think i don't think it's exactly like oh this percent of",
          "tokens": [
            50825,
            2815,
            3467,
            3665,
            291,
            483,
            412,
            309,
            741,
            500,
            380,
            519,
            741,
            500,
            380,
            519,
            309,
            311,
            2293,
            411,
            1954,
            341,
            3043,
            295,
            50979
          ],
          "temperature": 0,
          "avg_logprob": -0.05440267,
          "compression_ratio": 1.9288136,
          "no_speech_prob": 2.325431e-12
        },
        {
          "id": 401,
          "seek": 42449,
          "start": 2066.172,
          "end": 2069.532,
          "text": " the genome is doing this but you could say okay in these all these steering substances and sub",
          "tokens": [
            50979,
            264,
            21953,
            307,
            884,
            341,
            457,
            291,
            727,
            584,
            1392,
            294,
            613,
            439,
            613,
            14823,
            25455,
            293,
            1422,
            51147
          ],
          "temperature": 0,
          "avg_logprob": -0.05440267,
          "compression_ratio": 1.9288136,
          "no_speech_prob": 2.325431e-12
        },
        {
          "id": 402,
          "seek": 42449,
          "start": 2069.532,
          "end": 2072.9521,
          "text": " types you know how many different genes are involved in sort of specifying which is which",
          "tokens": [
            51147,
            3467,
            291,
            458,
            577,
            867,
            819,
            14424,
            366,
            3288,
            294,
            1333,
            295,
            1608,
            5489,
            597,
            307,
            597,
            51318
          ],
          "temperature": 0,
          "avg_logprob": -0.05440267,
          "compression_ratio": 1.9288136,
          "no_speech_prob": 2.325431e-12
        },
        {
          "id": 403,
          "seek": 42449,
          "start": 2072.9521,
          "end": 2080.4922,
          "text": " and how they wire um and how much genomic real estate do those genes take up um versus the ones",
          "tokens": [
            51318,
            293,
            577,
            436,
            6234,
            1105,
            293,
            577,
            709,
            1049,
            21401,
            957,
            9749,
            360,
            729,
            14424,
            747,
            493,
            1105,
            5717,
            264,
            2306,
            51695
          ],
          "temperature": 0,
          "avg_logprob": -0.05440267,
          "compression_ratio": 1.9288136,
          "no_speech_prob": 2.325431e-12
        },
        {
          "id": 404,
          "seek": 45109,
          "start": 2080.4922,
          "end": 2085.772,
          "text": " that specify, you know, visual cortex versus auditory cortex, you kind of just reusing the",
          "tokens": [
            50365,
            300,
            16500,
            11,
            291,
            458,
            11,
            5056,
            33312,
            5717,
            17748,
            827,
            33312,
            11,
            291,
            733,
            295,
            445,
            319,
            7981,
            264,
            50629
          ],
          "temperature": 0,
          "avg_logprob": -0.08398643,
          "compression_ratio": 1.8282443,
          "no_speech_prob": 1.3887376e-12
        },
        {
          "id": 405,
          "seek": 45109,
          "start": 2085.772,
          "end": 2090.392,
          "text": " same genes to do the same thing twice. Whereas the spider reflex hooking up, yes, you're right,",
          "tokens": [
            50629,
            912,
            14424,
            281,
            360,
            264,
            912,
            551,
            6091,
            13,
            13813,
            264,
            17614,
            23802,
            1106,
            5953,
            493,
            11,
            2086,
            11,
            291,
            434,
            558,
            11,
            50860
          ],
          "temperature": 0,
          "avg_logprob": -0.08398643,
          "compression_ratio": 1.8282443,
          "no_speech_prob": 1.3887376e-12
        },
        {
          "id": 406,
          "seek": 45109,
          "start": 2090.4521,
          "end": 2095.4922,
          "text": " they have to build a vision system, they have to build some auditory systems and touch systems",
          "tokens": [
            50863,
            436,
            362,
            281,
            1322,
            257,
            5201,
            1185,
            11,
            436,
            362,
            281,
            1322,
            512,
            17748,
            827,
            3652,
            293,
            2557,
            3652,
            51115
          ],
          "temperature": 0,
          "avg_logprob": -0.08398643,
          "compression_ratio": 1.8282443,
          "no_speech_prob": 1.3887376e-12
        },
        {
          "id": 407,
          "seek": 45109,
          "start": 2095.4922,
          "end": 2100.4321,
          "text": " and navigation type systems. So, you know, even feeding into the hippocampus and stuff like that,",
          "tokens": [
            51115,
            293,
            17346,
            2010,
            3652,
            13,
            407,
            11,
            291,
            458,
            11,
            754,
            12919,
            666,
            264,
            27745,
            905,
            1215,
            301,
            293,
            1507,
            411,
            300,
            11,
            51362
          ],
          "temperature": 0,
          "avg_logprob": -0.08398643,
          "compression_ratio": 1.8282443,
          "no_speech_prob": 1.3887376e-12
        },
        {
          "id": 408,
          "seek": 45109,
          "start": 2100.4922,
          "end": 2105.752,
          "text": " there's head direction cells, even the fly brain, it has innate circuits that, you know, figure out",
          "tokens": [
            51365,
            456,
            311,
            1378,
            3513,
            5438,
            11,
            754,
            264,
            3603,
            3567,
            11,
            309,
            575,
            41766,
            26354,
            300,
            11,
            291,
            458,
            11,
            2573,
            484,
            51628
          ],
          "temperature": 0,
          "avg_logprob": -0.08398643,
          "compression_ratio": 1.8282443,
          "no_speech_prob": 1.3887376e-12
        },
        {
          "id": 409,
          "seek": 47635,
          "start": 2105.752,
          "end": 2111.672,
          "text": " orientation and help it navigate in the world and it uses vision figure as optical flow of how it's",
          "tokens": [
            50365,
            14764,
            293,
            854,
            309,
            12350,
            294,
            264,
            1002,
            293,
            309,
            4960,
            5201,
            2573,
            382,
            20674,
            3095,
            295,
            577,
            309,
            311,
            50661
          ],
          "temperature": 0,
          "avg_logprob": -0.059411015,
          "compression_ratio": 1.9625851,
          "no_speech_prob": 1.6882602e-12
        },
        {
          "id": 410,
          "seek": 47635,
          "start": 2111.672,
          "end": 2117.312,
          "text": " flying and you know uh how is it how is its flight related to the wind direction it has all these",
          "tokens": [
            50661,
            7137,
            293,
            291,
            458,
            2232,
            577,
            307,
            309,
            577,
            307,
            1080,
            7018,
            4077,
            281,
            264,
            2468,
            3513,
            309,
            575,
            439,
            613,
            50943
          ],
          "temperature": 0,
          "avg_logprob": -0.059411015,
          "compression_ratio": 1.9625851,
          "no_speech_prob": 1.6882602e-12
        },
        {
          "id": 411,
          "seek": 47635,
          "start": 2117.312,
          "end": 2121.612,
          "text": " innate stuff that i think we in the mammal brain we would all put that and lump that into the",
          "tokens": [
            50943,
            41766,
            1507,
            300,
            741,
            519,
            321,
            294,
            264,
            49312,
            3567,
            321,
            576,
            439,
            829,
            300,
            293,
            25551,
            300,
            666,
            264,
            51158
          ],
          "temperature": 0,
          "avg_logprob": -0.059411015,
          "compression_ratio": 1.9625851,
          "no_speech_prob": 1.6882602e-12
        },
        {
          "id": 412,
          "seek": 47635,
          "start": 2121.612,
          "end": 2125.312,
          "text": " steering subsystem so there's a lot of work so all the genes basically that go into specifying",
          "tokens": [
            51158,
            14823,
            2090,
            9321,
            370,
            456,
            311,
            257,
            688,
            295,
            589,
            370,
            439,
            264,
            14424,
            1936,
            300,
            352,
            666,
            1608,
            5489,
            51343
          ],
          "temperature": 0,
          "avg_logprob": -0.059411015,
          "compression_ratio": 1.9625851,
          "no_speech_prob": 1.6882602e-12
        },
        {
          "id": 413,
          "seek": 47635,
          "start": 2125.312,
          "end": 2129.772,
          "text": " all the things a fly has to do we're going to have stuff like that too just all in the steering",
          "tokens": [
            51343,
            439,
            264,
            721,
            257,
            3603,
            575,
            281,
            360,
            321,
            434,
            516,
            281,
            362,
            1507,
            411,
            300,
            886,
            445,
            439,
            294,
            264,
            14823,
            51566
          ],
          "temperature": 0,
          "avg_logprob": -0.059411015,
          "compression_ratio": 1.9625851,
          "no_speech_prob": 1.6882602e-12
        },
        {
          "id": 414,
          "seek": 47635,
          "start": 2129.772,
          "end": 2135.132,
          "text": " subsystem but do we do we have some estimate of like here's how many nucleotides here are many",
          "tokens": [
            51566,
            2090,
            9321,
            457,
            360,
            321,
            360,
            321,
            362,
            512,
            12539,
            295,
            411,
            510,
            311,
            577,
            867,
            14962,
            310,
            1875,
            510,
            366,
            867,
            51834
          ],
          "temperature": 0,
          "avg_logprob": -0.059411015,
          "compression_ratio": 1.9625851,
          "no_speech_prob": 1.6882602e-12
        },
        {
          "id": 415,
          "seek": 50573,
          "start": 2135.132,
          "end": 2140.752,
          "text": " megabases it takes to i i don't know i mean but but um i mean i think you might be able to talk",
          "tokens": [
            50365,
            10816,
            455,
            1957,
            309,
            2516,
            281,
            741,
            741,
            500,
            380,
            458,
            741,
            914,
            457,
            457,
            1105,
            741,
            914,
            741,
            519,
            291,
            1062,
            312,
            1075,
            281,
            751,
            50646
          ],
          "temperature": 0,
          "avg_logprob": -0.054367967,
          "compression_ratio": 1.7854406,
          "no_speech_prob": 1.5432422e-12
        },
        {
          "id": 416,
          "seek": 50573,
          "start": 2140.752,
          "end": 2146.172,
          "text": " to biologists about this you know to some degree because you can say well we just have a ton in",
          "tokens": [
            50646,
            281,
            3228,
            12256,
            466,
            341,
            291,
            458,
            281,
            512,
            4314,
            570,
            291,
            393,
            584,
            731,
            321,
            445,
            362,
            257,
            2952,
            294,
            50917
          ],
          "temperature": 0,
          "avg_logprob": -0.054367967,
          "compression_ratio": 1.7854406,
          "no_speech_prob": 1.5432422e-12
        },
        {
          "id": 417,
          "seek": 50573,
          "start": 2146.172,
          "end": 2152.4321,
          "text": " common i mean we have a lot in common with yeast from a genes perspective yeast is still used as a",
          "tokens": [
            50917,
            2689,
            741,
            914,
            321,
            362,
            257,
            688,
            294,
            2689,
            365,
            21629,
            490,
            257,
            14424,
            4585,
            21629,
            307,
            920,
            1143,
            382,
            257,
            51230
          ],
          "temperature": 0,
          "avg_logprob": -0.054367967,
          "compression_ratio": 1.7854406,
          "no_speech_prob": 1.5432422e-12
        },
        {
          "id": 418,
          "seek": 50573,
          "start": 2152.4321,
          "end": 2156.892,
          "text": " model yeah for you know some amount of drug development and stuff like that in biology",
          "tokens": [
            51230,
            2316,
            1338,
            337,
            291,
            458,
            512,
            2372,
            295,
            4110,
            3250,
            293,
            1507,
            411,
            300,
            294,
            14956,
            51453
          ],
          "temperature": 0,
          "avg_logprob": -0.054367967,
          "compression_ratio": 1.7854406,
          "no_speech_prob": 1.5432422e-12
        },
        {
          "id": 419,
          "seek": 50573,
          "start": 2156.892,
          "end": 2161.612,
          "text": " and so so much of the genome is just going towards you have a cell at all it can recycle",
          "tokens": [
            51453,
            293,
            370,
            370,
            709,
            295,
            264,
            21953,
            307,
            445,
            516,
            3030,
            291,
            362,
            257,
            2815,
            412,
            439,
            309,
            393,
            32162,
            51689
          ],
          "temperature": 0,
          "avg_logprob": -0.054367967,
          "compression_ratio": 1.7854406,
          "no_speech_prob": 1.5432422e-12
        },
        {
          "id": 420,
          "seek": 53221,
          "start": 2161.612,
          "end": 2168.512,
          "text": " waste it can get energy it can replicate um and then it then you see what we have in common with",
          "tokens": [
            50365,
            5964,
            309,
            393,
            483,
            2281,
            309,
            393,
            25356,
            1105,
            293,
            550,
            309,
            550,
            291,
            536,
            437,
            321,
            362,
            294,
            2689,
            365,
            50710
          ],
          "temperature": 0,
          "avg_logprob": -0.06215286,
          "compression_ratio": 1.8181819,
          "no_speech_prob": 1.6172601e-12
        },
        {
          "id": 421,
          "seek": 53221,
          "start": 2168.512,
          "end": 2172.352,
          "text": " a mouse and so we do know at some level that you know the difference is us in a chimpanzee or",
          "tokens": [
            50710,
            257,
            9719,
            293,
            370,
            321,
            360,
            458,
            412,
            512,
            1496,
            300,
            291,
            458,
            264,
            2649,
            307,
            505,
            294,
            257,
            18375,
            48410,
            68,
            420,
            50902
          ],
          "temperature": 0,
          "avg_logprob": -0.06215286,
          "compression_ratio": 1.8181819,
          "no_speech_prob": 1.6172601e-12
        },
        {
          "id": 422,
          "seek": 53221,
          "start": 2172.352,
          "end": 2175.9722,
          "text": " something and that includes the social instincts and the more advanced you know differences in",
          "tokens": [
            50902,
            746,
            293,
            300,
            5974,
            264,
            2093,
            38997,
            293,
            264,
            544,
            7339,
            291,
            458,
            7300,
            294,
            51083
          ],
          "temperature": 0,
          "avg_logprob": -0.06215286,
          "compression_ratio": 1.8181819,
          "no_speech_prob": 1.6172601e-12
        },
        {
          "id": 423,
          "seek": 53221,
          "start": 2175.9722,
          "end": 2181.792,
          "text": " cortex and so on um it's it's a it's a tiny number of genes that go into these additional amount of",
          "tokens": [
            51083,
            33312,
            293,
            370,
            322,
            1105,
            309,
            311,
            309,
            311,
            257,
            309,
            311,
            257,
            5870,
            1230,
            295,
            14424,
            300,
            352,
            666,
            613,
            4497,
            2372,
            295,
            51374
          ],
          "temperature": 0,
          "avg_logprob": -0.06215286,
          "compression_ratio": 1.8181819,
          "no_speech_prob": 1.6172601e-12
        },
        {
          "id": 424,
          "seek": 53221,
          "start": 2181.792,
          "end": 2185.4922,
          "text": " making the eight-layer transformer instead of the six-layer transformer or",
          "tokens": [
            51374,
            1455,
            264,
            3180,
            12,
            8376,
            260,
            31782,
            2602,
            295,
            264,
            2309,
            12,
            8376,
            260,
            31782,
            420,
            51559
          ],
          "temperature": 0,
          "avg_logprob": -0.06215286,
          "compression_ratio": 1.8181819,
          "no_speech_prob": 1.6172601e-12
        },
        {
          "id": 425,
          "seek": 55609,
          "start": 2185.4922,
          "end": 2194.632,
          "text": " tweaking that reward function this would help explain why the hominid brain exploded inside so",
          "tokens": [
            50365,
            6986,
            2456,
            300,
            7782,
            2445,
            341,
            576,
            854,
            2903,
            983,
            264,
            3655,
            259,
            327,
            3567,
            27049,
            1854,
            370,
            50822
          ],
          "temperature": 0,
          "avg_logprob": -0.050007164,
          "compression_ratio": 1.6960353,
          "no_speech_prob": 1.2497351e-12
        },
        {
          "id": 426,
          "seek": 55609,
          "start": 2194.632,
          "end": 2201.352,
          "text": " fast which is presumably like tell me this is correct but under the story we um social learning",
          "tokens": [
            50822,
            2370,
            597,
            307,
            26742,
            411,
            980,
            385,
            341,
            307,
            3006,
            457,
            833,
            264,
            1657,
            321,
            1105,
            2093,
            2539,
            51158
          ],
          "temperature": 0,
          "avg_logprob": -0.050007164,
          "compression_ratio": 1.6960353,
          "no_speech_prob": 1.2497351e-12
        },
        {
          "id": 427,
          "seek": 55609,
          "start": 2201.352,
          "end": 2208.152,
          "text": " or some other thing increased the ability to learn from the environment like increase our sample",
          "tokens": [
            51158,
            420,
            512,
            661,
            551,
            6505,
            264,
            3485,
            281,
            1466,
            490,
            264,
            2823,
            411,
            3488,
            527,
            6889,
            51498
          ],
          "temperature": 0,
          "avg_logprob": -0.050007164,
          "compression_ratio": 1.6960353,
          "no_speech_prob": 1.2497351e-12
        },
        {
          "id": 428,
          "seek": 55609,
          "start": 2208.152,
          "end": 2213.312,
          "text": " efficiency right instead of having to go and kill the boar yourself and figure out like how to do",
          "tokens": [
            51498,
            10493,
            558,
            2602,
            295,
            1419,
            281,
            352,
            293,
            1961,
            264,
            748,
            289,
            1803,
            293,
            2573,
            484,
            411,
            577,
            281,
            360,
            51756
          ],
          "temperature": 0,
          "avg_logprob": -0.050007164,
          "compression_ratio": 1.6960353,
          "no_speech_prob": 1.2497351e-12
        },
        {
          "id": 429,
          "seek": 58391,
          "start": 2213.312,
          "end": 2218.512,
          "text": " that you can just be like uh the elder told me this how you make a spear and then now it increases",
          "tokens": [
            50365,
            300,
            291,
            393,
            445,
            312,
            411,
            2232,
            264,
            12995,
            1907,
            385,
            341,
            577,
            291,
            652,
            257,
            26993,
            293,
            550,
            586,
            309,
            8637,
            50625
          ],
          "temperature": 0,
          "avg_logprob": -0.04642506,
          "compression_ratio": 1.7655678,
          "no_speech_prob": 2.334724e-12
        },
        {
          "id": 430,
          "seek": 58391,
          "start": 2218.512,
          "end": 2222.512,
          "text": " the incentive to have a bigger cortex which can like learn these things yes and that can be done",
          "tokens": [
            50625,
            264,
            22346,
            281,
            362,
            257,
            3801,
            33312,
            597,
            393,
            411,
            1466,
            613,
            721,
            2086,
            293,
            300,
            393,
            312,
            1096,
            50825
          ],
          "temperature": 0,
          "avg_logprob": -0.04642506,
          "compression_ratio": 1.7655678,
          "no_speech_prob": 2.334724e-12
        },
        {
          "id": 431,
          "seek": 58391,
          "start": 2222.512,
          "end": 2227.212,
          "text": " with a relatively few genes because it's really it's really replicating what the mouse already has",
          "tokens": [
            50825,
            365,
            257,
            7226,
            1326,
            14424,
            570,
            309,
            311,
            534,
            309,
            311,
            534,
            3248,
            30541,
            437,
            264,
            9719,
            1217,
            575,
            51060
          ],
          "temperature": 0,
          "avg_logprob": -0.04642506,
          "compression_ratio": 1.7655678,
          "no_speech_prob": 2.334724e-12
        },
        {
          "id": 432,
          "seek": 58391,
          "start": 2227.212,
          "end": 2232.6921,
          "text": " is making more of it it's maybe not exactly the same and there may be tweaks but it's like from",
          "tokens": [
            51060,
            307,
            1455,
            544,
            295,
            309,
            309,
            311,
            1310,
            406,
            2293,
            264,
            912,
            293,
            456,
            815,
            312,
            46664,
            457,
            309,
            311,
            411,
            490,
            51334
          ],
          "temperature": 0,
          "avg_logprob": -0.04642506,
          "compression_ratio": 1.7655678,
          "no_speech_prob": 2.334724e-12
        },
        {
          "id": 433,
          "seek": 58391,
          "start": 2232.6921,
          "end": 2238.352,
          "text": " a perspective you don't have to reinvent right all this stuff right so then um how far back",
          "tokens": [
            51334,
            257,
            4585,
            291,
            500,
            380,
            362,
            281,
            33477,
            558,
            439,
            341,
            1507,
            558,
            370,
            550,
            1105,
            577,
            1400,
            646,
            51617
          ],
          "temperature": 0,
          "avg_logprob": -0.04642506,
          "compression_ratio": 1.7655678,
          "no_speech_prob": 2.334724e-12
        },
        {
          "id": 434,
          "seek": 60895,
          "start": 2238.352,
          "end": 2244.252,
          "text": " in the history of the evolution of the brain does the cortex go back it is the idea that like",
          "tokens": [
            50365,
            294,
            264,
            2503,
            295,
            264,
            9303,
            295,
            264,
            3567,
            775,
            264,
            33312,
            352,
            646,
            309,
            307,
            264,
            1558,
            300,
            411,
            50660
          ],
          "temperature": 0,
          "avg_logprob": -0.07323114,
          "compression_ratio": 2.0035586,
          "no_speech_prob": 2.1341425e-12
        },
        {
          "id": 435,
          "seek": 60895,
          "start": 2244.252,
          "end": 2248.252,
          "text": " the cortex has always figured out this omnidirectional inference thing that's been",
          "tokens": [
            50660,
            264,
            33312,
            575,
            1009,
            8932,
            484,
            341,
            36874,
            327,
            621,
            41048,
            38253,
            551,
            300,
            311,
            668,
            50860
          ],
          "temperature": 0,
          "avg_logprob": -0.07323114,
          "compression_ratio": 2.0035586,
          "no_speech_prob": 2.1341425e-12
        },
        {
          "id": 436,
          "seek": 60895,
          "start": 2248.252,
          "end": 2252.732,
          "text": " a solve problem for a long time and then the big unlock with primase is this we got the reward",
          "tokens": [
            50860,
            257,
            5039,
            1154,
            337,
            257,
            938,
            565,
            293,
            550,
            264,
            955,
            11634,
            365,
            2886,
            651,
            307,
            341,
            321,
            658,
            264,
            7782,
            51084
          ],
          "temperature": 0,
          "avg_logprob": -0.07323114,
          "compression_ratio": 2.0035586,
          "no_speech_prob": 2.1341425e-12
        },
        {
          "id": 437,
          "seek": 60895,
          "start": 2252.732,
          "end": 2257.892,
          "text": " function which increased the returns to having omnidirectional inference or is this good question",
          "tokens": [
            51084,
            2445,
            597,
            6505,
            264,
            11247,
            281,
            1419,
            36874,
            327,
            621,
            41048,
            38253,
            420,
            307,
            341,
            665,
            1168,
            51342
          ],
          "temperature": 0,
          "avg_logprob": -0.07323114,
          "compression_ratio": 2.0035586,
          "no_speech_prob": 2.1341425e-12
        },
        {
          "id": 438,
          "seek": 60895,
          "start": 2257.892,
          "end": 2261.652,
          "text": " is the cortex is the omnidirectional inference also something that took a while to unlock i'm",
          "tokens": [
            51342,
            307,
            264,
            33312,
            307,
            264,
            36874,
            327,
            621,
            41048,
            38253,
            611,
            746,
            300,
            1890,
            257,
            1339,
            281,
            11634,
            741,
            478,
            51530
          ],
          "temperature": 0,
          "avg_logprob": -0.07323114,
          "compression_ratio": 2.0035586,
          "no_speech_prob": 2.1341425e-12
        },
        {
          "id": 439,
          "seek": 60895,
          "start": 2261.652,
          "end": 2264.872,
          "text": " not sure that there's agreement about that i think there might be specific questions about language",
          "tokens": [
            51530,
            406,
            988,
            300,
            456,
            311,
            8106,
            466,
            300,
            741,
            519,
            456,
            1062,
            312,
            2685,
            1651,
            466,
            2856,
            51691
          ],
          "temperature": 0,
          "avg_logprob": -0.07323114,
          "compression_ratio": 2.0035586,
          "no_speech_prob": 2.1341425e-12
        },
        {
          "id": 440,
          "seek": 63547,
          "start": 2264.872,
          "end": 2269.232,
          "text": " you know are there tweaks to be you know whether that's your auditory and memory some combination",
          "tokens": [
            50365,
            291,
            458,
            366,
            456,
            46664,
            281,
            312,
            291,
            458,
            1968,
            300,
            311,
            428,
            17748,
            827,
            293,
            4675,
            512,
            6562,
            50583
          ],
          "temperature": 0,
          "avg_logprob": -0.06257628,
          "compression_ratio": 1.8779528,
          "no_speech_prob": 1.7829874e-12
        },
        {
          "id": 441,
          "seek": 63547,
          "start": 2269.232,
          "end": 2276.652,
          "text": " auditory memory regions there may also be like um macro wiring right of like you need to wire",
          "tokens": [
            50583,
            17748,
            827,
            4675,
            10682,
            456,
            815,
            611,
            312,
            411,
            1105,
            18887,
            27520,
            558,
            295,
            411,
            291,
            643,
            281,
            6234,
            50954
          ],
          "temperature": 0,
          "avg_logprob": -0.06257628,
          "compression_ratio": 1.8779528,
          "no_speech_prob": 1.7829874e-12
        },
        {
          "id": 442,
          "seek": 63547,
          "start": 2276.652,
          "end": 2281.572,
          "text": " auditory regions into memory regions or something like that and into some of these social instincts",
          "tokens": [
            50954,
            17748,
            827,
            10682,
            666,
            4675,
            10682,
            420,
            746,
            411,
            300,
            293,
            666,
            512,
            295,
            613,
            2093,
            38997,
            51200
          ],
          "temperature": 0,
          "avg_logprob": -0.06257628,
          "compression_ratio": 1.8779528,
          "no_speech_prob": 1.7829874e-12
        },
        {
          "id": 443,
          "seek": 63547,
          "start": 2281.572,
          "end": 2287.012,
          "text": " to get i see language for example to happen so there might be but that might be also a small",
          "tokens": [
            51200,
            281,
            483,
            741,
            536,
            2856,
            337,
            1365,
            281,
            1051,
            370,
            456,
            1062,
            312,
            457,
            300,
            1062,
            312,
            611,
            257,
            1359,
            51472
          ],
          "temperature": 0,
          "avg_logprob": -0.06257628,
          "compression_ratio": 1.8779528,
          "no_speech_prob": 1.7829874e-12
        },
        {
          "id": 444,
          "seek": 63547,
          "start": 2287.012,
          "end": 2291.532,
          "text": " number of gene changes yeah to be able to say oh i just need from my temporal lobe over here",
          "tokens": [
            51472,
            1230,
            295,
            12186,
            2962,
            1338,
            281,
            312,
            1075,
            281,
            584,
            1954,
            741,
            445,
            643,
            490,
            452,
            30881,
            450,
            650,
            670,
            510,
            51698
          ],
          "temperature": 0,
          "avg_logprob": -0.06257628,
          "compression_ratio": 1.8779528,
          "no_speech_prob": 1.7829874e-12
        },
        {
          "id": 445,
          "seek": 66213,
          "start": 2291.532,
          "end": 2295.392,
          "text": " going over to the auditory cortex something right and there is some evidence for the you know the",
          "tokens": [
            50365,
            516,
            670,
            281,
            264,
            17748,
            827,
            33312,
            746,
            558,
            293,
            456,
            307,
            512,
            4467,
            337,
            264,
            291,
            458,
            264,
            50558
          ],
          "temperature": 0,
          "avg_logprob": -0.082584605,
          "compression_ratio": 1.7713178,
          "no_speech_prob": 1.5015827e-12
        },
        {
          "id": 446,
          "seek": 66213,
          "start": 2295.392,
          "end": 2299.612,
          "text": " brocca's area warnicki's area they're connected with these hippocampus and so on and so prefrontal",
          "tokens": [
            50558,
            2006,
            22394,
            311,
            1859,
            12286,
            41356,
            311,
            1859,
            436,
            434,
            4582,
            365,
            613,
            27745,
            905,
            1215,
            301,
            293,
            370,
            322,
            293,
            370,
            659,
            11496,
            304,
            50769
          ],
          "temperature": 0,
          "avg_logprob": -0.082584605,
          "compression_ratio": 1.7713178,
          "no_speech_prob": 1.5015827e-12
        },
        {
          "id": 447,
          "seek": 66213,
          "start": 2299.612,
          "end": 2305.4722,
          "text": " cortex so there's like some small number of genes maybe for like enabling humans to really properly",
          "tokens": [
            50769,
            33312,
            370,
            456,
            311,
            411,
            512,
            1359,
            1230,
            295,
            14424,
            1310,
            337,
            411,
            23148,
            6255,
            281,
            534,
            6108,
            51062
          ],
          "temperature": 0,
          "avg_logprob": -0.082584605,
          "compression_ratio": 1.7713178,
          "no_speech_prob": 1.5015827e-12
        },
        {
          "id": 448,
          "seek": 66213,
          "start": 2305.4722,
          "end": 2310.9321,
          "text": " do language that could be a big one but yeah i mean i think that",
          "tokens": [
            51062,
            360,
            2856,
            300,
            727,
            312,
            257,
            955,
            472,
            457,
            1338,
            741,
            914,
            741,
            519,
            300,
            51335
          ],
          "temperature": 0,
          "avg_logprob": -0.082584605,
          "compression_ratio": 1.7713178,
          "no_speech_prob": 1.5015827e-12
        },
        {
          "id": 449,
          "seek": 66213,
          "start": 2310.9321,
          "end": 2319.792,
          "text": " is it that something changed about the cortex and it became possible to do these things whereas",
          "tokens": [
            51335,
            307,
            309,
            300,
            746,
            3105,
            466,
            264,
            33312,
            293,
            309,
            3062,
            1944,
            281,
            360,
            613,
            721,
            9735,
            51778
          ],
          "temperature": 0,
          "avg_logprob": -0.082584605,
          "compression_ratio": 1.7713178,
          "no_speech_prob": 1.5015827e-12
        },
        {
          "id": 450,
          "seek": 69039,
          "start": 2319.792,
          "end": 2325.232,
          "text": " that potential was already there but there wasn't the incentive to expand that capability and then",
          "tokens": [
            50365,
            300,
            3995,
            390,
            1217,
            456,
            457,
            456,
            2067,
            380,
            264,
            22346,
            281,
            5268,
            300,
            13759,
            293,
            550,
            50637
          ],
          "temperature": 0,
          "avg_logprob": -0.14092685,
          "compression_ratio": 1.7420814,
          "no_speech_prob": 1.2643516e-12
        },
        {
          "id": 451,
          "seek": 69039,
          "start": 2325.232,
          "end": 2330.712,
          "text": " use it wired it to these social instincts and use it more um i mean i would lean somewhat toward the",
          "tokens": [
            50637,
            764,
            309,
            27415,
            309,
            281,
            613,
            2093,
            38997,
            293,
            764,
            309,
            544,
            1105,
            741,
            914,
            741,
            576,
            11659,
            8344,
            7361,
            264,
            50911
          ],
          "temperature": 0,
          "avg_logprob": -0.14092685,
          "compression_ratio": 1.7420814,
          "no_speech_prob": 1.2643516e-12
        },
        {
          "id": 452,
          "seek": 69039,
          "start": 2330.712,
          "end": 2337.292,
          "text": " latter i mean i think a mouse i has a lot of similarity in terms of cortex as a human right",
          "tokens": [
            50911,
            18481,
            741,
            914,
            741,
            519,
            257,
            9719,
            741,
            575,
            257,
            688,
            295,
            32194,
            294,
            2115,
            295,
            33312,
            382,
            257,
            1952,
            558,
            51240
          ],
          "temperature": 0,
          "avg_logprob": -0.14092685,
          "compression_ratio": 1.7420814,
          "no_speech_prob": 1.2643516e-12
        },
        {
          "id": 453,
          "seek": 69039,
          "start": 2337.292,
          "end": 2345.6921,
          "text": " although there's that uh the cesane hercule hussle work yeah the um the the number of neurons",
          "tokens": [
            51240,
            4878,
            456,
            311,
            300,
            2232,
            264,
            7879,
            1929,
            720,
            66,
            2271,
            276,
            2023,
            306,
            589,
            1338,
            264,
            1105,
            264,
            264,
            1230,
            295,
            22027,
            51660
          ],
          "temperature": 0,
          "avg_logprob": -0.14092685,
          "compression_ratio": 1.7420814,
          "no_speech_prob": 1.2643516e-12
        },
        {
          "id": 454,
          "seek": 71629,
          "start": 2345.6921,
          "end": 2351.9321,
          "text": " scales better with weight with primate brains than it does with rodent brains right so yeah",
          "tokens": [
            50365,
            17408,
            1101,
            365,
            3364,
            365,
            2886,
            473,
            15442,
            813,
            309,
            775,
            365,
            8685,
            317,
            15442,
            558,
            370,
            1338,
            50677
          ],
          "temperature": 0,
          "avg_logprob": -0.08553949,
          "compression_ratio": 1.8649789,
          "no_speech_prob": 1.2400128e-12
        },
        {
          "id": 455,
          "seek": 71629,
          "start": 2351.9321,
          "end": 2355.832,
          "text": " does that suggest that there actually was some improvement in the scalability of the cortex",
          "tokens": [
            50677,
            775,
            300,
            3402,
            300,
            456,
            767,
            390,
            512,
            10444,
            294,
            264,
            15664,
            2310,
            295,
            264,
            33312,
            50872
          ],
          "temperature": 0,
          "avg_logprob": -0.08553949,
          "compression_ratio": 1.8649789,
          "no_speech_prob": 1.2400128e-12
        },
        {
          "id": 456,
          "seek": 71629,
          "start": 2355.832,
          "end": 2360.572,
          "text": " maybe maybe i'm not i'm not super deep on this there may there may have been",
          "tokens": [
            50872,
            1310,
            1310,
            741,
            478,
            406,
            741,
            478,
            406,
            1687,
            2452,
            322,
            341,
            456,
            815,
            456,
            815,
            362,
            668,
            51109
          ],
          "temperature": 0,
          "avg_logprob": -0.08553949,
          "compression_ratio": 1.8649789,
          "no_speech_prob": 1.2400128e-12
        },
        {
          "id": 457,
          "seek": 71629,
          "start": 2360.572,
          "end": 2367.032,
          "text": " yeah changes in architecture changes in the folding changes in neuron properties and stuff",
          "tokens": [
            51109,
            1338,
            2962,
            294,
            9482,
            2962,
            294,
            264,
            25335,
            2962,
            294,
            34090,
            7221,
            293,
            1507,
            51432
          ],
          "temperature": 0,
          "avg_logprob": -0.08553949,
          "compression_ratio": 1.8649789,
          "no_speech_prob": 1.2400128e-12
        },
        {
          "id": 458,
          "seek": 71629,
          "start": 2367.032,
          "end": 2371.312,
          "text": " that somehow slightly tweak this but they're still a scaling that's right either way right",
          "tokens": [
            51432,
            300,
            6063,
            4748,
            29879,
            341,
            457,
            436,
            434,
            920,
            257,
            21589,
            300,
            311,
            558,
            2139,
            636,
            558,
            51646
          ],
          "temperature": 0,
          "avg_logprob": -0.08553949,
          "compression_ratio": 1.8649789,
          "no_speech_prob": 1.2400128e-12
        },
        {
          "id": 459,
          "seek": 74191,
          "start": 2371.312,
          "end": 2376.792,
          "text": " um and so i was not saying there aren't something special about humans in the architecture of the",
          "tokens": [
            50365,
            1105,
            293,
            370,
            741,
            390,
            406,
            1566,
            456,
            3212,
            380,
            746,
            2121,
            466,
            6255,
            294,
            264,
            9482,
            295,
            264,
            50639
          ],
          "temperature": 0,
          "avg_logprob": -0.048454836,
          "compression_ratio": 1.823077,
          "no_speech_prob": 1.1925082e-12
        },
        {
          "id": 460,
          "seek": 74191,
          "start": 2376.792,
          "end": 2384.112,
          "text": " learning subsystem at all um but yeah i mean i think it's pretty widely thought that this is",
          "tokens": [
            50639,
            2539,
            2090,
            9321,
            412,
            439,
            1105,
            457,
            1338,
            741,
            914,
            741,
            519,
            309,
            311,
            1238,
            13371,
            1194,
            300,
            341,
            307,
            51005
          ],
          "temperature": 0,
          "avg_logprob": -0.048454836,
          "compression_ratio": 1.823077,
          "no_speech_prob": 1.1925082e-12
        },
        {
          "id": 461,
          "seek": 74191,
          "start": 2384.112,
          "end": 2387.772,
          "text": " expanded but then the question is okay well how does that how does that fit in also with the",
          "tokens": [
            51005,
            14342,
            457,
            550,
            264,
            1168,
            307,
            1392,
            731,
            577,
            775,
            300,
            577,
            775,
            300,
            3318,
            294,
            611,
            365,
            264,
            51188
          ],
          "temperature": 0,
          "avg_logprob": -0.048454836,
          "compression_ratio": 1.823077,
          "no_speech_prob": 1.1925082e-12
        },
        {
          "id": 462,
          "seek": 74191,
          "start": 2387.772,
          "end": 2392.1921,
          "text": " steering subsystem changes and the instincts that make use of this and allow you to bootstrap",
          "tokens": [
            51188,
            14823,
            2090,
            9321,
            2962,
            293,
            264,
            38997,
            300,
            652,
            764,
            295,
            341,
            293,
            2089,
            291,
            281,
            11450,
            372,
            4007,
            51409
          ],
          "temperature": 0,
          "avg_logprob": -0.048454836,
          "compression_ratio": 1.823077,
          "no_speech_prob": 1.1925082e-12
        },
        {
          "id": 463,
          "seek": 74191,
          "start": 2392.1921,
          "end": 2398.672,
          "text": " using this effectively um but i mean just to say a few other things i mean so even the fly brain",
          "tokens": [
            51409,
            1228,
            341,
            8659,
            1105,
            457,
            741,
            914,
            445,
            281,
            584,
            257,
            1326,
            661,
            721,
            741,
            914,
            370,
            754,
            264,
            3603,
            3567,
            51733
          ],
          "temperature": 0,
          "avg_logprob": -0.048454836,
          "compression_ratio": 1.823077,
          "no_speech_prob": 1.1925082e-12
        },
        {
          "id": 464,
          "seek": 76927,
          "start": 2398.672,
          "end": 2402.752,
          "text": " has some amount of, for example, even very far back,",
          "tokens": [
            50365,
            575,
            512,
            2372,
            295,
            11,
            337,
            1365,
            11,
            754,
            588,
            1400,
            646,
            11,
            50569
          ],
          "temperature": 0,
          "avg_logprob": -0.15744787,
          "compression_ratio": 1.717742,
          "no_speech_prob": 1.5430538e-12
        },
        {
          "id": 465,
          "seek": 76927,
          "start": 2403.652,
          "end": 2405.4321,
          "text": " I mean, I think you've read this great book,",
          "tokens": [
            50614,
            286,
            914,
            11,
            286,
            519,
            291,
            600,
            1401,
            341,
            869,
            1446,
            11,
            50703
          ],
          "temperature": 0,
          "avg_logprob": -0.15744787,
          "compression_ratio": 1.717742,
          "no_speech_prob": 1.5430538e-12
        },
        {
          "id": 466,
          "seek": 76927,
          "start": 2405.532,
          "end": 2406.832,
          "text": " The Brief History of Intelligence, right?",
          "tokens": [
            50708,
            440,
            39805,
            12486,
            295,
            27274,
            11,
            558,
            30,
            50773
          ],
          "temperature": 0,
          "avg_logprob": -0.15744787,
          "compression_ratio": 1.717742,
          "no_speech_prob": 1.5430538e-12
        },
        {
          "id": 467,
          "seek": 76927,
          "start": 2406.852,
          "end": 2407.792,
          "text": " I think this is a really good book.",
          "tokens": [
            50774,
            286,
            519,
            341,
            307,
            257,
            534,
            665,
            1446,
            13,
            50821
          ],
          "temperature": 0,
          "avg_logprob": -0.15744787,
          "compression_ratio": 1.717742,
          "no_speech_prob": 1.5430538e-12
        },
        {
          "id": 468,
          "seek": 76927,
          "start": 2408.132,
          "end": 2409.9722,
          "text": " Lots of AI researchers think this is a really good book,",
          "tokens": [
            50838,
            15908,
            295,
            7318,
            10309,
            519,
            341,
            307,
            257,
            534,
            665,
            1446,
            11,
            50930
          ],
          "temperature": 0,
          "avg_logprob": -0.15744787,
          "compression_ratio": 1.717742,
          "no_speech_prob": 1.5430538e-12
        },
        {
          "id": 469,
          "seek": 76927,
          "start": 2410.012,
          "end": 2410.4321,
          "text": " it seems like.",
          "tokens": [
            50932,
            309,
            2544,
            411,
            13,
            50953
          ],
          "temperature": 0,
          "avg_logprob": -0.15744787,
          "compression_ratio": 1.717742,
          "no_speech_prob": 1.5430538e-12
        },
        {
          "id": 470,
          "seek": 76927,
          "start": 2412.712,
          "end": 2414.772,
          "text": " Yeah, you have some amount of learning",
          "tokens": [
            51067,
            865,
            11,
            291,
            362,
            512,
            2372,
            295,
            2539,
            51170
          ],
          "temperature": 0,
          "avg_logprob": -0.15744787,
          "compression_ratio": 1.717742,
          "no_speech_prob": 1.5430538e-12
        },
        {
          "id": 471,
          "seek": 76927,
          "start": 2414.772,
          "end": 2420.332,
          "text": " going back all the way to anything that has a brain, basically.",
          "tokens": [
            51170,
            516,
            646,
            439,
            264,
            636,
            281,
            1340,
            300,
            575,
            257,
            3567,
            11,
            1936,
            13,
            51448
          ],
          "temperature": 0,
          "avg_logprob": -0.15744787,
          "compression_ratio": 1.717742,
          "no_speech_prob": 1.5430538e-12
        },
        {
          "id": 472,
          "seek": 76927,
          "start": 2421.612,
          "end": 2424.392,
          "text": " You have something kind of like",
          "tokens": [
            51512,
            509,
            362,
            746,
            733,
            295,
            411,
            51651
          ],
          "temperature": 0,
          "avg_logprob": -0.15744787,
          "compression_ratio": 1.717742,
          "no_speech_prob": 1.5430538e-12
        },
        {
          "id": 473,
          "seek": 76927,
          "start": 2424.392,
          "end": 2426.9321,
          "text": " primitive reinforcement learning, at least,",
          "tokens": [
            51651,
            28540,
            29280,
            2539,
            11,
            412,
            1935,
            11,
            51778
          ],
          "temperature": 0,
          "avg_logprob": -0.15744787,
          "compression_ratio": 1.717742,
          "no_speech_prob": 1.5430538e-12
        },
        {
          "id": 474,
          "seek": 79753,
          "start": 2426.9321,
          "end": 2432.512,
          "text": " um going back at least to like vertebrates like imagine like a zebrafish it's like a",
          "tokens": [
            50365,
            1105,
            516,
            646,
            412,
            1935,
            281,
            411,
            16167,
            1443,
            1024,
            411,
            3811,
            411,
            257,
            47060,
            11608,
            309,
            311,
            411,
            257,
            50644
          ],
          "temperature": 0,
          "avg_logprob": -0.07924835,
          "compression_ratio": 1.872,
          "no_speech_prob": 1.1878598e-12
        },
        {
          "id": 475,
          "seek": 79753,
          "start": 2432.512,
          "end": 2439.832,
          "text": " um these kind of these other branches birds maybe kind of reinvented something kind of cortex-like",
          "tokens": [
            50644,
            1105,
            613,
            733,
            295,
            613,
            661,
            14770,
            9009,
            1310,
            733,
            295,
            33477,
            292,
            746,
            733,
            295,
            33312,
            12,
            4092,
            51010
          ],
          "temperature": 0,
          "avg_logprob": -0.07924835,
          "compression_ratio": 1.872,
          "no_speech_prob": 1.1878598e-12
        },
        {
          "id": 476,
          "seek": 79753,
          "start": 2439.832,
          "end": 2444.312,
          "text": " but it doesn't have the six layers but they have something a little bit cortex-like um so that",
          "tokens": [
            51010,
            457,
            309,
            1177,
            380,
            362,
            264,
            2309,
            7914,
            457,
            436,
            362,
            746,
            257,
            707,
            857,
            33312,
            12,
            4092,
            1105,
            370,
            300,
            51234
          ],
          "temperature": 0,
          "avg_logprob": -0.07924835,
          "compression_ratio": 1.872,
          "no_speech_prob": 1.1878598e-12
        },
        {
          "id": 477,
          "seek": 79753,
          "start": 2444.312,
          "end": 2449.9922,
          "text": " some of those things um after reptiles in some sense birds and mammals both kind of made us up",
          "tokens": [
            51234,
            512,
            295,
            729,
            721,
            1105,
            934,
            29143,
            4680,
            294,
            512,
            2020,
            9009,
            293,
            35408,
            1293,
            733,
            295,
            1027,
            505,
            493,
            51518
          ],
          "temperature": 0,
          "avg_logprob": -0.07924835,
          "compression_ratio": 1.872,
          "no_speech_prob": 1.1878598e-12
        },
        {
          "id": 478,
          "seek": 79753,
          "start": 2449.9922,
          "end": 2454.9722,
          "text": " somewhat cortex-like but differently organized thing but even a fly brain has like associative",
          "tokens": [
            51518,
            8344,
            33312,
            12,
            4092,
            457,
            7614,
            9983,
            551,
            457,
            754,
            257,
            3603,
            3567,
            575,
            411,
            4180,
            1166,
            51767
          ],
          "temperature": 0,
          "avg_logprob": -0.07924835,
          "compression_ratio": 1.872,
          "no_speech_prob": 1.1878598e-12
        },
        {
          "id": 479,
          "seek": 82557,
          "start": 2454.9722,
          "end": 2460.312,
          "text": " learning senders that actually do things that maybe look a little bit like this like thought",
          "tokens": [
            50365,
            2539,
            2845,
            433,
            300,
            767,
            360,
            721,
            300,
            1310,
            574,
            257,
            707,
            857,
            411,
            341,
            411,
            1194,
            50632
          ],
          "temperature": 0,
          "avg_logprob": -0.11964153,
          "compression_ratio": 1.7590362,
          "no_speech_prob": 1.2448619e-12
        },
        {
          "id": 480,
          "seek": 82557,
          "start": 2460.312,
          "end": 2464.172,
          "text": " assessor concept from from berns where there's like a specific dopamine signal to train specific",
          "tokens": [
            50632,
            5877,
            284,
            3410,
            490,
            490,
            272,
            1248,
            82,
            689,
            456,
            311,
            411,
            257,
            2685,
            37219,
            6358,
            281,
            3847,
            2685,
            50825
          ],
          "temperature": 0,
          "avg_logprob": -0.11964153,
          "compression_ratio": 1.7590362,
          "no_speech_prob": 1.2448619e-12
        },
        {
          "id": 481,
          "seek": 82557,
          "start": 2464.172,
          "end": 2470.372,
          "text": " subgroups of neurons in the fly mushroom body to associate different sensory information with",
          "tokens": [
            50825,
            1422,
            17377,
            82,
            295,
            22027,
            294,
            264,
            3603,
            12094,
            1772,
            281,
            14644,
            819,
            27233,
            1589,
            365,
            51135
          ],
          "temperature": 0,
          "avg_logprob": -0.11964153,
          "compression_ratio": 1.7590362,
          "no_speech_prob": 1.2448619e-12
        },
        {
          "id": 482,
          "seek": 2471,
          "start": 2470.372,
          "end": 2485.0781,
          "text": " am i going to get food now or am i going to get hurt now yeah tangent I remember reading in one blog post that Baron Millage wrote that the parts of the cortex",
          "tokens": [
            51135,
            669,
            741,
            516,
            281,
            483,
            1755,
            586,
            420,
            669,
            741,
            516,
            281,
            483,
            4607,
            586,
            1338,
            1338,
            5353,
            39805,
            27747,
            13,
            50588,
            50623,
            286,
            1604,
            3760,
            294,
            472,
            6968,
            2183,
            300,
            30978,
            7190,
            609,
            4114,
            300,
            264,
            3166,
            295,
            264,
            33312,
            11,
            51055
          ],
          "temperature": 0,
          "avg_logprob": -0.23654921,
          "compression_ratio": 1.6,
          "no_speech_prob": 1.0401543e-12
        },
        {
          "id": 483,
          "seek": 2471,
          "start": 2485.0781,
          "end": 2492.758,
          "text": " which are associated with audio and vision, have scaled disproportionately between other primates and humans,",
          "tokens": [
            51055,
            597,
            366,
            6615,
            365,
            6278,
            293,
            5201,
            11,
            362,
            36039,
            43397,
            1296,
            661,
            2886,
            1024,
            293,
            6255,
            11,
            51439
          ],
          "temperature": 0,
          "avg_logprob": -0.23654921,
          "compression_ratio": 1.6,
          "no_speech_prob": 1.0401543e-12
        },
        {
          "id": 484,
          "seek": 2471,
          "start": 2493.218,
          "end": 2496.218,
          "text": " whereas the parts associated, say, with odor have not.",
          "tokens": [
            51462,
            9735,
            264,
            3166,
            6615,
            11,
            584,
            11,
            365,
            41176,
            362,
            406,
            13,
            51612
          ],
          "temperature": 0,
          "avg_logprob": -0.23654921,
          "compression_ratio": 1.6,
          "no_speech_prob": 1.0401543e-12
        },
        {
          "id": 485,
          "seek": 4965,
          "start": 2496.218,
          "end": 2505.6182,
          "text": " And I remember him saying something like, this is explained by that kind of data having worse scaling law properties.",
          "tokens": [
            50365,
            400,
            286,
            1604,
            796,
            1566,
            746,
            411,
            11,
            341,
            307,
            8825,
            538,
            300,
            733,
            295,
            1412,
            1419,
            5324,
            21589,
            2101,
            7221,
            13,
            50835
          ],
          "temperature": 0,
          "avg_logprob": -0.12849759,
          "compression_ratio": 1.6293436,
          "no_speech_prob": 1.0942083e-12
        },
        {
          "id": 486,
          "seek": 4965,
          "start": 2506.158,
          "end": 2518.538,
          "text": " But I think the and maybe he meant this, but another interpretation of actually what's happening there is that these social reward functions that are built into the steering subsystem needed to make use.",
          "tokens": [
            50862,
            583,
            286,
            519,
            264,
            293,
            1310,
            415,
            4140,
            341,
            11,
            457,
            1071,
            14174,
            295,
            767,
            437,
            311,
            2737,
            456,
            307,
            300,
            613,
            2093,
            7782,
            6828,
            300,
            366,
            3094,
            666,
            264,
            14823,
            2090,
            9321,
            2978,
            281,
            652,
            764,
            13,
            51481
          ],
          "temperature": 0,
          "avg_logprob": -0.12849759,
          "compression_ratio": 1.6293436,
          "no_speech_prob": 1.0942083e-12
        },
        {
          "id": 487,
          "seek": 4965,
          "start": 2520.1182,
          "end": 2524.998,
          "text": " More of being able to see your elders and see what the visual cues are and hear what they're saying.",
          "tokens": [
            51560,
            5048,
            295,
            885,
            1075,
            281,
            536,
            428,
            22737,
            293,
            536,
            437,
            264,
            5056,
            32192,
            366,
            293,
            1568,
            437,
            436,
            434,
            1566,
            13,
            51804
          ],
          "temperature": 0,
          "avg_logprob": -0.12849759,
          "compression_ratio": 1.6293436,
          "no_speech_prob": 1.0942083e-12
        },
        {
          "id": 488,
          "seek": 7843,
          "start": 2524.998,
          "end": 2531.218,
          "text": " yeah in order to make a sense of these cues which guide learning you needed to activate these um",
          "tokens": [
            50365,
            1338,
            294,
            1668,
            281,
            652,
            257,
            2020,
            295,
            613,
            32192,
            597,
            5934,
            2539,
            291,
            2978,
            281,
            13615,
            613,
            1105,
            50676
          ],
          "temperature": 0,
          "avg_logprob": -0.04135774,
          "compression_ratio": 1.8022388,
          "no_speech_prob": 1.6299469e-12
        },
        {
          "id": 489,
          "seek": 7843,
          "start": 2531.218,
          "end": 2535.998,
          "text": " yeah activate the vision and audio more than i mean there's all this stuff i feel like it's come",
          "tokens": [
            50676,
            1338,
            13615,
            264,
            5201,
            293,
            6278,
            544,
            813,
            741,
            914,
            456,
            311,
            439,
            341,
            1507,
            741,
            841,
            411,
            309,
            311,
            808,
            50915
          ],
          "temperature": 0,
          "avg_logprob": -0.04135774,
          "compression_ratio": 1.8022388,
          "no_speech_prob": 1.6299469e-12
        },
        {
          "id": 490,
          "seek": 7843,
          "start": 2535.998,
          "end": 2542.178,
          "text": " up in in your your shows before actually but like even like the design of the human eye where you",
          "tokens": [
            50915,
            493,
            294,
            294,
            428,
            428,
            3110,
            949,
            767,
            457,
            411,
            754,
            411,
            264,
            1715,
            295,
            264,
            1952,
            3313,
            689,
            291,
            51224
          ],
          "temperature": 0,
          "avg_logprob": -0.04135774,
          "compression_ratio": 1.8022388,
          "no_speech_prob": 1.6299469e-12
        },
        {
          "id": 491,
          "seek": 7843,
          "start": 2542.178,
          "end": 2546.058,
          "text": " have like the pupil and the white and everything like we are designed to be able to establish",
          "tokens": [
            51224,
            362,
            411,
            264,
            44533,
            293,
            264,
            2418,
            293,
            1203,
            411,
            321,
            366,
            4761,
            281,
            312,
            1075,
            281,
            8327,
            51418
          ],
          "temperature": 0,
          "avg_logprob": -0.04135774,
          "compression_ratio": 1.8022388,
          "no_speech_prob": 1.6299469e-12
        },
        {
          "id": 492,
          "seek": 7843,
          "start": 2546.058,
          "end": 2550.198,
          "text": " relationships based on joint eye contact and and maybe this came up in the sudden episode i can't",
          "tokens": [
            51418,
            6159,
            2361,
            322,
            7225,
            3313,
            3385,
            293,
            293,
            1310,
            341,
            1361,
            493,
            294,
            264,
            3990,
            3500,
            741,
            393,
            380,
            51625
          ],
          "temperature": 0,
          "avg_logprob": -0.04135774,
          "compression_ratio": 1.8022388,
          "no_speech_prob": 1.6299469e-12
        },
        {
          "id": 493,
          "seek": 10363,
          "start": 2550.198,
          "end": 2555.678,
          "text": " remember. But yeah, we have to bootstrap to the point where we can detect eye contact and where",
          "tokens": [
            50365,
            1604,
            13,
            583,
            1338,
            11,
            321,
            362,
            281,
            11450,
            372,
            4007,
            281,
            264,
            935,
            689,
            321,
            393,
            5531,
            3313,
            3385,
            293,
            689,
            50639
          ],
          "temperature": 0,
          "avg_logprob": -0.13047561,
          "compression_ratio": 1.6080586,
          "no_speech_prob": 2.0438553e-12
        },
        {
          "id": 494,
          "seek": 10363,
          "start": 2555.678,
          "end": 2561.798,
          "text": " we can communicate by language. And that's what the first couple of years of life are trying to do.",
          "tokens": [
            50639,
            321,
            393,
            7890,
            538,
            2856,
            13,
            400,
            300,
            311,
            437,
            264,
            700,
            1916,
            295,
            924,
            295,
            993,
            366,
            1382,
            281,
            360,
            13,
            50945
          ],
          "temperature": 0,
          "avg_logprob": -0.13047561,
          "compression_ratio": 1.6080586,
          "no_speech_prob": 2.0438553e-12
        },
        {
          "id": 495,
          "seek": 10363,
          "start": 2562.178,
          "end": 2567.158,
          "text": " Okay. I want to ask you about RL. So currently the way these LNs are trained,",
          "tokens": [
            50964,
            1033,
            13,
            286,
            528,
            281,
            1029,
            291,
            466,
            497,
            43,
            13,
            407,
            4362,
            264,
            636,
            613,
            441,
            45,
            82,
            366,
            8895,
            11,
            51213
          ],
          "temperature": 0,
          "avg_logprob": -0.13047561,
          "compression_ratio": 1.6080586,
          "no_speech_prob": 2.0438553e-12
        },
        {
          "id": 496,
          "seek": 10363,
          "start": 2567.478,
          "end": 2573.498,
          "text": " if they solve the unit test or solve a math problem, that whole trajectory,",
          "tokens": [
            51229,
            498,
            436,
            5039,
            264,
            4985,
            1500,
            420,
            5039,
            257,
            5221,
            1154,
            11,
            300,
            1379,
            21512,
            11,
            51530
          ],
          "temperature": 0,
          "avg_logprob": -0.13047561,
          "compression_ratio": 1.6080586,
          "no_speech_prob": 2.0438553e-12
        },
        {
          "id": 497,
          "seek": 10363,
          "start": 2573.8582,
          "end": 2578.478,
          "text": " every token in that trajectory is up-weighted. And what's going on with humans? Are there",
          "tokens": [
            51548,
            633,
            14862,
            294,
            300,
            21512,
            307,
            493,
            12,
            12329,
            292,
            13,
            400,
            437,
            311,
            516,
            322,
            365,
            6255,
            30,
            2014,
            456,
            51779
          ],
          "temperature": 0,
          "avg_logprob": -0.13047561,
          "compression_ratio": 1.6080586,
          "no_speech_prob": 2.0438553e-12
        },
        {
          "id": 498,
          "seek": 13191,
          "start": 2578.478,
          "end": 2581.658,
          "text": " different types of model based versus model free that are happening in different parts of the brain",
          "tokens": [
            50365,
            819,
            3467,
            295,
            2316,
            2361,
            5717,
            2316,
            1737,
            300,
            366,
            2737,
            294,
            819,
            3166,
            295,
            264,
            3567,
            50524
          ],
          "temperature": 0,
          "avg_logprob": -0.059955418,
          "compression_ratio": 1.91,
          "no_speech_prob": 3.5461237e-12
        },
        {
          "id": 499,
          "seek": 13191,
          "start": 2581.658,
          "end": 2585.458,
          "text": " yeah i mean this is this is another one of these things i mean again all my answers to these",
          "tokens": [
            50524,
            1338,
            741,
            914,
            341,
            307,
            341,
            307,
            1071,
            472,
            295,
            613,
            721,
            741,
            914,
            797,
            439,
            452,
            6338,
            281,
            613,
            50714
          ],
          "temperature": 0,
          "avg_logprob": -0.059955418,
          "compression_ratio": 1.91,
          "no_speech_prob": 3.5461237e-12
        },
        {
          "id": 500,
          "seek": 13191,
          "start": 2585.458,
          "end": 2589.678,
          "text": " questions any specific thing i say is all just kind of like directionally this we can kind of",
          "tokens": [
            50714,
            1651,
            604,
            2685,
            551,
            741,
            584,
            307,
            439,
            445,
            733,
            295,
            411,
            3513,
            379,
            341,
            321,
            393,
            733,
            295,
            50925
          ],
          "temperature": 0,
          "avg_logprob": -0.059955418,
          "compression_ratio": 1.91,
          "no_speech_prob": 3.5461237e-12
        },
        {
          "id": 501,
          "seek": 13191,
          "start": 2589.678,
          "end": 2593.8582,
          "text": " explore around this i find this interesting maybe i feel like the literature points in these",
          "tokens": [
            50925,
            6839,
            926,
            341,
            741,
            915,
            341,
            1880,
            1310,
            741,
            841,
            411,
            264,
            10394,
            2793,
            294,
            613,
            51134
          ],
          "temperature": 0,
          "avg_logprob": -0.059955418,
          "compression_ratio": 1.91,
          "no_speech_prob": 3.5461237e-12
        },
        {
          "id": 502,
          "seek": 13191,
          "start": 2593.8582,
          "end": 2597.918,
          "text": " directions in some very broad way what i actually want to do is like go and map the entire mouse",
          "tokens": [
            51134,
            11095,
            294,
            512,
            588,
            4152,
            636,
            437,
            741,
            767,
            528,
            281,
            360,
            307,
            411,
            352,
            293,
            4471,
            264,
            2302,
            9719,
            51337
          ],
          "temperature": 0,
          "avg_logprob": -0.059955418,
          "compression_ratio": 1.91,
          "no_speech_prob": 3.5461237e-12
        },
        {
          "id": 503,
          "seek": 13191,
          "start": 2597.918,
          "end": 2602.278,
          "text": " brain and like figure this out comprehensively and like make neuroscience a ground truth science",
          "tokens": [
            51337,
            3567,
            293,
            411,
            2573,
            341,
            484,
            13914,
            356,
            293,
            411,
            652,
            42762,
            257,
            2727,
            3494,
            3497,
            51555
          ],
          "temperature": 0,
          "avg_logprob": -0.059955418,
          "compression_ratio": 1.91,
          "no_speech_prob": 3.5461237e-12
        },
        {
          "id": 504,
          "seek": 15571,
          "start": 2602.278,
          "end": 2608.8782,
          "text": " so i don't know basically um but uh but yeah i mean there so first of all i mean i think with",
          "tokens": [
            50365,
            370,
            741,
            500,
            380,
            458,
            1936,
            1105,
            457,
            2232,
            457,
            1338,
            741,
            914,
            456,
            370,
            700,
            295,
            439,
            741,
            914,
            741,
            519,
            365,
            50695
          ],
          "temperature": 0,
          "avg_logprob": -0.04070689,
          "compression_ratio": 1.8903655,
          "no_speech_prob": 1.6045272e-12
        },
        {
          "id": 505,
          "seek": 15571,
          "start": 2608.8782,
          "end": 2613.5781,
          "text": " ilia on the podcast i mean he was like it's weird that you don't use value functions right you use",
          "tokens": [
            50695,
            1930,
            654,
            322,
            264,
            7367,
            741,
            914,
            415,
            390,
            411,
            309,
            311,
            3657,
            300,
            291,
            500,
            380,
            764,
            2158,
            6828,
            558,
            291,
            764,
            50930
          ],
          "temperature": 0,
          "avg_logprob": -0.04070689,
          "compression_ratio": 1.8903655,
          "no_speech_prob": 1.6045272e-12
        },
        {
          "id": 506,
          "seek": 15571,
          "start": 2613.5781,
          "end": 2618.0981,
          "text": " like the most dumbest form of rl basically and of course there are these people are incredibly",
          "tokens": [
            50930,
            411,
            264,
            881,
            10316,
            377,
            1254,
            295,
            367,
            75,
            1936,
            293,
            295,
            1164,
            456,
            366,
            613,
            561,
            366,
            6252,
            51156
          ],
          "temperature": 0,
          "avg_logprob": -0.04070689,
          "compression_ratio": 1.8903655,
          "no_speech_prob": 1.6045272e-12
        },
        {
          "id": 507,
          "seek": 15571,
          "start": 2618.0981,
          "end": 2621.938,
          "text": " smart and they're optimizing for how to do it on gpus and it's really incredible what they're",
          "tokens": [
            51156,
            4069,
            293,
            436,
            434,
            40425,
            337,
            577,
            281,
            360,
            309,
            322,
            290,
            31624,
            293,
            309,
            311,
            534,
            4651,
            437,
            436,
            434,
            51348
          ],
          "temperature": 0,
          "avg_logprob": -0.04070689,
          "compression_ratio": 1.8903655,
          "no_speech_prob": 1.6045272e-12
        },
        {
          "id": 508,
          "seek": 15571,
          "start": 2621.938,
          "end": 2625.5781,
          "text": " achieving but like conceptually it's a really dumb form of rl even compared to like what was",
          "tokens": [
            51348,
            19626,
            457,
            411,
            3410,
            671,
            309,
            311,
            257,
            534,
            10316,
            1254,
            295,
            367,
            75,
            754,
            5347,
            281,
            411,
            437,
            390,
            51530
          ],
          "temperature": 0,
          "avg_logprob": -0.04070689,
          "compression_ratio": 1.8903655,
          "no_speech_prob": 1.6045272e-12
        },
        {
          "id": 509,
          "seek": 15571,
          "start": 2625.5781,
          "end": 2631.5981,
          "text": " being done in like 10 years ago right like even uh you know the atari game playing stuff right",
          "tokens": [
            51530,
            885,
            1096,
            294,
            411,
            1266,
            924,
            2057,
            558,
            411,
            754,
            2232,
            291,
            458,
            264,
            412,
            3504,
            1216,
            2433,
            1507,
            558,
            51831
          ],
          "temperature": 0,
          "avg_logprob": -0.04070689,
          "compression_ratio": 1.8903655,
          "no_speech_prob": 1.6045272e-12
        },
        {
          "id": 510,
          "seek": 18503,
          "start": 2631.5981,
          "end": 2636.418,
          "text": " was using like q learning which is basically like it's a kind of temporal difference learning right",
          "tokens": [
            50365,
            390,
            1228,
            411,
            9505,
            2539,
            597,
            307,
            1936,
            411,
            309,
            311,
            257,
            733,
            295,
            30881,
            2649,
            2539,
            558,
            50606
          ],
          "temperature": 0,
          "avg_logprob": -0.06033955,
          "compression_ratio": 1.9251969,
          "no_speech_prob": 1.6234399e-12
        },
        {
          "id": 511,
          "seek": 18503,
          "start": 2636.418,
          "end": 2640.8381,
          "text": " and the temporal difference learning basically means you have some kind of a value function of",
          "tokens": [
            50606,
            293,
            264,
            30881,
            2649,
            2539,
            1936,
            1355,
            291,
            362,
            512,
            733,
            295,
            257,
            2158,
            2445,
            295,
            50827
          ],
          "temperature": 0,
          "avg_logprob": -0.06033955,
          "compression_ratio": 1.9251969,
          "no_speech_prob": 1.6234399e-12
        },
        {
          "id": 512,
          "seek": 18503,
          "start": 2640.8381,
          "end": 2646.3782,
          "text": " like what action i choose now doesn't just tell me literally what happens immediately after this",
          "tokens": [
            50827,
            411,
            437,
            3069,
            741,
            2826,
            586,
            1177,
            380,
            445,
            980,
            385,
            3736,
            437,
            2314,
            4258,
            934,
            341,
            51104
          ],
          "temperature": 0,
          "avg_logprob": -0.06033955,
          "compression_ratio": 1.9251969,
          "no_speech_prob": 1.6234399e-12
        },
        {
          "id": 513,
          "seek": 18503,
          "start": 2646.3782,
          "end": 2650.958,
          "text": " it tells me like what is the long-run consequence of that for my expected you know total reward or",
          "tokens": [
            51104,
            309,
            5112,
            385,
            411,
            437,
            307,
            264,
            938,
            12,
            12997,
            18326,
            295,
            300,
            337,
            452,
            5176,
            291,
            458,
            3217,
            7782,
            420,
            51333
          ],
          "temperature": 0,
          "avg_logprob": -0.06033955,
          "compression_ratio": 1.9251969,
          "no_speech_prob": 1.6234399e-12
        },
        {
          "id": 514,
          "seek": 18503,
          "start": 2650.958,
          "end": 2657.698,
          "text": " something like that um and so you would have value functions like the fact that we don't have like",
          "tokens": [
            51333,
            746,
            411,
            300,
            1105,
            293,
            370,
            291,
            576,
            362,
            2158,
            6828,
            411,
            264,
            1186,
            300,
            321,
            500,
            380,
            362,
            411,
            51670
          ],
          "temperature": 0,
          "avg_logprob": -0.06033955,
          "compression_ratio": 1.9251969,
          "no_speech_prob": 1.6234399e-12
        },
        {
          "id": 515,
          "seek": 21113,
          "start": 2657.698,
          "end": 2663.8582,
          "text": " value functions at all is like in the llms is like it's crazy i mean i think i think because",
          "tokens": [
            50365,
            2158,
            6828,
            412,
            439,
            307,
            411,
            294,
            264,
            4849,
            2592,
            307,
            411,
            309,
            311,
            3219,
            741,
            914,
            741,
            519,
            741,
            519,
            570,
            50673
          ],
          "temperature": 0,
          "avg_logprob": -0.06304193,
          "compression_ratio": 1.8,
          "no_speech_prob": 1.44392e-12
        },
        {
          "id": 516,
          "seek": 21113,
          "start": 2663.8582,
          "end": 2668.8582,
          "text": " ilia said it i can say it i know you know one one hundredth of what he does about ai but like",
          "tokens": [
            50673,
            1930,
            654,
            848,
            309,
            741,
            393,
            584,
            309,
            741,
            458,
            291,
            458,
            472,
            472,
            3262,
            392,
            295,
            437,
            415,
            775,
            466,
            9783,
            457,
            411,
            50923
          ],
          "temperature": 0,
          "avg_logprob": -0.06304193,
          "compression_ratio": 1.8,
          "no_speech_prob": 1.44392e-12
        },
        {
          "id": 517,
          "seek": 21113,
          "start": 2668.8582,
          "end": 2678.3582,
          "text": " it's kind of crazy that this is working yeah um but uh yeah i mean in terms of the brain um",
          "tokens": [
            50923,
            309,
            311,
            733,
            295,
            3219,
            300,
            341,
            307,
            1364,
            1338,
            1105,
            457,
            2232,
            1338,
            741,
            914,
            294,
            2115,
            295,
            264,
            3567,
            1105,
            51398
          ],
          "temperature": 0,
          "avg_logprob": -0.06304193,
          "compression_ratio": 1.8,
          "no_speech_prob": 1.44392e-12
        },
        {
          "id": 518,
          "seek": 21113,
          "start": 2678.3582,
          "end": 2686.198,
          "text": " well so i think there are some parts of the brain that are thought to do something that's very much",
          "tokens": [
            51398,
            731,
            370,
            741,
            519,
            456,
            366,
            512,
            3166,
            295,
            264,
            3567,
            300,
            366,
            1194,
            281,
            360,
            746,
            300,
            311,
            588,
            709,
            51790
          ],
          "temperature": 0,
          "avg_logprob": -0.06304193,
          "compression_ratio": 1.8,
          "no_speech_prob": 1.44392e-12
        },
        {
          "id": 519,
          "seek": 23963,
          "start": 2686.198,
          "end": 2691.778,
          "text": " like model free rl that's or parts of the basal ganglia um sort of striatum and basal ganglia",
          "tokens": [
            50365,
            411,
            2316,
            1737,
            367,
            75,
            300,
            311,
            420,
            3166,
            295,
            264,
            987,
            304,
            10145,
            14218,
            1105,
            1333,
            295,
            3575,
            267,
            449,
            293,
            987,
            304,
            10145,
            14218,
            50644
          ],
          "temperature": 0,
          "avg_logprob": -0.07975177,
          "compression_ratio": 1.987069,
          "no_speech_prob": 1.1925411e-12
        },
        {
          "id": 520,
          "seek": 23963,
          "start": 2691.778,
          "end": 2697.1582,
          "text": " they have like a certain finite like it is thought that they have a certain like finite relatively",
          "tokens": [
            50644,
            436,
            362,
            411,
            257,
            1629,
            19362,
            411,
            309,
            307,
            1194,
            300,
            436,
            362,
            257,
            1629,
            411,
            19362,
            7226,
            50913
          ],
          "temperature": 0,
          "avg_logprob": -0.07975177,
          "compression_ratio": 1.987069,
          "no_speech_prob": 1.1925411e-12
        },
        {
          "id": 521,
          "seek": 23963,
          "start": 2697.1582,
          "end": 2701.258,
          "text": " small action space and the types of actions they could take first of all might be like",
          "tokens": [
            50913,
            1359,
            3069,
            1901,
            293,
            264,
            3467,
            295,
            5909,
            436,
            727,
            747,
            700,
            295,
            439,
            1062,
            312,
            411,
            51118
          ],
          "temperature": 0,
          "avg_logprob": -0.07975177,
          "compression_ratio": 1.987069,
          "no_speech_prob": 1.1925411e-12
        },
        {
          "id": 522,
          "seek": 23963,
          "start": 2701.258,
          "end": 2705.958,
          "text": " tell the spinal cord or tell the brainstem and spinal cord to do this motor action yes no",
          "tokens": [
            51118,
            980,
            264,
            28022,
            12250,
            420,
            980,
            264,
            3567,
            1099,
            293,
            28022,
            12250,
            281,
            360,
            341,
            5932,
            3069,
            2086,
            572,
            51353
          ],
          "temperature": 0,
          "avg_logprob": -0.07975177,
          "compression_ratio": 1.987069,
          "no_speech_prob": 1.1925411e-12
        },
        {
          "id": 523,
          "seek": 23963,
          "start": 2705.958,
          "end": 2712.3381,
          "text": " or it might be more complicated cognitive type actions like tell the thalamus to allow this",
          "tokens": [
            51353,
            420,
            309,
            1062,
            312,
            544,
            6179,
            15605,
            2010,
            5909,
            411,
            980,
            264,
            258,
            23819,
            301,
            281,
            2089,
            341,
            51672
          ],
          "temperature": 0,
          "avg_logprob": -0.07975177,
          "compression_ratio": 1.987069,
          "no_speech_prob": 1.1925411e-12
        },
        {
          "id": 524,
          "seek": 26577,
          "start": 2712.3381,
          "end": 2717.0981,
          "text": " part of the cortex to talk to this other part or release the memory that's in the hippocampus and",
          "tokens": [
            50365,
            644,
            295,
            264,
            33312,
            281,
            751,
            281,
            341,
            661,
            644,
            420,
            4374,
            264,
            4675,
            300,
            311,
            294,
            264,
            27745,
            905,
            1215,
            301,
            293,
            50603
          ],
          "temperature": 0,
          "avg_logprob": -0.032489,
          "compression_ratio": 1.8339623,
          "no_speech_prob": 1.5859789e-12
        },
        {
          "id": 525,
          "seek": 26577,
          "start": 2717.0981,
          "end": 2722.178,
          "text": " start a new one or something right but there's some finite set of actions that kind of come out",
          "tokens": [
            50603,
            722,
            257,
            777,
            472,
            420,
            746,
            558,
            457,
            456,
            311,
            512,
            19362,
            992,
            295,
            5909,
            300,
            733,
            295,
            808,
            484,
            50857
          ],
          "temperature": 0,
          "avg_logprob": -0.032489,
          "compression_ratio": 1.8339623,
          "no_speech_prob": 1.5859789e-12
        },
        {
          "id": 526,
          "seek": 26577,
          "start": 2722.178,
          "end": 2727.8582,
          "text": " of the basal ganglia and that it's just a very simple rl so there are probably parts of other",
          "tokens": [
            50857,
            295,
            264,
            987,
            304,
            10145,
            14218,
            293,
            300,
            309,
            311,
            445,
            257,
            588,
            2199,
            367,
            75,
            370,
            456,
            366,
            1391,
            3166,
            295,
            661,
            51141
          ],
          "temperature": 0,
          "avg_logprob": -0.032489,
          "compression_ratio": 1.8339623,
          "no_speech_prob": 1.5859789e-12
        },
        {
          "id": 527,
          "seek": 26577,
          "start": 2727.8582,
          "end": 2734.938,
          "text": " brains in our brain that are just like doing very simple naive type rl algorithms um layer one thing",
          "tokens": [
            51141,
            15442,
            294,
            527,
            3567,
            300,
            366,
            445,
            411,
            884,
            588,
            2199,
            29052,
            2010,
            367,
            75,
            14642,
            1105,
            4583,
            472,
            551,
            51495
          ],
          "temperature": 0,
          "avg_logprob": -0.032489,
          "compression_ratio": 1.8339623,
          "no_speech_prob": 1.5859789e-12
        },
        {
          "id": 528,
          "seek": 26577,
          "start": 2734.938,
          "end": 2739.798,
          "text": " on top of that is that some of the major work in neuroscience like peter diane's work and a bunch",
          "tokens": [
            51495,
            322,
            1192,
            295,
            300,
            307,
            300,
            512,
            295,
            264,
            2563,
            589,
            294,
            42762,
            411,
            280,
            2398,
            274,
            21133,
            311,
            589,
            293,
            257,
            3840,
            51738
          ],
          "temperature": 0,
          "avg_logprob": -0.032489,
          "compression_ratio": 1.8339623,
          "no_speech_prob": 1.5859789e-12
        },
        {
          "id": 529,
          "seek": 29323,
          "start": 2739.798,
          "end": 2744.738,
          "text": " bunch of work that is part of why i think deep mind did the temporal difference learning stuff",
          "tokens": [
            50365,
            3840,
            295,
            589,
            300,
            307,
            644,
            295,
            983,
            741,
            519,
            2452,
            1575,
            630,
            264,
            30881,
            2649,
            2539,
            1507,
            50612
          ],
          "temperature": 0,
          "avg_logprob": -0.03498916,
          "compression_ratio": 1.8841699,
          "no_speech_prob": 1.3672079e-12
        },
        {
          "id": 530,
          "seek": 29323,
          "start": 2744.738,
          "end": 2750.778,
          "text": " in the first place um is they were very interested in neuroscience um and there's a lot of neuroscience",
          "tokens": [
            50612,
            294,
            264,
            700,
            1081,
            1105,
            307,
            436,
            645,
            588,
            3102,
            294,
            42762,
            1105,
            293,
            456,
            311,
            257,
            688,
            295,
            42762,
            50914
          ],
          "temperature": 0,
          "avg_logprob": -0.03498916,
          "compression_ratio": 1.8841699,
          "no_speech_prob": 1.3672079e-12
        },
        {
          "id": 531,
          "seek": 29323,
          "start": 2750.778,
          "end": 2756.3782,
          "text": " evidence that the dopamine is giving this reward prediction error signal um rather than just reward",
          "tokens": [
            50914,
            4467,
            300,
            264,
            37219,
            307,
            2902,
            341,
            7782,
            17630,
            6713,
            6358,
            1105,
            2831,
            813,
            445,
            7782,
            51194
          ],
          "temperature": 0,
          "avg_logprob": -0.03498916,
          "compression_ratio": 1.8841699,
          "no_speech_prob": 1.3672079e-12
        },
        {
          "id": 532,
          "seek": 29323,
          "start": 2756.3782,
          "end": 2761.558,
          "text": " yes no you know a gazillion time steps in the future it's a prediction error um and that's",
          "tokens": [
            51194,
            2086,
            572,
            291,
            458,
            257,
            26232,
            11836,
            565,
            4439,
            294,
            264,
            2027,
            309,
            311,
            257,
            17630,
            6713,
            1105,
            293,
            300,
            311,
            51453
          ],
          "temperature": 0,
          "avg_logprob": -0.03498916,
          "compression_ratio": 1.8841699,
          "no_speech_prob": 1.3672079e-12
        },
        {
          "id": 533,
          "seek": 29323,
          "start": 2761.558,
          "end": 2768.538,
          "text": " consistent with like learning these value functions um so there's that and then there's maybe like",
          "tokens": [
            51453,
            8398,
            365,
            411,
            2539,
            613,
            2158,
            6828,
            1105,
            370,
            456,
            311,
            300,
            293,
            550,
            456,
            311,
            1310,
            411,
            51802
          ],
          "temperature": 0,
          "avg_logprob": -0.03498916,
          "compression_ratio": 1.8841699,
          "no_speech_prob": 1.3672079e-12
        },
        {
          "id": 534,
          "seek": 32197,
          "start": 2768.538,
          "end": 2772.998,
          "text": " higher order stuff. So we have these cortex making this world model. Well, one of the things the",
          "tokens": [
            50365,
            2946,
            1668,
            1507,
            13,
            407,
            321,
            362,
            613,
            33312,
            1455,
            341,
            1002,
            2316,
            13,
            1042,
            11,
            472,
            295,
            264,
            721,
            264,
            50588
          ],
          "temperature": 0,
          "avg_logprob": -0.06644391,
          "compression_ratio": 1.8191882,
          "no_speech_prob": 1.1159242e-12
        },
        {
          "id": 535,
          "seek": 32197,
          "start": 2772.998,
          "end": 2778.8582,
          "text": " cortex world model can contain is a model of when you do and don't get rewards, right? Again, it's",
          "tokens": [
            50588,
            33312,
            1002,
            2316,
            393,
            5304,
            307,
            257,
            2316,
            295,
            562,
            291,
            360,
            293,
            500,
            380,
            483,
            17203,
            11,
            558,
            30,
            3764,
            11,
            309,
            311,
            50881
          ],
          "temperature": 0,
          "avg_logprob": -0.06644391,
          "compression_ratio": 1.8191882,
          "no_speech_prob": 1.1159242e-12
        },
        {
          "id": 536,
          "seek": 32197,
          "start": 2778.8582,
          "end": 2782.398,
          "text": " predicting what the steering subsystem will do. It could be predicting what the basal ganglia will do.",
          "tokens": [
            50881,
            32884,
            437,
            264,
            14823,
            2090,
            9321,
            486,
            360,
            13,
            467,
            727,
            312,
            32884,
            437,
            264,
            987,
            304,
            10145,
            14218,
            486,
            360,
            13,
            51058
          ],
          "temperature": 0,
          "avg_logprob": -0.06644391,
          "compression_ratio": 1.8191882,
          "no_speech_prob": 1.1159242e-12
        },
        {
          "id": 537,
          "seek": 32197,
          "start": 2783.178,
          "end": 2787.298,
          "text": " And so you have a model in your cortex that has more generalization and more concepts and all this",
          "tokens": [
            51097,
            400,
            370,
            291,
            362,
            257,
            2316,
            294,
            428,
            33312,
            300,
            575,
            544,
            2674,
            2144,
            293,
            544,
            10392,
            293,
            439,
            341,
            51303
          ],
          "temperature": 0,
          "avg_logprob": -0.06644391,
          "compression_ratio": 1.8191882,
          "no_speech_prob": 1.1159242e-12
        },
        {
          "id": 538,
          "seek": 32197,
          "start": 2787.298,
          "end": 2793.318,
          "text": " stuff that says, okay, these types of plans, these types of actions will lead in these types of",
          "tokens": [
            51303,
            1507,
            300,
            1619,
            11,
            1392,
            11,
            613,
            3467,
            295,
            5482,
            11,
            613,
            3467,
            295,
            5909,
            486,
            1477,
            294,
            613,
            3467,
            295,
            51604
          ],
          "temperature": 0,
          "avg_logprob": -0.06644391,
          "compression_ratio": 1.8191882,
          "no_speech_prob": 1.1159242e-12
        },
        {
          "id": 539,
          "seek": 34675,
          "start": 2793.318,
          "end": 2799.818,
          "text": " circumstances to reward. So I have a model of my reward. Some people also think that you can go the",
          "tokens": [
            50365,
            9121,
            281,
            7782,
            13,
            407,
            286,
            362,
            257,
            2316,
            295,
            452,
            7782,
            13,
            2188,
            561,
            611,
            519,
            300,
            291,
            393,
            352,
            264,
            50690
          ],
          "temperature": 0,
          "avg_logprob": -0.0717098,
          "compression_ratio": 1.851145,
          "no_speech_prob": 1.7622105e-12
        },
        {
          "id": 540,
          "seek": 34675,
          "start": 2799.818,
          "end": 2803.818,
          "text": " other way. And so this is part of the inference picture. There's this idea of RL as inference.",
          "tokens": [
            50690,
            661,
            636,
            13,
            400,
            370,
            341,
            307,
            644,
            295,
            264,
            38253,
            3036,
            13,
            821,
            311,
            341,
            1558,
            295,
            497,
            43,
            382,
            38253,
            13,
            50890
          ],
          "temperature": 0,
          "avg_logprob": -0.0717098,
          "compression_ratio": 1.851145,
          "no_speech_prob": 1.7622105e-12
        },
        {
          "id": 541,
          "seek": 34675,
          "start": 2804.798,
          "end": 2811.418,
          "text": " You could say, well, conditional on my having a high reward, sample a plan that I would have had",
          "tokens": [
            50939,
            509,
            727,
            584,
            11,
            731,
            11,
            27708,
            322,
            452,
            1419,
            257,
            1090,
            7782,
            11,
            6889,
            257,
            1393,
            300,
            286,
            576,
            362,
            632,
            51270
          ],
          "temperature": 0,
          "avg_logprob": -0.0717098,
          "compression_ratio": 1.851145,
          "no_speech_prob": 1.7622105e-12
        },
        {
          "id": 542,
          "seek": 34675,
          "start": 2811.418,
          "end": 2817.1582,
          "text": " to get there. That's inference of the plan part from the reward part. I'm clamping the reward as",
          "tokens": [
            51270,
            281,
            483,
            456,
            13,
            663,
            311,
            38253,
            295,
            264,
            1393,
            644,
            490,
            264,
            7782,
            644,
            13,
            286,
            478,
            17690,
            278,
            264,
            7782,
            382,
            51557
          ],
          "temperature": 0,
          "avg_logprob": -0.0717098,
          "compression_ratio": 1.851145,
          "no_speech_prob": 1.7622105e-12
        },
        {
          "id": 543,
          "seek": 34675,
          "start": 2817.1582,
          "end": 2823.298,
          "text": " high and inferring the plan sampling from plans that could lead to that. And so if you have this",
          "tokens": [
            51557,
            1090,
            293,
            13596,
            2937,
            264,
            1393,
            21179,
            490,
            5482,
            300,
            727,
            1477,
            281,
            300,
            13,
            400,
            370,
            498,
            291,
            362,
            341,
            51864
          ],
          "temperature": 0,
          "avg_logprob": -0.0717098,
          "compression_ratio": 1.851145,
          "no_speech_prob": 1.7622105e-12
        },
        {
          "id": 544,
          "seek": 37673,
          "start": 2823.298,
          "end": 2827.738,
          "text": " very general cortical thing it can just do if you have this like general very general model",
          "tokens": [
            50365,
            588,
            2674,
            11278,
            804,
            551,
            309,
            393,
            445,
            360,
            498,
            291,
            362,
            341,
            411,
            2674,
            588,
            2674,
            2316,
            50587
          ],
          "temperature": 0,
          "avg_logprob": -0.05427239,
          "compression_ratio": 1.8498024,
          "no_speech_prob": 1.3198562e-12
        },
        {
          "id": 545,
          "seek": 37673,
          "start": 2827.738,
          "end": 2833.418,
          "text": " based system and the model among other things includes plans and rewards then you just get it",
          "tokens": [
            50587,
            2361,
            1185,
            293,
            264,
            2316,
            3654,
            661,
            721,
            5974,
            5482,
            293,
            17203,
            550,
            291,
            445,
            483,
            309,
            50871
          ],
          "temperature": 0,
          "avg_logprob": -0.05427239,
          "compression_ratio": 1.8498024,
          "no_speech_prob": 1.3198562e-12
        },
        {
          "id": 546,
          "seek": 37673,
          "start": 2833.418,
          "end": 2840.698,
          "text": " for free basically so like in neural network parlance there's a value head associated to the",
          "tokens": [
            50871,
            337,
            1737,
            1936,
            370,
            411,
            294,
            18161,
            3209,
            13734,
            719,
            456,
            311,
            257,
            2158,
            1378,
            6615,
            281,
            264,
            51235
          ],
          "temperature": 0,
          "avg_logprob": -0.05427239,
          "compression_ratio": 1.8498024,
          "no_speech_prob": 1.3198562e-12
        },
        {
          "id": 547,
          "seek": 37673,
          "start": 2840.698,
          "end": 2846.3381,
          "text": " the omnidirectional inference that's happening yes yeah there's or there's a value input um yeah",
          "tokens": [
            51235,
            264,
            36874,
            327,
            621,
            41048,
            38253,
            300,
            311,
            2737,
            2086,
            1338,
            456,
            311,
            420,
            456,
            311,
            257,
            2158,
            4846,
            1105,
            1338,
            51517
          ],
          "temperature": 0,
          "avg_logprob": -0.05427239,
          "compression_ratio": 1.8498024,
          "no_speech_prob": 1.3198562e-12
        },
        {
          "id": 548,
          "seek": 37673,
          "start": 2846.3381,
          "end": 2851.3381,
          "text": " oh okay yeah and it can predict one of one of the one of the almost sensory variables it can",
          "tokens": [
            51517,
            1954,
            1392,
            1338,
            293,
            309,
            393,
            6069,
            472,
            295,
            472,
            295,
            264,
            472,
            295,
            264,
            1920,
            27233,
            9102,
            309,
            393,
            51767
          ],
          "temperature": 0,
          "avg_logprob": -0.05427239,
          "compression_ratio": 1.8498024,
          "no_speech_prob": 1.3198562e-12
        },
        {
          "id": 549,
          "seek": 40477,
          "start": 2851.3381,
          "end": 2857.398,
          "text": " predict is is what rewards it's going to get yeah but speaking of this thing about amortizing things",
          "tokens": [
            50365,
            6069,
            307,
            307,
            437,
            17203,
            309,
            311,
            516,
            281,
            483,
            1338,
            457,
            4124,
            295,
            341,
            551,
            466,
            669,
            477,
            3319,
            721,
            50668
          ],
          "temperature": 0,
          "avg_logprob": -0.098205335,
          "compression_ratio": 1.7102273,
          "no_speech_prob": 9.809357e-13
        },
        {
          "id": 550,
          "seek": 40477,
          "start": 2857.398,
          "end": 2867.6582,
          "text": " um yeah obviously value is like amortized rollouts of looking up reward yeah something like that yeah",
          "tokens": [
            50668,
            1105,
            1338,
            2745,
            2158,
            307,
            411,
            669,
            477,
            1602,
            3373,
            7711,
            295,
            1237,
            493,
            7782,
            1338,
            746,
            411,
            300,
            1338,
            51181
          ],
          "temperature": 0,
          "avg_logprob": -0.098205335,
          "compression_ratio": 1.7102273,
          "no_speech_prob": 9.809357e-13
        },
        {
          "id": 551,
          "seek": 40477,
          "start": 2867.6582,
          "end": 2874.958,
          "text": " yeah it's like a statistical average or prediction of it yeah right tangential thought uh you know",
          "tokens": [
            51181,
            1338,
            309,
            311,
            411,
            257,
            22820,
            4274,
            420,
            17630,
            295,
            309,
            1338,
            558,
            10266,
            2549,
            1194,
            2232,
            291,
            458,
            51546
          ],
          "temperature": 0,
          "avg_logprob": -0.098205335,
          "compression_ratio": 1.7102273,
          "no_speech_prob": 9.809357e-13
        },
        {
          "id": 552,
          "seek": 42839,
          "start": 2874.958,
          "end": 2896.3782,
          "text": " Joe Henrik and others have this idea that the way human societies have learned to do things is just like, how do you figure out that, you know, this kind of bean, which actually just almost always poisons you, is edible if you do this 10 step incredibly complicated process, any one of which, if you fail at, the bean will be poisonous.",
          "tokens": [
            50365,
            6807,
            8651,
            14456,
            293,
            2357,
            362,
            341,
            1558,
            300,
            264,
            636,
            1952,
            19329,
            362,
            3264,
            281,
            360,
            721,
            307,
            445,
            411,
            11,
            577,
            360,
            291,
            2573,
            484,
            300,
            11,
            291,
            458,
            11,
            341,
            733,
            295,
            16230,
            11,
            597,
            767,
            445,
            1920,
            1009,
            714,
            23886,
            291,
            11,
            307,
            30666,
            498,
            291,
            360,
            341,
            1266,
            1823,
            6252,
            6179,
            1399,
            11,
            604,
            472,
            295,
            597,
            11,
            498,
            291,
            3061,
            412,
            11,
            264,
            16230,
            486,
            312,
            37376,
            13,
            51436
          ],
          "temperature": 0,
          "avg_logprob": -0.12141009,
          "compression_ratio": 1.6076555,
          "no_speech_prob": 1.7969649e-12
        },
        {
          "id": 553,
          "seek": 44981,
          "start": 2896.3782,
          "end": 2901.1582,
          "text": " how do you figure out how to hunt this seal in this particular way with this like particular",
          "tokens": [
            50365,
            577,
            360,
            291,
            2573,
            484,
            577,
            281,
            12454,
            341,
            12185,
            294,
            341,
            1729,
            636,
            365,
            341,
            411,
            1729,
            50604
          ],
          "temperature": 0,
          "avg_logprob": -0.09538078,
          "compression_ratio": 1.8326849,
          "no_speech_prob": 1.4161305e-12
        },
        {
          "id": 554,
          "seek": 44981,
          "start": 2901.1582,
          "end": 2907.978,
          "text": " weapon at this particular time of the year etc um there's no way but uh just like trying shit over",
          "tokens": [
            50604,
            7463,
            412,
            341,
            1729,
            565,
            295,
            264,
            1064,
            5183,
            1105,
            456,
            311,
            572,
            636,
            457,
            2232,
            445,
            411,
            1382,
            4611,
            670,
            50945
          ],
          "temperature": 0,
          "avg_logprob": -0.09538078,
          "compression_ratio": 1.8326849,
          "no_speech_prob": 1.4161305e-12
        },
        {
          "id": 555,
          "seek": 44981,
          "start": 2907.978,
          "end": 2912.6382,
          "text": " generations and it's actually this is actually very much like model free are all happening at",
          "tokens": [
            50945,
            10593,
            293,
            309,
            311,
            767,
            341,
            307,
            767,
            588,
            709,
            411,
            2316,
            1737,
            366,
            439,
            2737,
            412,
            51178
          ],
          "temperature": 0,
          "avg_logprob": -0.09538078,
          "compression_ratio": 1.8326849,
          "no_speech_prob": 1.4161305e-12
        },
        {
          "id": 556,
          "seek": 44981,
          "start": 2912.6382,
          "end": 2917.3381,
          "text": " like a civilizational level um no not exactly because evolution is the simplest algorithm",
          "tokens": [
            51178,
            411,
            257,
            5605,
            590,
            1478,
            1496,
            1105,
            572,
            406,
            2293,
            570,
            9303,
            307,
            264,
            22811,
            9284,
            51413
          ],
          "temperature": 0,
          "avg_logprob": -0.09538078,
          "compression_ratio": 1.8326849,
          "no_speech_prob": 1.4161305e-12
        },
        {
          "id": 557,
          "seek": 44981,
          "start": 2917.3381,
          "end": 2921.458,
          "text": " in some sense right and if we believe that all this can come from evolution like the outer loop",
          "tokens": [
            51413,
            294,
            512,
            2020,
            558,
            293,
            498,
            321,
            1697,
            300,
            439,
            341,
            393,
            808,
            490,
            9303,
            411,
            264,
            10847,
            6367,
            51619
          ],
          "temperature": 0,
          "avg_logprob": -0.09538078,
          "compression_ratio": 1.8326849,
          "no_speech_prob": 1.4161305e-12
        },
        {
          "id": 558,
          "seek": 47489,
          "start": 2921.458,
          "end": 2928.1382,
          "text": " can be like extremely not foresighted and yeah right um that that's interesting just like uh",
          "tokens": [
            50365,
            393,
            312,
            411,
            4664,
            406,
            2091,
            28654,
            292,
            293,
            1338,
            558,
            1105,
            300,
            300,
            311,
            1880,
            445,
            411,
            2232,
            50699
          ],
          "temperature": 0,
          "avg_logprob": -0.14156929,
          "compression_ratio": 1.8994975,
          "no_speech_prob": 1.1026224e-12
        },
        {
          "id": 559,
          "seek": 47489,
          "start": 2928.1382,
          "end": 2932.758,
          "text": " hierarchies of evolution model for you culture uh evolution model for you so what does that tell",
          "tokens": [
            50699,
            35250,
            530,
            295,
            9303,
            2316,
            337,
            291,
            3713,
            2232,
            9303,
            2316,
            337,
            291,
            370,
            437,
            775,
            300,
            980,
            50930
          ],
          "temperature": 0,
          "avg_logprob": -0.14156929,
          "compression_ratio": 1.8994975,
          "no_speech_prob": 1.1026224e-12
        },
        {
          "id": 560,
          "seek": 47489,
          "start": 2932.758,
          "end": 2937.678,
          "text": " you maybe the simple algorithms can just get you anything if you do it enough right yeah yeah so",
          "tokens": [
            50930,
            291,
            1310,
            264,
            2199,
            14642,
            393,
            445,
            483,
            291,
            1340,
            498,
            291,
            360,
            309,
            1547,
            558,
            1338,
            1338,
            370,
            51176
          ],
          "temperature": 0,
          "avg_logprob": -0.14156929,
          "compression_ratio": 1.8994975,
          "no_speech_prob": 1.1026224e-12
        },
        {
          "id": 561,
          "seek": 47489,
          "start": 2937.678,
          "end": 2944.1382,
          "text": " but yeah so you you have like maybe this yeah evolution model free basal ganglia model free",
          "tokens": [
            51176,
            457,
            1338,
            370,
            291,
            291,
            362,
            411,
            1310,
            341,
            1338,
            9303,
            2316,
            1737,
            987,
            304,
            10145,
            14218,
            2316,
            1737,
            51499
          ],
          "temperature": 0,
          "avg_logprob": -0.14156929,
          "compression_ratio": 1.8994975,
          "no_speech_prob": 1.1026224e-12
        },
        {
          "id": 562,
          "seek": 49757,
          "start": 2944.1382,
          "end": 2952.1182,
          "text": " cortex model based culture uh model free potentially um i mean there's like you pay",
          "tokens": [
            50365,
            33312,
            2316,
            2361,
            3713,
            2232,
            2316,
            1737,
            7263,
            1105,
            741,
            914,
            456,
            311,
            411,
            291,
            1689,
            50764
          ],
          "temperature": 0,
          "avg_logprob": -0.07731424,
          "compression_ratio": 1.9416667,
          "no_speech_prob": 1.4497056e-12
        },
        {
          "id": 563,
          "seek": 49757,
          "start": 2952.1182,
          "end": 2955.438,
          "text": " attention to your elders or whatever so there's maybe this like group selection or whatever of",
          "tokens": [
            50764,
            3202,
            281,
            428,
            22737,
            420,
            2035,
            370,
            456,
            311,
            1310,
            341,
            411,
            1594,
            9450,
            420,
            2035,
            295,
            50930
          ],
          "temperature": 0,
          "avg_logprob": -0.07731424,
          "compression_ratio": 1.9416667,
          "no_speech_prob": 1.4497056e-12
        },
        {
          "id": 564,
          "seek": 49757,
          "start": 2955.438,
          "end": 2963.978,
          "text": " these things is like more model free yeah but now i think culture well it stores some of the model",
          "tokens": [
            50930,
            613,
            721,
            307,
            411,
            544,
            2316,
            1737,
            1338,
            457,
            586,
            741,
            519,
            3713,
            731,
            309,
            9512,
            512,
            295,
            264,
            2316,
            51357
          ],
          "temperature": 0,
          "avg_logprob": -0.07731424,
          "compression_ratio": 1.9416667,
          "no_speech_prob": 1.4497056e-12
        },
        {
          "id": 565,
          "seek": 49757,
          "start": 2963.978,
          "end": 2968.1582,
          "text": " yeah right so let's say you want to train an agent to help you with something like processing",
          "tokens": [
            51357,
            1338,
            558,
            370,
            718,
            311,
            584,
            291,
            528,
            281,
            3847,
            364,
            9461,
            281,
            854,
            291,
            365,
            746,
            411,
            9007,
            51566
          ],
          "temperature": 0,
          "avg_logprob": -0.07731424,
          "compression_ratio": 1.9416667,
          "no_speech_prob": 1.4497056e-12
        },
        {
          "id": 566,
          "seek": 49757,
          "start": 2968.1582,
          "end": 2972.738,
          "text": " loan applications training an agent to do this requires more than just giving the model access",
          "tokens": [
            51566,
            10529,
            5821,
            3097,
            364,
            9461,
            281,
            360,
            341,
            7029,
            544,
            813,
            445,
            2902,
            264,
            2316,
            2105,
            51795
          ],
          "temperature": 0,
          "avg_logprob": -0.07731424,
          "compression_ratio": 1.9416667,
          "no_speech_prob": 1.4497056e-12
        },
        {
          "id": 567,
          "seek": 52617,
          "start": 2972.738,
          "end": 2976.8782,
          "text": " to the right tools, things like browsers and PDF readers and risk models.",
          "tokens": [
            50365,
            281,
            264,
            558,
            3873,
            11,
            721,
            411,
            36069,
            293,
            17752,
            17147,
            293,
            3148,
            5245,
            13,
            50572
          ],
          "temperature": 0,
          "avg_logprob": -0.103070445,
          "compression_ratio": 1.6307693,
          "no_speech_prob": 4.194234e-12
        },
        {
          "id": 568,
          "seek": 52617,
          "start": 2977.178,
          "end": 2980.5781,
          "text": " There's this level of tacit knowledge that you can only get by actually working in an",
          "tokens": [
            50587,
            821,
            311,
            341,
            1496,
            295,
            25018,
            270,
            3601,
            300,
            291,
            393,
            787,
            483,
            538,
            767,
            1364,
            294,
            364,
            50757
          ],
          "temperature": 0,
          "avg_logprob": -0.103070445,
          "compression_ratio": 1.6307693,
          "no_speech_prob": 4.194234e-12
        },
        {
          "id": 569,
          "seek": 52617,
          "start": 2980.5781,
          "end": 2980.8782,
          "text": " industry.",
          "tokens": [
            50757,
            3518,
            13,
            50772
          ],
          "temperature": 0,
          "avg_logprob": -0.103070445,
          "compression_ratio": 1.6307693,
          "no_speech_prob": 4.194234e-12
        },
        {
          "id": 570,
          "seek": 52617,
          "start": 2981.298,
          "end": 2985.758,
          "text": " For example, certain loan applications will pass every single automated check despite",
          "tokens": [
            50793,
            1171,
            1365,
            11,
            1629,
            10529,
            5821,
            486,
            1320,
            633,
            2167,
            18473,
            1520,
            7228,
            51016
          ],
          "temperature": 0,
          "avg_logprob": -0.103070445,
          "compression_ratio": 1.6307693,
          "no_speech_prob": 4.194234e-12
        },
        {
          "id": 571,
          "seek": 52617,
          "start": 2985.758,
          "end": 2987.1382,
          "text": " being super risky.",
          "tokens": [
            51016,
            885,
            1687,
            21137,
            13,
            51085
          ],
          "temperature": 0,
          "avg_logprob": -0.103070445,
          "compression_ratio": 1.6307693,
          "no_speech_prob": 4.194234e-12
        },
        {
          "id": 572,
          "seek": 52617,
          "start": 2987.498,
          "end": 2992.278,
          "text": " Every single individual part of the application might look safe, but experienced underwriters",
          "tokens": [
            51103,
            2048,
            2167,
            2609,
            644,
            295,
            264,
            3861,
            1062,
            574,
            3273,
            11,
            457,
            6751,
            833,
            86,
            39335,
            51342
          ],
          "temperature": 0,
          "avg_logprob": -0.103070445,
          "compression_ratio": 1.6307693,
          "no_speech_prob": 4.194234e-12
        },
        {
          "id": 573,
          "seek": 52617,
          "start": 2992.278,
          "end": 2997.0981,
          "text": " know to compare across documents to find subtle patterns that signal risk.",
          "tokens": [
            51342,
            458,
            281,
            6794,
            2108,
            8512,
            281,
            915,
            13743,
            8294,
            300,
            6358,
            3148,
            13,
            51583
          ],
          "temperature": 0,
          "avg_logprob": -0.103070445,
          "compression_ratio": 1.6307693,
          "no_speech_prob": 4.194234e-12
        },
        {
          "id": 574,
          "seek": 52617,
          "start": 2997.478,
          "end": 3001.3381,
          "text": " Libelbox has experts like this in whatever domain you're focused on, and they will set",
          "tokens": [
            51602,
            15834,
            338,
            4995,
            575,
            8572,
            411,
            341,
            294,
            2035,
            9274,
            291,
            434,
            5178,
            322,
            11,
            293,
            436,
            486,
            992,
            51795
          ],
          "temperature": 0,
          "avg_logprob": -0.103070445,
          "compression_ratio": 1.6307693,
          "no_speech_prob": 4.194234e-12
        },
        {
          "id": 575,
          "seek": 55477,
          "start": 3001.3381,
          "end": 3005.8582,
          "text": " up highly realistic training environments that include whatever subtle nuances and watch outs",
          "tokens": [
            50365,
            493,
            5405,
            12465,
            3097,
            12388,
            300,
            4090,
            2035,
            13743,
            38775,
            293,
            1159,
            14758,
            50591
          ],
          "temperature": 0,
          "avg_logprob": -0.0965202,
          "compression_ratio": 1.7788461,
          "no_speech_prob": 4.660213e-12
        },
        {
          "id": 576,
          "seek": 55477,
          "start": 3005.8582,
          "end": 3010.1582,
          "text": " you need to look out for. Beyond just building the environment itself, Labelbox provides all the",
          "tokens": [
            50591,
            291,
            643,
            281,
            574,
            484,
            337,
            13,
            19707,
            445,
            2390,
            264,
            2823,
            2564,
            11,
            10137,
            338,
            4995,
            6417,
            439,
            264,
            50806
          ],
          "temperature": 0,
          "avg_logprob": -0.0965202,
          "compression_ratio": 1.7788461,
          "no_speech_prob": 4.660213e-12
        },
        {
          "id": 577,
          "seek": 55477,
          "start": 3010.1582,
          "end": 3014.198,
          "text": " scaffolding you need to capture training data for your agent. They give you the tools to grade",
          "tokens": [
            50806,
            44094,
            278,
            291,
            643,
            281,
            7983,
            3097,
            1412,
            337,
            428,
            9461,
            13,
            814,
            976,
            291,
            264,
            3873,
            281,
            7204,
            51008
          ],
          "temperature": 0,
          "avg_logprob": -0.0965202,
          "compression_ratio": 1.7788461,
          "no_speech_prob": 4.660213e-12
        },
        {
          "id": 578,
          "seek": 55477,
          "start": 3014.198,
          "end": 3020.0781,
          "text": " agent performance and capture the video of each session and to reset the entire environment to a",
          "tokens": [
            51008,
            9461,
            3389,
            293,
            7983,
            264,
            960,
            295,
            1184,
            5481,
            293,
            281,
            14322,
            264,
            2302,
            2823,
            281,
            257,
            51302
          ],
          "temperature": 0,
          "avg_logprob": -0.0965202,
          "compression_ratio": 1.7788461,
          "no_speech_prob": 4.660213e-12
        },
        {
          "id": 579,
          "seek": 55477,
          "start": 3020.0781,
          "end": 3024.538,
          "text": " clean state between every episode. So whatever domain you're working in, Labelbox can help you",
          "tokens": [
            51302,
            2541,
            1785,
            1296,
            633,
            3500,
            13,
            407,
            2035,
            9274,
            291,
            434,
            1364,
            294,
            11,
            10137,
            338,
            4995,
            393,
            854,
            291,
            51525
          ],
          "temperature": 0,
          "avg_logprob": -0.0965202,
          "compression_ratio": 1.7788461,
          "no_speech_prob": 4.660213e-12
        },
        {
          "id": 580,
          "seek": 55477,
          "start": 3024.538,
          "end": 3030.758,
          "text": " train reliable real-world agents. Learn more at labelbox.com slash thwarkash.",
          "tokens": [
            51525,
            3847,
            12924,
            957,
            12,
            13217,
            12554,
            13,
            17216,
            544,
            412,
            7645,
            4995,
            13,
            1112,
            17330,
            258,
            86,
            809,
            1299,
            13,
            51836
          ],
          "temperature": 0,
          "avg_logprob": -0.0965202,
          "compression_ratio": 1.7788461,
          "no_speech_prob": 4.660213e-12
        },
        {
          "id": 581,
          "seek": 58477,
          "start": 3031.3381,
          "end": 3045.958,
          "text": " So stepping back, how is it a disadvantage or an advantage for humans that we get to use biological hardware in comparison to computers as they exist now?",
          "tokens": [
            50365,
            407,
            16821,
            646,
            11,
            577,
            307,
            309,
            257,
            24292,
            420,
            364,
            5002,
            337,
            6255,
            300,
            321,
            483,
            281,
            764,
            13910,
            8837,
            294,
            9660,
            281,
            10807,
            382,
            436,
            2514,
            586,
            30,
            51096
          ],
          "temperature": 0,
          "avg_logprob": -0.103575595,
          "compression_ratio": 1.6455696,
          "no_speech_prob": 1.1785059e-12
        },
        {
          "id": 582,
          "seek": 58477,
          "start": 3046.0781,
          "end": 3055.978,
          "text": " So what I mean by this question is like if there's the algorithm, would the algorithm just qualitatively perform much worse or much better if inscribed in the hardware of today?",
          "tokens": [
            51102,
            407,
            437,
            286,
            914,
            538,
            341,
            1168,
            307,
            411,
            498,
            456,
            311,
            264,
            9284,
            11,
            576,
            264,
            9284,
            445,
            31312,
            356,
            2042,
            709,
            5324,
            420,
            709,
            1101,
            498,
            1028,
            18732,
            294,
            264,
            8837,
            295,
            965,
            30,
            51597
          ],
          "temperature": 0,
          "avg_logprob": -0.103575595,
          "compression_ratio": 1.6455696,
          "no_speech_prob": 1.1785059e-12
        },
        {
          "id": 583,
          "seek": 58477,
          "start": 3055.978,
          "end": 3057.978,
          "text": " And the reason to think it might like here's what I mean.",
          "tokens": [
            51597,
            400,
            264,
            1778,
            281,
            519,
            309,
            1062,
            411,
            510,
            311,
            437,
            286,
            914,
            13,
            51697
          ],
          "temperature": 0,
          "avg_logprob": -0.103575595,
          "compression_ratio": 1.6455696,
          "no_speech_prob": 1.1785059e-12
        },
        {
          "id": 584,
          "seek": 61141,
          "start": 3057.978,
          "end": 3064.258,
          "text": " And like, you know, obviously the brain has had to make a bunch of tradeoffs which are not relevant to competing hardware.",
          "tokens": [
            50365,
            400,
            411,
            11,
            291,
            458,
            11,
            2745,
            264,
            3567,
            575,
            632,
            281,
            652,
            257,
            3840,
            295,
            4923,
            19231,
            597,
            366,
            406,
            7340,
            281,
            15439,
            8837,
            13,
            50679
          ],
          "temperature": 0,
          "avg_logprob": -0.1534944,
          "compression_ratio": 1.6445993,
          "no_speech_prob": 1.7346282e-12
        },
        {
          "id": 585,
          "seek": 61141,
          "start": 3064.438,
          "end": 3065.898,
          "text": " It has to be much more energetically efficient.",
          "tokens": [
            50688,
            467,
            575,
            281,
            312,
            709,
            544,
            2043,
            847,
            984,
            7148,
            13,
            50761
          ],
          "temperature": 0,
          "avg_logprob": -0.1534944,
          "compression_ratio": 1.6445993,
          "no_speech_prob": 1.7346282e-12
        },
        {
          "id": 586,
          "seek": 61141,
          "start": 3066.238,
          "end": 3070.698,
          "text": " Maybe as a result, it has to run on slower speeds so that there can be a smaller voltage gap.",
          "tokens": [
            50778,
            2704,
            382,
            257,
            1874,
            11,
            309,
            575,
            281,
            1190,
            322,
            14009,
            16411,
            370,
            300,
            456,
            393,
            312,
            257,
            4356,
            8352,
            7417,
            13,
            51001
          ],
          "temperature": 0,
          "avg_logprob": -0.1534944,
          "compression_ratio": 1.6445993,
          "no_speech_prob": 1.7346282e-12
        },
        {
          "id": 587,
          "seek": 61141,
          "start": 3070.8582,
          "end": 3074.8582,
          "text": " And so the brain runs at 200 hertz and has to like run on 20 watts.",
          "tokens": [
            51009,
            400,
            370,
            264,
            3567,
            6676,
            412,
            2331,
            45830,
            293,
            575,
            281,
            411,
            1190,
            322,
            945,
            31247,
            13,
            51209
          ],
          "temperature": 0,
          "avg_logprob": -0.1534944,
          "compression_ratio": 1.6445993,
          "no_speech_prob": 1.7346282e-12
        },
        {
          "id": 588,
          "seek": 61141,
          "start": 3075.318,
          "end": 3082.5981,
          "text": " On the other hand, you know, with like robotics, we've clearly experienced that fingers are way more nimble than we can make motors so far.",
          "tokens": [
            51232,
            1282,
            264,
            661,
            1011,
            11,
            291,
            458,
            11,
            365,
            411,
            34145,
            11,
            321,
            600,
            4448,
            6751,
            300,
            7350,
            366,
            636,
            544,
            24887,
            638,
            813,
            321,
            393,
            652,
            25035,
            370,
            1400,
            13,
            51596
          ],
          "temperature": 0,
          "avg_logprob": -0.1534944,
          "compression_ratio": 1.6445993,
          "no_speech_prob": 1.7346282e-12
        },
        {
          "id": 589,
          "seek": 63603,
          "start": 3082.5981,
          "end": 3086.8582,
          "text": " as maybe there's something in the brain that is the equivalent of like cognitive uh dexterity",
          "tokens": [
            50365,
            382,
            1310,
            456,
            311,
            746,
            294,
            264,
            3567,
            300,
            307,
            264,
            10344,
            295,
            411,
            15605,
            2232,
            368,
            36671,
            507,
            50578
          ],
          "temperature": 0,
          "avg_logprob": -0.060707252,
          "compression_ratio": 1.8501629,
          "no_speech_prob": 2.408856e-12
        },
        {
          "id": 590,
          "seek": 63603,
          "start": 3086.8582,
          "end": 3091.6382,
          "text": " which is like maybe due to the fact that we can do unstructured sparsity we can co-locate the",
          "tokens": [
            50578,
            597,
            307,
            411,
            1310,
            3462,
            281,
            264,
            1186,
            300,
            321,
            393,
            360,
            18799,
            46847,
            637,
            685,
            507,
            321,
            393,
            598,
            12,
            5842,
            473,
            264,
            50817
          ],
          "temperature": 0,
          "avg_logprob": -0.060707252,
          "compression_ratio": 1.8501629,
          "no_speech_prob": 2.408856e-12
        },
        {
          "id": 591,
          "seek": 63603,
          "start": 3091.6382,
          "end": 3096.058,
          "text": " memory in the compute yes where does this all that are you like fuck we would be so smarter",
          "tokens": [
            50817,
            4675,
            294,
            264,
            14722,
            2086,
            689,
            775,
            341,
            439,
            300,
            366,
            291,
            411,
            3275,
            321,
            576,
            312,
            370,
            20294,
            51038
          ],
          "temperature": 0,
          "avg_logprob": -0.060707252,
          "compression_ratio": 1.8501629,
          "no_speech_prob": 2.408856e-12
        },
        {
          "id": 592,
          "seek": 63603,
          "start": 3096.058,
          "end": 3099.758,
          "text": " if we didn't have to deal with these brains or are you like oh i mean i think in the end we will",
          "tokens": [
            51038,
            498,
            321,
            994,
            380,
            362,
            281,
            2028,
            365,
            613,
            15442,
            420,
            366,
            291,
            411,
            1954,
            741,
            914,
            741,
            519,
            294,
            264,
            917,
            321,
            486,
            51223
          ],
          "temperature": 0,
          "avg_logprob": -0.060707252,
          "compression_ratio": 1.8501629,
          "no_speech_prob": 2.408856e-12
        },
        {
          "id": 593,
          "seek": 63603,
          "start": 3099.758,
          "end": 3103.958,
          "text": " get the best of both worlds right somehow right i think i think an obvious downside of the brain",
          "tokens": [
            51223,
            483,
            264,
            1151,
            295,
            1293,
            13401,
            558,
            6063,
            558,
            741,
            519,
            741,
            519,
            364,
            6322,
            25060,
            295,
            264,
            3567,
            51433
          ],
          "temperature": 0,
          "avg_logprob": -0.060707252,
          "compression_ratio": 1.8501629,
          "no_speech_prob": 2.408856e-12
        },
        {
          "id": 594,
          "seek": 63603,
          "start": 3103.958,
          "end": 3108.998,
          "text": " is it cannot be copied yeah you don't have you know external read write access to every neuron",
          "tokens": [
            51433,
            307,
            309,
            2644,
            312,
            25365,
            1338,
            291,
            500,
            380,
            362,
            291,
            458,
            8320,
            1401,
            2464,
            2105,
            281,
            633,
            34090,
            51685
          ],
          "temperature": 0,
          "avg_logprob": -0.060707252,
          "compression_ratio": 1.8501629,
          "no_speech_prob": 2.408856e-12
        },
        {
          "id": 595,
          "seek": 66243,
          "start": 3108.998,
          "end": 3110.798,
          "text": " in synapse, whereas you do.",
          "tokens": [
            50365,
            294,
            5451,
            11145,
            11,
            9735,
            291,
            360,
            13,
            50455
          ],
          "temperature": 0,
          "avg_logprob": -0.19285622,
          "compression_ratio": 1.7418301,
          "no_speech_prob": 1.5921845e-12
        },
        {
          "id": 596,
          "seek": 66243,
          "start": 3110.878,
          "end": 3112.378,
          "text": " I can just edit something in the weight matrix,",
          "tokens": [
            50459,
            286,
            393,
            445,
            8129,
            746,
            294,
            264,
            3364,
            8141,
            11,
            50534
          ],
          "temperature": 0,
          "avg_logprob": -0.19285622,
          "compression_ratio": 1.7418301,
          "no_speech_prob": 1.5921845e-12
        },
        {
          "id": 597,
          "seek": 66243,
          "start": 3112.498,
          "end": 3114.0781,
          "text": " you know, in Python or whatever,",
          "tokens": [
            50540,
            291,
            458,
            11,
            294,
            15329,
            420,
            2035,
            11,
            50619
          ],
          "temperature": 0,
          "avg_logprob": -0.19285622,
          "compression_ratio": 1.7418301,
          "no_speech_prob": 1.5921845e-12
        },
        {
          "id": 598,
          "seek": 66243,
          "start": 3114.898,
          "end": 3116.878,
          "text": " you know, and load that up",
          "tokens": [
            50660,
            291,
            458,
            11,
            293,
            3677,
            300,
            493,
            50759
          ],
          "temperature": 0,
          "avg_logprob": -0.19285622,
          "compression_ratio": 1.7418301,
          "no_speech_prob": 1.5921845e-12
        },
        {
          "id": 599,
          "seek": 66243,
          "start": 3116.878,
          "end": 3119.6782,
          "text": " and copy that in principle, right?",
          "tokens": [
            50759,
            293,
            5055,
            300,
            294,
            8665,
            11,
            558,
            30,
            50899
          ],
          "temperature": 0,
          "avg_logprob": -0.19285622,
          "compression_ratio": 1.7418301,
          "no_speech_prob": 1.5921845e-12
        },
        {
          "id": 600,
          "seek": 66243,
          "start": 3121.038,
          "end": 3122.558,
          "text": " So the fact that it can't be copied",
          "tokens": [
            50967,
            407,
            264,
            1186,
            300,
            309,
            393,
            380,
            312,
            25365,
            51043
          ],
          "temperature": 0,
          "avg_logprob": -0.19285622,
          "compression_ratio": 1.7418301,
          "no_speech_prob": 1.5921845e-12
        },
        {
          "id": 601,
          "seek": 66243,
          "start": 3122.558,
          "end": 3123.6382,
          "text": " and kind of random accessed",
          "tokens": [
            51043,
            293,
            733,
            295,
            4974,
            34211,
            51097
          ],
          "temperature": 0,
          "avg_logprob": -0.19285622,
          "compression_ratio": 1.7418301,
          "no_speech_prob": 1.5921845e-12
        },
        {
          "id": 602,
          "seek": 66243,
          "start": 3123.6382,
          "end": 3125.438,
          "text": " is, like, very annoying.",
          "tokens": [
            51097,
            307,
            11,
            411,
            11,
            588,
            11304,
            13,
            51187
          ],
          "temperature": 0,
          "avg_logprob": -0.19285622,
          "compression_ratio": 1.7418301,
          "no_speech_prob": 1.5921845e-12
        },
        {
          "id": 603,
          "seek": 66243,
          "start": 3126.1382,
          "end": 3127.738,
          "text": " But otherwise, maybe these are,",
          "tokens": [
            51222,
            583,
            5911,
            11,
            1310,
            613,
            366,
            11,
            51302
          ],
          "temperature": 0,
          "avg_logprob": -0.19285622,
          "compression_ratio": 1.7418301,
          "no_speech_prob": 1.5921845e-12
        },
        {
          "id": 604,
          "seek": 66243,
          "start": 3127.978,
          "end": 3129.018,
          "text": " it, like, has a lot of advantages.",
          "tokens": [
            51314,
            309,
            11,
            411,
            11,
            575,
            257,
            688,
            295,
            14906,
            13,
            51366
          ],
          "temperature": 0,
          "avg_logprob": -0.19285622,
          "compression_ratio": 1.7418301,
          "no_speech_prob": 1.5921845e-12
        },
        {
          "id": 605,
          "seek": 66243,
          "start": 3129.3381,
          "end": 3130.898,
          "text": " So it also tells you that you want to, like,",
          "tokens": [
            51382,
            407,
            309,
            611,
            5112,
            291,
            300,
            291,
            528,
            281,
            11,
            411,
            11,
            51460
          ],
          "temperature": 0,
          "avg_logprob": -0.19285622,
          "compression_ratio": 1.7418301,
          "no_speech_prob": 1.5921845e-12
        },
        {
          "id": 606,
          "seek": 66243,
          "start": 3130.938,
          "end": 3132.978,
          "text": " somehow do the co-design of the algorithm",
          "tokens": [
            51462,
            6063,
            360,
            264,
            598,
            12,
            14792,
            788,
            295,
            264,
            9284,
            51564
          ],
          "temperature": 0,
          "avg_logprob": -0.19285622,
          "compression_ratio": 1.7418301,
          "no_speech_prob": 1.5921845e-12
        },
        {
          "id": 607,
          "seek": 66243,
          "start": 3132.978,
          "end": 3136.198,
          "text": " and it maybe even doesn't change it",
          "tokens": [
            51564,
            293,
            309,
            1310,
            754,
            1177,
            380,
            1319,
            309,
            51725
          ],
          "temperature": 0,
          "avg_logprob": -0.19285622,
          "compression_ratio": 1.7418301,
          "no_speech_prob": 1.5921845e-12
        },
        {
          "id": 608,
          "seek": 66243,
          "start": 3136.198,
          "end": 3137.378,
          "text": " that much from all of what we discussed,",
          "tokens": [
            51725,
            300,
            709,
            490,
            439,
            295,
            437,
            321,
            7152,
            11,
            51784
          ],
          "temperature": 0,
          "avg_logprob": -0.19285622,
          "compression_ratio": 1.7418301,
          "no_speech_prob": 1.5921845e-12
        },
        {
          "id": 609,
          "seek": 66243,
          "start": 3137.438,
          "end": 3138.798,
          "text": " but you want to somehow do this co-design.",
          "tokens": [
            51787,
            457,
            291,
            528,
            281,
            6063,
            360,
            341,
            598,
            12,
            14792,
            788,
            13,
            51855
          ],
          "temperature": 0,
          "avg_logprob": -0.19285622,
          "compression_ratio": 1.7418301,
          "no_speech_prob": 1.5921845e-12
        },
        {
          "id": 610,
          "seek": 69223,
          "start": 3138.798,
          "end": 3143.978,
          "text": " So, yeah, how do you do it with really slow, low voltage switches?",
          "tokens": [
            50365,
            407,
            11,
            1338,
            11,
            577,
            360,
            291,
            360,
            309,
            365,
            534,
            2964,
            11,
            2295,
            8352,
            19458,
            30,
            50624
          ],
          "temperature": 0,
          "avg_logprob": -0.15155189,
          "compression_ratio": 1.7857143,
          "no_speech_prob": 1.5983965e-12
        },
        {
          "id": 611,
          "seek": 69223,
          "start": 3144.398,
          "end": 3147.3582,
          "text": " That's going to be really important for the energy consumption.",
          "tokens": [
            50645,
            663,
            311,
            516,
            281,
            312,
            534,
            1021,
            337,
            264,
            2281,
            12126,
            13,
            50793
          ],
          "temperature": 0,
          "avg_logprob": -0.15155189,
          "compression_ratio": 1.7857143,
          "no_speech_prob": 1.5983965e-12
        },
        {
          "id": 612,
          "seek": 69223,
          "start": 3148.3582,
          "end": 3150.0981,
          "text": " The co-locating memory and compute.",
          "tokens": [
            50843,
            440,
            598,
            12,
            5842,
            990,
            4675,
            293,
            14722,
            13,
            50930
          ],
          "temperature": 0,
          "avg_logprob": -0.15155189,
          "compression_ratio": 1.7857143,
          "no_speech_prob": 1.5983965e-12
        },
        {
          "id": 613,
          "seek": 69223,
          "start": 3150.558,
          "end": 3154.6782,
          "text": " So, like, I think that probably just like hardware companies will try to co-locate memory and compute.",
          "tokens": [
            50953,
            407,
            11,
            411,
            11,
            286,
            519,
            300,
            1391,
            445,
            411,
            8837,
            3431,
            486,
            853,
            281,
            598,
            12,
            5842,
            473,
            4675,
            293,
            14722,
            13,
            51159
          ],
          "temperature": 0,
          "avg_logprob": -0.15155189,
          "compression_ratio": 1.7857143,
          "no_speech_prob": 1.5983965e-12
        },
        {
          "id": 614,
          "seek": 69223,
          "start": 3154.878,
          "end": 3158.6782,
          "text": " They will try to use lower voltages, allow some stochastic stuff.",
          "tokens": [
            51169,
            814,
            486,
            853,
            281,
            764,
            3126,
            49614,
            11,
            2089,
            512,
            342,
            8997,
            2750,
            1507,
            13,
            51359
          ],
          "temperature": 0,
          "avg_logprob": -0.15155189,
          "compression_ratio": 1.7857143,
          "no_speech_prob": 1.5983965e-12
        },
        {
          "id": 615,
          "seek": 69223,
          "start": 3159.298,
          "end": 3165.718,
          "text": " There are some people that think that this, like, all this probabilistic stuff that we were talking about, oh, oh, it's actually energy-based models and so on.",
          "tokens": [
            51390,
            821,
            366,
            512,
            561,
            300,
            519,
            300,
            341,
            11,
            411,
            11,
            439,
            341,
            31959,
            3142,
            1507,
            300,
            321,
            645,
            1417,
            466,
            11,
            1954,
            11,
            1954,
            11,
            309,
            311,
            767,
            2281,
            12,
            6032,
            5245,
            293,
            370,
            322,
            13,
            51711
          ],
          "temperature": 0,
          "avg_logprob": -0.15155189,
          "compression_ratio": 1.7857143,
          "no_speech_prob": 1.5983965e-12
        },
        {
          "id": 616,
          "seek": 69223,
          "start": 3165.938,
          "end": 3167.498,
          "text": " It is doing lots of sampling.",
          "tokens": [
            51722,
            467,
            307,
            884,
            3195,
            295,
            21179,
            13,
            51800
          ],
          "temperature": 0,
          "avg_logprob": -0.15155189,
          "compression_ratio": 1.7857143,
          "no_speech_prob": 1.5983965e-12
        },
        {
          "id": 617,
          "seek": 72093,
          "start": 3167.498,
          "end": 3173.3582,
          "text": " it's not just amortizing everything that the neurons are also very natural for that because",
          "tokens": [
            50365,
            309,
            311,
            406,
            445,
            669,
            477,
            3319,
            1203,
            300,
            264,
            22027,
            366,
            611,
            588,
            3303,
            337,
            300,
            570,
            50658
          ],
          "temperature": 0,
          "avg_logprob": -0.034034498,
          "compression_ratio": 1.810606,
          "no_speech_prob": 1.543199e-12
        },
        {
          "id": 618,
          "seek": 72093,
          "start": 3173.3582,
          "end": 3179.0781,
          "text": " they're naturally stochastic and so you don't have to do a random number generator and a bunch",
          "tokens": [
            50658,
            436,
            434,
            8195,
            342,
            8997,
            2750,
            293,
            370,
            291,
            500,
            380,
            362,
            281,
            360,
            257,
            4974,
            1230,
            19265,
            293,
            257,
            3840,
            50944
          ],
          "temperature": 0,
          "avg_logprob": -0.034034498,
          "compression_ratio": 1.810606,
          "no_speech_prob": 1.543199e-12
        },
        {
          "id": 619,
          "seek": 72093,
          "start": 3179.0781,
          "end": 3184.778,
          "text": " of python code basically to generate a sample the neuron just generates samples and it can tune what",
          "tokens": [
            50944,
            295,
            38797,
            3089,
            1936,
            281,
            8460,
            257,
            6889,
            264,
            34090,
            445,
            23815,
            10938,
            293,
            309,
            393,
            10864,
            437,
            51229
          ],
          "temperature": 0,
          "avg_logprob": -0.034034498,
          "compression_ratio": 1.810606,
          "no_speech_prob": 1.543199e-12
        },
        {
          "id": 620,
          "seek": 72093,
          "start": 3184.778,
          "end": 3191.3582,
          "text": " the different probabilities are yeah and so and like learn learn those tunings and so it could",
          "tokens": [
            51229,
            264,
            819,
            33783,
            366,
            1338,
            293,
            370,
            293,
            411,
            1466,
            1466,
            729,
            4267,
            1109,
            293,
            370,
            309,
            727,
            51558
          ],
          "temperature": 0,
          "avg_logprob": -0.034034498,
          "compression_ratio": 1.810606,
          "no_speech_prob": 1.543199e-12
        },
        {
          "id": 621,
          "seek": 72093,
          "start": 3191.3582,
          "end": 3196.378,
          "text": " be that it's very co-designed with like some kind of inference method or something yeah it'd be",
          "tokens": [
            51558,
            312,
            300,
            309,
            311,
            588,
            598,
            12,
            14792,
            16690,
            365,
            411,
            512,
            733,
            295,
            38253,
            3170,
            420,
            746,
            1338,
            309,
            1116,
            312,
            51809
          ],
          "temperature": 0,
          "avg_logprob": -0.034034498,
          "compression_ratio": 1.810606,
          "no_speech_prob": 1.543199e-12
        },
        {
          "id": 622,
          "seek": 74981,
          "start": 3196.378,
          "end": 3201.258,
          "text": " hilarious i mean the message of this interview is like you know all these people that folks make",
          "tokens": [
            50365,
            19796,
            741,
            914,
            264,
            3636,
            295,
            341,
            4049,
            307,
            411,
            291,
            458,
            439,
            613,
            561,
            300,
            4024,
            652,
            50609
          ],
          "temperature": 0,
          "avg_logprob": -0.11409655,
          "compression_ratio": 1.8314177,
          "no_speech_prob": 2.004845e-12
        },
        {
          "id": 623,
          "seek": 74981,
          "start": 3201.258,
          "end": 3206.818,
          "text": " fun of on twitter you know yon lakoon and beth jazos and whatever they're like no like well yeah",
          "tokens": [
            50609,
            1019,
            295,
            322,
            21439,
            291,
            458,
            288,
            266,
            287,
            514,
            4106,
            293,
            778,
            71,
            361,
            921,
            329,
            293,
            2035,
            436,
            434,
            411,
            572,
            411,
            731,
            1338,
            50887
          ],
          "temperature": 0,
          "avg_logprob": -0.11409655,
          "compression_ratio": 1.8314177,
          "no_speech_prob": 2.004845e-12
        },
        {
          "id": 624,
          "seek": 74981,
          "start": 3206.818,
          "end": 3211.418,
          "text": " maybe i don't know that is actually that is actually one read of me granted you know i i",
          "tokens": [
            50887,
            1310,
            741,
            500,
            380,
            458,
            300,
            307,
            767,
            300,
            307,
            767,
            472,
            1401,
            295,
            385,
            12344,
            291,
            458,
            741,
            741,
            51117
          ],
          "temperature": 0,
          "avg_logprob": -0.11409655,
          "compression_ratio": 1.8314177,
          "no_speech_prob": 2.004845e-12
        },
        {
          "id": 625,
          "seek": 74981,
          "start": 3211.418,
          "end": 3216.778,
          "text": " haven't really worked on ai at all since loms you know took off so i'm just like out of the loop but",
          "tokens": [
            51117,
            2378,
            380,
            534,
            2732,
            322,
            9783,
            412,
            439,
            1670,
            287,
            4785,
            291,
            458,
            1890,
            766,
            370,
            741,
            478,
            445,
            411,
            484,
            295,
            264,
            6367,
            457,
            51385
          ],
          "temperature": 0,
          "avg_logprob": -0.11409655,
          "compression_ratio": 1.8314177,
          "no_speech_prob": 2.004845e-12
        },
        {
          "id": 626,
          "seek": 74981,
          "start": 3216.778,
          "end": 3222.1782,
          "text": " um i i'm surprised and i i think it's amazing how the scaling is is working and everything but",
          "tokens": [
            51385,
            1105,
            741,
            741,
            478,
            6100,
            293,
            741,
            741,
            519,
            309,
            311,
            2243,
            577,
            264,
            21589,
            307,
            307,
            1364,
            293,
            1203,
            457,
            51655
          ],
          "temperature": 0,
          "avg_logprob": -0.11409655,
          "compression_ratio": 1.8314177,
          "no_speech_prob": 2.004845e-12
        },
        {
          "id": 627,
          "seek": 77561,
          "start": 3222.1782,
          "end": 3227.1382,
          "text": " yeah, I think Jan LeCun and Beth Jezos are kind of onto something about the probabilistic models,",
          "tokens": [
            50365,
            1338,
            11,
            286,
            519,
            4956,
            1456,
            34,
            409,
            293,
            14011,
            2588,
            27681,
            366,
            733,
            295,
            3911,
            746,
            466,
            264,
            31959,
            3142,
            5245,
            11,
            50613
          ],
          "temperature": 0,
          "avg_logprob": -0.119934544,
          "compression_ratio": 1.5308642,
          "no_speech_prob": 1.1513134e-12
        },
        {
          "id": 628,
          "seek": 77561,
          "start": 3227.238,
          "end": 3231.818,
          "text": " or at least possibly. And in fact, that's what all the neuroscientists and all the AI people",
          "tokens": [
            50618,
            420,
            412,
            1935,
            6264,
            13,
            400,
            294,
            1186,
            11,
            300,
            311,
            437,
            439,
            264,
            28813,
            5412,
            1751,
            293,
            439,
            264,
            7318,
            561,
            50847
          ],
          "temperature": 0,
          "avg_logprob": -0.119934544,
          "compression_ratio": 1.5308642,
          "no_speech_prob": 1.1513134e-12
        },
        {
          "id": 629,
          "seek": 77561,
          "start": 3231.818,
          "end": 3237.5781,
          "text": " thought until 2021 or something, right? So there's a bunch of cellular stuff happening in the brain",
          "tokens": [
            50847,
            1194,
            1826,
            7201,
            420,
            746,
            11,
            558,
            30,
            407,
            456,
            311,
            257,
            3840,
            295,
            29267,
            1507,
            2737,
            294,
            264,
            3567,
            51135
          ],
          "temperature": 0,
          "avg_logprob": -0.119934544,
          "compression_ratio": 1.5308642,
          "no_speech_prob": 1.1513134e-12
        },
        {
          "id": 630,
          "seek": 77561,
          "start": 3237.5781,
          "end": 3245.8582,
          "text": " that is not just about neuron-to-neuron synaptic connections. How much of that is",
          "tokens": [
            51135,
            300,
            307,
            406,
            445,
            466,
            34090,
            12,
            1353,
            12,
            716,
            374,
            266,
            5451,
            2796,
            299,
            9271,
            13,
            1012,
            709,
            295,
            300,
            307,
            51549
          ],
          "temperature": 0,
          "avg_logprob": -0.119934544,
          "compression_ratio": 1.5308642,
          "no_speech_prob": 1.1513134e-12
        },
        {
          "id": 631,
          "seek": 79929,
          "start": 3245.8582,
          "end": 3254.318,
          "text": " functionally doing more work than the synapses themselves are doing versus it's just a bunch of",
          "tokens": [
            50365,
            2445,
            379,
            884,
            544,
            589,
            813,
            264,
            5451,
            2382,
            279,
            2969,
            366,
            884,
            5717,
            309,
            311,
            445,
            257,
            3840,
            295,
            50788
          ],
          "temperature": 0,
          "avg_logprob": -0.07381663,
          "compression_ratio": 1.7162162,
          "no_speech_prob": 1.5921927e-12
        },
        {
          "id": 632,
          "seek": 79929,
          "start": 3254.318,
          "end": 3259.698,
          "text": " kludge that you have to do in order to make the synaptic thing work so the way you need to you",
          "tokens": [
            50788,
            350,
            1471,
            432,
            300,
            291,
            362,
            281,
            360,
            294,
            1668,
            281,
            652,
            264,
            5451,
            2796,
            299,
            551,
            589,
            370,
            264,
            636,
            291,
            643,
            281,
            291,
            51057
          ],
          "temperature": 0,
          "avg_logprob": -0.07381663,
          "compression_ratio": 1.7162162,
          "no_speech_prob": 1.5921927e-12
        },
        {
          "id": 633,
          "seek": 79929,
          "start": 3259.698,
          "end": 3265.458,
          "text": " know with a digital mind you can nudge the synapse sorry the parameter extremely easily but with",
          "tokens": [
            51057,
            458,
            365,
            257,
            4562,
            1575,
            291,
            393,
            297,
            16032,
            264,
            5451,
            11145,
            2597,
            264,
            13075,
            4664,
            3612,
            457,
            365,
            51345
          ],
          "temperature": 0,
          "avg_logprob": -0.07381663,
          "compression_ratio": 1.7162162,
          "no_speech_prob": 1.5921927e-12
        },
        {
          "id": 634,
          "seek": 79929,
          "start": 3265.458,
          "end": 3272.918,
          "text": " a cell to modulate a synapse according to the gradient signal it just takes all of this crazy",
          "tokens": [
            51345,
            257,
            2815,
            281,
            1072,
            5256,
            257,
            5451,
            11145,
            4650,
            281,
            264,
            16235,
            6358,
            309,
            445,
            2516,
            439,
            295,
            341,
            3219,
            51718
          ],
          "temperature": 0,
          "avg_logprob": -0.07381663,
          "compression_ratio": 1.7162162,
          "no_speech_prob": 1.5921927e-12
        },
        {
          "id": 635,
          "seek": 82635,
          "start": 3272.918,
          "end": 3276.998,
          "text": " machinery so like is it actually doing more than it takes extremely little code to do so i don't",
          "tokens": [
            50365,
            27302,
            370,
            411,
            307,
            309,
            767,
            884,
            544,
            813,
            309,
            2516,
            4664,
            707,
            3089,
            281,
            360,
            370,
            741,
            500,
            380,
            50569
          ],
          "temperature": 0,
          "avg_logprob": -0.073090024,
          "compression_ratio": 1.840678,
          "no_speech_prob": 1.4840825e-12
        },
        {
          "id": 636,
          "seek": 82635,
          "start": 3276.998,
          "end": 3283.1382,
          "text": " know but i'm i'm not a believer in the like radical like oh actually memory is not synapses mostly",
          "tokens": [
            50569,
            458,
            457,
            741,
            478,
            741,
            478,
            406,
            257,
            23892,
            294,
            264,
            411,
            12001,
            411,
            1954,
            767,
            4675,
            307,
            406,
            5451,
            2382,
            279,
            5240,
            50876
          ],
          "temperature": 0,
          "avg_logprob": -0.073090024,
          "compression_ratio": 1.840678,
          "no_speech_prob": 1.4840825e-12
        },
        {
          "id": 637,
          "seek": 82635,
          "start": 3283.1382,
          "end": 3289.518,
          "text": " or like learning is mostly genetic changes or something like that i think it would just make a",
          "tokens": [
            50876,
            420,
            411,
            2539,
            307,
            5240,
            12462,
            2962,
            420,
            746,
            411,
            300,
            741,
            519,
            309,
            576,
            445,
            652,
            257,
            51195
          ],
          "temperature": 0,
          "avg_logprob": -0.073090024,
          "compression_ratio": 1.840678,
          "no_speech_prob": 1.4840825e-12
        },
        {
          "id": 638,
          "seek": 82635,
          "start": 3289.518,
          "end": 3293.238,
          "text": " lot of sense i think you put it really well for it to be more like the second thing you said like",
          "tokens": [
            51195,
            688,
            295,
            2020,
            741,
            519,
            291,
            829,
            309,
            534,
            731,
            337,
            309,
            281,
            312,
            544,
            411,
            264,
            1150,
            551,
            291,
            848,
            411,
            51381
          ],
          "temperature": 0,
          "avg_logprob": -0.073090024,
          "compression_ratio": 1.840678,
          "no_speech_prob": 1.4840825e-12
        },
        {
          "id": 639,
          "seek": 82635,
          "start": 3293.238,
          "end": 3298.1382,
          "text": " let's say you want to do weight normalization across all the weights coming out of your neuron",
          "tokens": [
            51381,
            718,
            311,
            584,
            291,
            528,
            281,
            360,
            3364,
            2710,
            2144,
            2108,
            439,
            264,
            17443,
            1348,
            484,
            295,
            428,
            34090,
            51626
          ],
          "temperature": 0,
          "avg_logprob": -0.073090024,
          "compression_ratio": 1.840678,
          "no_speech_prob": 1.4840825e-12
        },
        {
          "id": 640,
          "seek": 82635,
          "start": 3298.1382,
          "end": 3301.6382,
          "text": " right or into your neuron well you probably have to go like",
          "tokens": [
            51626,
            558,
            420,
            666,
            428,
            34090,
            731,
            291,
            1391,
            362,
            281,
            352,
            411,
            51801
          ],
          "temperature": 0,
          "avg_logprob": -0.073090024,
          "compression_ratio": 1.840678,
          "no_speech_prob": 1.4840825e-12
        }
      ],
      "x_groq": {
        "id": "req_01ke0zdg89fns9zwaar9dps3cw"
      }
    }
  ]
}